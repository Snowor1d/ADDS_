NOT GUIDE learning . . .
w3 ( 0.7737292845494284 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.9520340524042207) - present_state_Q (0.9520340524042207)) * f3(0.7920340524042206)
w4 ( 0.9542907096453792 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.9520340524042207) - present_state_Q (0.9520340524042207)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.764605225305637 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( -0.07788776429659908) - present_state_Q (-0.11605939268241425)) * f3(-0.15)
w4 ( 0.9542907096453792 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( -0.07788776429659908) - present_state_Q (-0.11605939268241425)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0217976413294063 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.4419277062149593) - present_state_Q (0.4419277062149593)) * f3(0.3619277062149593)
w4 ( 1.0048181205152522 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.4419277062149593) - present_state_Q (0.4419277062149593)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0413209053438286 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.38611709269715) - present_state_Q (0.38611709269715)) * f3(0.2992095799498604)
w4 ( 1.0100380774478328 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.38611709269715) - present_state_Q (0.38611709269715)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.023328286190481 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.4330980775492856) - present_state_Q (-0.1561981358015743)) * f3(-0.15)
w4 ( 1.0100380774478328 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.4330980775492856) - present_state_Q (-0.1561981358015743)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.023244135213793 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.039508633176007495) - present_state_Q (0.039508633176007495)) * f3(-0.0008725351717089325)
w4 ( 1.0138958463683991 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.039508633176007495) - present_state_Q (0.039508633176007495)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.017417435908431 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.03740184539386884) - present_state_Q (-0.03740184539386884)) * f3(-0.056369501994932444)
w4 ( 1.0159631696901081 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.03740184539386884) - present_state_Q (-0.03740184539386884)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0104302087147639 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.0478357796972034) - present_state_Q (-0.0478357796972034)) * f3(-0.06698827903430939)
w4 ( 1.0180492740935632 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.0478357796972034) - present_state_Q (-0.0478357796972034)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.002968234488408 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.03119290278631273) - present_state_Q (-0.051553888268183995)) * f3(-0.07117252941351464)
w4 ( 1.0201461432895422 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.03119290278631273) - present_state_Q (-0.051553888268183995)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9857542968772426 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.028493944288926987) - present_state_Q (-0.15044523517326122)) * f3(-0.15)
w4 ( 1.0201461432895422 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.028493944288926987) - present_state_Q (-0.15044523517326122)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9686009391980949 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.04305965921739595) - present_state_Q (-0.1478631445315864)) * f3(-0.15)
w4 ( 1.0201461432895422 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.04305965921739595) - present_state_Q (-0.1478631445315864)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.957793500868038 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.07745620871417344) - present_state_Q (-0.07745620871417344)) * f3(-0.10103142338575669)
w4 ( 1.0222855644652278 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.07745620871417344) - present_state_Q (-0.07745620871417344)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9411299861311859 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.12322331384090116) - present_state_Q (-0.12322331384090116)) * f3(-0.15)
w4 ( 1.0245073664301414 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.12322331384090116) - present_state_Q (-0.12322331384090116)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9265699111095307 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.6455082743426729) - present_state_Q (0.4541601038039273)) * f3(0.37370966002977585)
w4 ( 1.0206112736664448 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.6455082743426729) - present_state_Q (0.4541601038039273)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9481135620839228 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.38865071855611627) - present_state_Q (0.38865071855611627)) * f3(0.33133151959918294)
w4 ( 1.0258129884928406 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.38865071855611627) - present_state_Q (0.38865071855611627)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9580964437315003 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.15051167667949072) - present_state_Q (0.15051167667949072)) * f3(0.11547051062021035)
w4 ( 1.0292711464567945 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.15051167667949072) - present_state_Q (0.15051167667949072)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9526074592947622 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.34188694467630476) - present_state_Q (-0.009230530160194407)) * f3(-0.05260574376225408)
w4 ( 1.0334448233553057 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.34188694467630476) - present_state_Q (-0.009230530160194407)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9667014208153631 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.20618956551668144) - present_state_Q (0.20618956551668144)) * f3(0.17305320357717213)
w4 ( 1.0367025409194457 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.20618956551668144) - present_state_Q (0.20618956551668144)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.98209590558883 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.13934497832600612) - present_state_Q (0.2594468771591688)) * f3(0.2040389312117037)
w4 ( 1.0412294666434863 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.13934497832600612) - present_state_Q (0.2594468771591688)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9979698422896264 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.14031616203870073) - present_state_Q (0.2727940282268574)) * f3(0.21415450266249467)
w4 ( 1.0456768921713484 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.14031616203870073) - present_state_Q (0.2727940282268574)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0067251961907675 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.14200635126304467) - present_state_Q (0.14200635126304467)) * f3(0.10038306903778878)
w4 ( 1.0491656693068014 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.14200635126304467) - present_state_Q (0.14200635126304467)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0154436733759673 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1426678853779818) - present_state_Q (0.1426678853779818)) * f3(0.10002854700244093)
w4 ( 1.0526520649194406 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1426678853779818) - present_state_Q (0.1426678853779818)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0232081176529406 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1315367102893101) - present_state_Q (0.1315367102893101)) * f3(0.08807049572253413)
w4 ( 1.0561785327623991 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1315367102893101) - present_state_Q (0.1315367102893101)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0280160208330198 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.09609968866972514) - present_state_Q (0.09609968866972514)) * f3(0.0526310790836545)
w4 ( 1.0598325738831882 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.09609968866972514) - present_state_Q (0.09609968866972514)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0309586410667446 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.0748282562912012) - present_state_Q (0.0748282562912012)) * f3(0.03155101932126607)
w4 ( 1.06356319216054 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.0748282562912012) - present_state_Q (0.0748282562912012)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.030389271604909 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.015319237724067555) - present_state_Q (0.015319237724067555)) * f3(-0.0057732928189870095)
w4 ( 1.0655356175326367 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.015319237724067555) - present_state_Q (0.015319237724067555)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.012711379430969 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.2396775418859461) - present_state_Q (-0.15455839074073635)) * f3(-0.15)
w4 ( 1.0655356175326367 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.2396775418859461) - present_state_Q (-0.15455839074073635)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0119130121248296 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.09301124322940924) - present_state_Q (0.013193958614441986)) * f3(-0.008014873636328112)
w4 ( 1.0675278318640538 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.09301124322940924) - present_state_Q (0.013193958614441986)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0140617049006457 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.08765680761371908) - present_state_Q (0.08765680761371908)) * f3(0.023327240008812075)
w4 ( 1.0730544851029398 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.08765680761371908) - present_state_Q (0.08765680761371908)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0159579097024967 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.06331275101098069) - present_state_Q (0.06331275101098069)) * f3(0.020107821356749586)
w4 ( 1.0768265591993003 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.06331275101098069) - present_state_Q (0.06331275101098069)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0085265767413503 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.05066986438681849) - present_state_Q (-0.05066986438681849)) * f3(-0.07107223132102856)
w4 ( 1.0789177649551964 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.05066986438681849) - present_state_Q (-0.05066986438681849)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9918079857529356 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.15127898651120253) - present_state_Q (-0.1297006312120986)) * f3(-0.15)
w4 ( 1.0811469104203184 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.15127898651120253) - present_state_Q (-0.1297006312120986)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8927549036077203 ) += alpha ( 0.1) * (reward ( -1) + discount_factor ( 0.1) * next_state_max_Q( 0.6684606187258681) - present_state_Q (0.7229477928855805)) * f3(0.5981098883619133)
w4 ( 1.0612736896481625 ) += alpha ( 0.1) * (reward ( -1) + discount_factor ( 0.1) * next_state_max_Q( 0.6684606187258681) - present_state_Q (0.7229477928855805)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9147794725787395 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.3863377751713041) - present_state_Q (0.3863377751713041)) * f3(0.33764684885102925)
w4 ( 1.066492057666929 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.3863377751713041) - present_state_Q (0.3863377751713041)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.927357537651633 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.18593241188683138) - present_state_Q (0.17984159818655218)) * f3(0.14996173393917855)
w4 ( 1.0698470642389375 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.18593241188683138) - present_state_Q (0.17984159818655218)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.935296019773615 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.12581224968088361) - present_state_Q (0.12581224968088361)) * f3(0.08952142376666854)
w4 ( 1.0733941401400864 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.12581224968088361) - present_state_Q (0.12581224968088361)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9408618051753147 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1339884924768724) - present_state_Q (0.0999231249246674)) * f3(0.06092975711888257)
w4 ( 1.0770480430373786 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1339884924768724) - present_state_Q (0.0999231249246674)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9542137287139083 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.221529547718606) - present_state_Q (0.221529547718606)) * f3(0.1667690879503034)
w4 ( 1.0818517834796981 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.221529547718606) - present_state_Q (0.221529547718606)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9658116444678191 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1998511383679569) - present_state_Q (0.1998511383679569)) * f3(0.14141489196665355)
w4 ( 1.0867725873325111 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1998511383679569) - present_state_Q (0.1998511383679569)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9754411026811188 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.15111279186191512) - present_state_Q (0.15111279186191512)) * f3(0.11145225778254873)
w4 ( 1.0902285812818082 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.15111279186191512) - present_state_Q (0.15111279186191512)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9871088078719435 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1793239627290731) - present_state_Q (0.1793239627290731)) * f3(0.13913174163439704)
w4 ( 1.0935830150159835 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1793239627290731) - present_state_Q (0.1793239627290731)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.995394825206641 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.11211373476986725) - present_state_Q (0.16192130811262162)) * f3(0.09756404404827915)
w4 ( 1.0986787554081698 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.11211373476986725) - present_state_Q (0.16192130811262162)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9971781442047105 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.04039432448679522) - present_state_Q (0.04039432448679522)) * f3(0.018505972617255395)
w4 ( 1.1006060456240936 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.04039432448679522) - present_state_Q (0.04039432448679522)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9872294941584492 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.07121795341147139) - present_state_Q (-0.07121795341147139)) * f3(-0.09349390062926817)
w4 ( 1.1027342379402343 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.07121795341147139) - present_state_Q (-0.07121795341147139)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0092454770349752 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.5162415701799219) - present_state_Q (0.5162415701799219)) * f3(0.41121962906098203)
w4 ( 1.108088063808615 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.5162415701799219) - present_state_Q (0.5162415701799219)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.032254338654053 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.5420817578705482) - present_state_Q (0.5420817578705482)) * f3(0.4492808965545112)
w4 ( 1.112185075151947 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.5420817578705482) - present_state_Q (0.5420817578705482)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0550250914936976 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.5953874046643947) - present_state_Q (0.5953874046643947)) * f3(0.4905889756903765)
w4 ( 1.1158982858383635 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.5953874046643947) - present_state_Q (0.5953874046643947)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0366548519634826 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.6642887162361413) - present_state_Q (-0.15825376372405464)) * f3(-0.15)
w4 ( 1.1158982858383635 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.6642887162361413) - present_state_Q (-0.15825376372405464)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0183778150878058 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.6297089725059777) - present_state_Q (-0.15549822779452238)) * f3(-0.15)
w4 ( 1.1158982858383635 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.6297089725059777) - present_state_Q (-0.15549822779452238)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0397345193027714 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.46097527495999474) - present_state_Q (0.46097527495999474)) * f3(0.3649955906206352)
w4 ( 1.1205792638586516 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.46097527495999474) - present_state_Q (0.46097527495999474)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0605891449594678 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.4592323467881505) - present_state_Q (0.4592323467881505)) * f3(0.35546189803075556)
w4 ( 1.1252727909617768 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.4592323467881505) - present_state_Q (0.4592323467881505)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0756556101704486 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.28154045879666) - present_state_Q (0.28154045879666)) * f3(0.20179736173627605)
w4 ( 1.129752472484275 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.28154045879666) - present_state_Q (0.28154045879666)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0866882127877415 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1880375131957568) - present_state_Q (0.1880375131957568)) * f3(0.1328003247003473)
w4 ( 1.1330755374367703 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1880375131957568) - present_state_Q (0.1880375131957568)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0690209680422926 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.14813084445101066) - present_state_Q (-0.1630032319181612)) * f3(-0.15)
w4 ( 1.1330755374367703 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.14813084445101066) - present_state_Q (-0.1630032319181612)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0514196359358599 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.13068995222503182) - present_state_Q (-0.1603531452063439)) * f3(-0.15)
w4 ( 1.1330755374367703 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.13068995222503182) - present_state_Q (-0.1603531452063439)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.051790772912908 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.02665964783570156) - present_state_Q (0.02665964783570156)) * f3(0.0038026083500023733)
w4 ( 1.135027550070666 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.02665964783570156) - present_state_Q (0.02665964783570156)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.034300358924985 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.08258983257923244) - present_state_Q (-0.15776861593693617)) * f3(-0.15)
w4 ( 1.135027550070666 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.08258983257923244) - present_state_Q (-0.15776861593693617)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.016936178853736 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.024669509111851503) - present_state_Q (-0.15514505383874774)) * f3(-0.15)
w4 ( 1.135027550070666 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.024669509111851503) - present_state_Q (-0.15514505383874774)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9694953871304538 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.3418937774258906) - present_state_Q (-0.14808442412376738)) * f3(-0.15)
w4 ( 1.1027342379402343 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.3418937774258906) - present_state_Q (-0.14808442412376738)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9851505419989358 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.2948088993214387) - present_state_Q (0.2948088993214387)) * f3(0.21309040045842065)
w4 ( 1.1086116138651199 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.2948088993214387) - present_state_Q (0.2948088993214387)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9951196280515217 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.15894982051892825) - present_state_Q (0.15894982051892825)) * f3(0.1163328355195152)
w4 ( 1.1120393945112517 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.15894982051892825) - present_state_Q (0.15894982051892825)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0079948801306144 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.20088194604857315) - present_state_Q (0.20088194604857315)) * f3(0.1571674056659503)
w4 ( 1.1153162195054769 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.20088194604857315) - present_state_Q (0.20088194604857315)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0111096194512126 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.09054601028471013) - present_state_Q (0.05522240003566371)) * f3(0.032655002812404126)
w4 ( 1.1172238839074624 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.09054601028471013) - present_state_Q (0.05522240003566371)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7807804655367159 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( 0.8582174814917722) - present_state_Q (0.9502367030645935)) * f3(0.7981463710564667)
w4 ( 1.0649035986615876 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( 0.8582174814917722) - present_state_Q (0.9502367030645935)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6248784105036241 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.5878037421408902) - present_state_Q (0.5878037421408902)) * f3(0.6164516192703053)
w4 ( 1.0396133649823196 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.5878037421408902) - present_state_Q (0.5878037421408902)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5310667904669047 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.43773616635124735) - present_state_Q (0.3573400786980361)) * f3(0.40548487184185505)
w4 ( 1.0164777003616905 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.43773616635124735) - present_state_Q (0.3573400786980361)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.43831859910627746 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.37942804596896273) - present_state_Q (0.3177032924073181)) * f3(0.40683305047411594)
w4 ( 0.9936800954835863 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.37942804596896273) - present_state_Q (0.3177032924073181)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3459850372782403 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.3317073534725176) - present_state_Q (0.27953272749014796)) * f3(0.4110359868578278)
w4 ( 0.9712164755621573 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.3317073534725176) - present_state_Q (0.27953272749014796)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2040481848509408 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.33031187613092505) - present_state_Q (0.33031187613092505)) * f3(0.617847236242058)
w4 ( 0.9436491072999433 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.33031187613092505) - present_state_Q (0.33031187613092505)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.168877065695742 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( 0.21651822169458332) - present_state_Q (0.21651822169458332)) * f3(0.5061565673521546)
w4 ( 0.9353107105056419 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( 0.21651822169458332) - present_state_Q (0.21651822169458332)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.13604016214774647 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( 0.15675773623056155) - present_state_Q (0.09131328528560448)) * f3(0.20840392098400456)
w4 ( 0.9258568854356666 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( 0.15675773623056155) - present_state_Q (0.09131328528560448)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8221077011724305 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.9103106934269966) - present_state_Q (0.6835066205047877)) * f3(0.5685210257506815)
w4 ( 1.0716245313262893 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.9103106934269966) - present_state_Q (0.6835066205047877)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8440357691451776 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.3163150805905325) - present_state_Q (0.3163150805905325)) * f3(0.30655059957660763)
w4 ( 1.0759164298911004 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.3163150805905325) - present_state_Q (0.3163150805905325)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8276405119406645 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.3096676738923252) - present_state_Q (-0.06205037957831061)) * f3(-0.15)
w4 ( 1.0824745327729057 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.3096676738923252) - present_state_Q (-0.06205037957831061)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8478502329992416 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.2917776066128572) - present_state_Q (0.2917776066128572)) * f3(0.2740672204585664)
w4 ( 1.0868989336971964 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.2917776066128572) - present_state_Q (0.2917776066128572)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8627204022625657 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.19666785035490225) - present_state_Q (0.19666785035490225)) * f3(0.1806827279684801)
w4 ( 1.0901909294359187 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.19666785035490225) - present_state_Q (0.19666785035490225)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8517463181776953 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.19199312145183245) - present_state_Q (-0.06548060586636625)) * f3(-0.10117347894656598)
w4 ( 1.0923602892719417 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.19199312145183245) - present_state_Q (-0.06548060586636625)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8416113631930415 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1895692974200716) - present_state_Q (-0.05828701657513077)) * f3(-0.09408226446110875)
w4 ( 1.094514777164576 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1895692974200716) - present_state_Q (-0.05828701657513077)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.845426210371064 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.18764235510271515) - present_state_Q (0.05521090835619516)) * f3(0.03959144834557188)
w4 ( 1.096441883818884 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.18764235510271515) - present_state_Q (0.05521090835619516)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8595493963315214 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.18749776841584437) - present_state_Q (0.18749776841584437)) * f3(0.1699025784876533)
w4 ( 1.0997668918525871 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.18749776841584437) - present_state_Q (0.18749776841584437)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8714952481439119 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1645169181979707) - present_state_Q (0.1645169181979707)) * f3(0.14022026312654312)
w4 ( 1.1031746309470745 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.1645169181979707) - present_state_Q (0.1645169181979707)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.854155723863896 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.25243998112804156) - present_state_Q (-0.13072428722158677)) * f3(-0.15)
w4 ( 1.1031746309470745 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.25243998112804156) - present_state_Q (-0.13072428722158677)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8548045584417382 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.02774749546279635) - present_state_Q (0.02774749546279635)) * f3(0.00665452760550788)
w4 ( 1.1051246854552415 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.02774749546279635) - present_state_Q (0.02774749546279635)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8541092826222201 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.016072014556267857) - present_state_Q (0.016072014556267857)) * f3(-0.007054804625551136)
w4 ( 1.1070957558290402 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.016072014556267857) - present_state_Q (0.016072014556267857)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.850288136573211 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.010198024831001448) - present_state_Q (-0.010198024831001448)) * f3(-0.03786393685863556)
w4 ( 1.109114112273736 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.010198024831001448) - present_state_Q (-0.010198024831001448)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8452912983281741 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.019569865056178457) - present_state_Q (-0.019569865056178457)) * f3(-0.04910352797572903)
w4 ( 1.111149338030837 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.019569865056178457) - present_state_Q (-0.019569865056178457)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8272473437888422 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.7613660787289827) - present_state_Q (-0.1267936947492261)) * f3(-0.15)
w4 ( 1.111149338030837 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.7613660787289827) - present_state_Q (-0.1267936947492261)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8372887313897709 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.18898302158007274) - present_state_Q (0.18898302158007274)) * f3(0.12099292344558361)
w4 ( 1.1177886602754605 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.18898302158007274) - present_state_Q (0.18898302158007274)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.830350702947645 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.08638121610197544) - present_state_Q (-0.03339242944344267)) * f3(-0.06658181408511066)
w4 ( 1.1198727213775679 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.08638121610197544) - present_state_Q (-0.03339242944344267)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8228498813093925 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.0951755553708041) - present_state_Q (-0.03711088925450915)) * f3(-0.0716665180998981)
w4 ( 1.1219659782671512 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.0951755553708041) - present_state_Q (-0.03711088925450915)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.829766317518057 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.10791244519220336) - present_state_Q (0.10791244519220336)) * f3(0.076604259772405)
w4 ( 1.1255774934644593 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.10791244519220336) - present_state_Q (0.10791244519220336)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8224401642365479 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.10270832911094768) - present_state_Q (-0.035611573646833976)) * f3(-0.07004758121536829)
w4 ( 1.1276692582775751 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.10270832911094768) - present_state_Q (-0.035611573646833976)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8218851528483186 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.017913949032482737) - present_state_Q (0.017913949032482737)) * f3(-0.0056410622131707845)
w4 ( 1.1296370131693168 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.017913949032482737) - present_state_Q (0.017913949032482737)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8048284701320683 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.13829408156108824) - present_state_Q (-0.12328277292724779)) * f3(-0.15)
w4 ( 1.1296370131693168 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.13829408156108824) - present_state_Q (-0.12328277292724779)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7882836821750854 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.048543335424387095) - present_state_Q (-0.09813153025642389)) * f3(-0.15)
w4 ( 1.1318429848969145 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.048543335424387095) - present_state_Q (-0.09813153025642389)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7894212917605489 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.03186925710915568) - present_state_Q (0.03186925710915568)) * f3(0.011712024008593886)
w4 ( 1.133785620234118 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.03186925710915568) - present_state_Q (0.03186925710915568)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7724619773878185 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.12207764417941663) - present_state_Q (-0.11841319376408233)) * f3(-0.15)
w4 ( 1.133785620234118 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.12207764417941663) - present_state_Q (-0.11841319376408233)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7781162468696451 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.06925618108766712) - present_state_Q (0.06925618108766712)) * f3(0.06030130938030469)
w4 ( 1.1356609591081603 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.06925618108766712) - present_state_Q (0.06925618108766712)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7813011828365461 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( 0.08070184895863931) - present_state_Q (0.08070184895863931)) * f3(0.07452437859993781)
w4 ( 1.1365156957800349 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( 0.08070184895863931) - present_state_Q (0.08070184895863931)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7851108554305647 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( 0.1937810655534885) - present_state_Q (0.09244922585873162)) * f3(0.0892343611845224)
w4 ( 1.137369553541428 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( 0.1937810655534885) - present_state_Q (0.09244922585873162)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7841536898116117 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.015128846076891142) - present_state_Q (0.015128846076891142)) * f3(-0.009703782518405398)
w4 ( 1.1393423216184897 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.015128846076891142) - present_state_Q (0.015128846076891142)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7860859655005854 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.03848246292665661) - present_state_Q (0.03848246292665661)) * f3(0.02001599520376878)
w4 ( 1.1412730531852218 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( 0.03848246292665661) - present_state_Q (0.03848246292665661)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.781637259239445 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.011778375230026047) - present_state_Q (-0.011778375230026047)) * f3(-0.04402042246320287)
w4 ( 1.143294254260636 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.011778375230026047) - present_state_Q (-0.011778375230026047)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7723446950072207 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( 0.02258693262373253) - present_state_Q (-0.11724558888591675)) * f3(-0.15)
w4 ( 1.143294254260636 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( 0.02258693262373253) - present_state_Q (-0.11724558888591675)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7769442245297649 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.766116139269021) - present_state_Q (1.1108760160675097)) * f3(1.0775801632212298)
w4 ( 1.099732578792306 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.766116139269021) - present_state_Q (1.1108760160675097)) * f4(0.18)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7793096803157186 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2939082764821307) - present_state_Q (0.3159029280579768)) * f3(0.20843242270713347)
w4 ( 1.1013214093865693 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2939082764821307) - present_state_Q (0.3159029280579768)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7821965861861433 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09319423724601635) - present_state_Q (0.09319423724601635)) * f3(0.09132160276701944)
w4 ( 1.1019536597595265 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09319423724601635) - present_state_Q (0.09319423724601635)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7854649080931856 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.10595723680061642) - present_state_Q (0.10595723680061642)) * f3(0.10728525934202358)
w4 ( 1.1025629367332854 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.10595723680061642) - present_state_Q (0.10595723680061642)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7896627300438059 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1439843065619424) - present_state_Q (0.1439843065619424)) * f3(0.15523678597339813)
w4 ( 1.1031037649814739 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1439843065619424) - present_state_Q (0.1439843065619424)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7940273376008834 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.15383967576907281) - present_state_Q (0.15383967576907281)) * f3(0.16687833356670267)
w4 ( 1.1036268535650895 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.15383967576907281) - present_state_Q (0.15383967576907281)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7985751311928968 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.16635198922352903) - present_state_Q (0.16635198922352903)) * f3(0.18170590018746818)
w4 ( 1.104127419984487 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.16635198922352903) - present_state_Q (0.16635198922352903)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8032763686076855 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17956950054389154) - present_state_Q (0.17956950054389154)) * f3(0.19720993804171025)
w4 ( 1.1046041948835081 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17956950054389154) - present_state_Q (0.17956950054389154)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8034012898753796 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18814054753122997) - present_state_Q (0.0024098291058230565)) * f3(0.003)
w4 ( 1.1046041948835081 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18814054753122997) - present_state_Q (0.0024098291058230565)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8035257328842773 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17220233528430232) - present_state_Q (0.002410203869626139)) * f3(0.003)
w4 ( 1.1046041948835081 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17220233528430232) - present_state_Q (0.002410203869626139)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8036497907868018 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.15936918946890652) - present_state_Q (0.002410577198652832)) * f3(0.003)
w4 ( 1.1046041948835081 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.15936918946890652) - present_state_Q (0.002410577198652832)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8487760810427587 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.36867742634464673) - present_state_Q (0.1455666579178877)) * f3(0.11962820934824688)
w4 ( 1.1123145423697034 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.36867742634464673) - present_state_Q (0.1455666579178877)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8529411682293458 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2711158398477563) - present_state_Q (0.2711158398477563)) * f3(0.2670000524455773)
w4 ( 1.1129385253462514 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2711158398477563) - present_state_Q (0.2711158398477563)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8566568470395025 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.27669011917491126) - present_state_Q (0.27669011917491126)) * f3(0.24610584583448414)
w4 ( 1.113844398702707 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.27669011917491126) - present_state_Q (0.27669011917491126)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8607549880143696 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2756496007634867) - present_state_Q (0.2756496007634867)) * f3(0.2697647554140451)
w4 ( 1.1144520601399583 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2756496007634867) - present_state_Q (0.2756496007634867)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8590334245807506 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.28945878523836305) - present_state_Q (0.28945878523836305)) * f3(0.28449524689675876)
w4 ( 1.1142100085131001 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.28945878523836305) - present_state_Q (0.28945878523836305)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8404917645285902 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.3085390972330234) - present_state_Q (0.0992888262512966)) * f3(0.08964101265165153)
w4 ( 1.1100731386800442 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.3085390972330234) - present_state_Q (0.0992888262512966)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7634547978560164 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.21998825581986584) - present_state_Q (0.325493004463724)) * f3(0.3344352565717027)
w4 ( 1.1008591619645172 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.21998825581986584) - present_state_Q (0.325493004463724)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7111623222554582 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.22527587135257235) - present_state_Q (0.22527587135257235)) * f3(0.23739651041943266)
w4 ( 1.092048168827648 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.22527587135257235) - present_state_Q (0.22527587135257235)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6591265660467198 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.21255807742273264) - present_state_Q (0.21255807742273264)) * f3(0.23746498567870467)
w4 ( 1.0832829597489262 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.21255807742273264) - present_state_Q (0.21255807742273264)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6527547895486728 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.16411754767913253) - present_state_Q (0.16411754767913253)) * f3(0.18325195115958046)
w4 ( 1.0818921365772813 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.16411754767913253) - present_state_Q (0.16411754767913253)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6550117581641527 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06474989698276928) - present_state_Q (0.06474989698276928)) * f3(0.06604632388991304)
w4 ( 1.0825755867627123 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06474989698276928) - present_state_Q (0.06474989698276928)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6607335263041292 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.8273264809038307) - present_state_Q (0.15911237559352942)) * f3(0.17680499728372498)
w4 ( 1.0838700678526996 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.8273264809038307) - present_state_Q (0.15911237559352942)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6308471722540211 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.7965524262700565) - present_state_Q (0.7965524262700565)) * f3(0.9430930785352678)
w4 ( 1.0787997129144107 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.7965524262700565) - present_state_Q (0.7965524262700565)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6133028819964372 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.6778669936979864) - present_state_Q (0.6778669936979864)) * f3(0.8351230806148878)
w4 ( 1.0758585887938161 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.6778669936979864) - present_state_Q (0.6778669936979864)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6124297547008344 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4612672287770676) - present_state_Q (0.4612672287770676)) * f3(0.5766830391312927)
w4 ( 1.0757071837348224 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4612672287770676) - present_state_Q (0.4612672287770676)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6144706430126926 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4002419182844804) - present_state_Q (0.4002419182844804)) * f3(0.5130144986818462)
w4 ( 1.0760254419231743 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4002419182844804) - present_state_Q (0.4002419182844804)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5913810724954803 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.34331199135548074) - present_state_Q (0.34331199135548074)) * f3(0.4536432586484564)
w4 ( 1.0729715571698546 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.34331199135548074) - present_state_Q (0.34331199135548074)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.461647414873147 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.3906366342713581) - present_state_Q (0.3906366342713581)) * f3(0.5516888450021543)
w4 ( 1.0588621193447894 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.3906366342713581) - present_state_Q (0.3906366342713581)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.46719358374293735 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.13398978438839054) - present_state_Q (0.13398978438839054)) * f3(0.19849629102716584)
w4 ( 1.0599797561209912 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.13398978438839054) - present_state_Q (0.13398978438839054)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4734286740209858 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.15373628509213833) - present_state_Q (0.15373628509213833)) * f3(0.23831041076231774)
w4 ( 1.0610263054946594 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.15373628509213833) - present_state_Q (0.15373628509213833)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.47176011992576283 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.1175238459148357) - present_state_Q (0.10549108980468799)) * f3(0.1780005485917385)
w4 ( 1.060838828084233 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.1175238459148357) - present_state_Q (0.10549108980468799)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4732163563965563 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04009466470382421) - present_state_Q (0.04009466470382421)) * f3(0.04001586260642425)
w4 ( 1.061566657687766 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04009466470382421) - present_state_Q (0.04009466470382421)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4733302406313561 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.022650982222944992) - present_state_Q (0.022650982222944992)) * f3(0.003)
w4 ( 1.0623258859197648 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.022650982222944992) - present_state_Q (0.022650982222944992)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.48127317186520285 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.7594507612841197) - present_state_Q (0.16240029534546901)) * f3(0.25332685219676426)
w4 ( 1.0635800650428966 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.7594507612841197) - present_state_Q (0.16240029534546901)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.48020206768550844 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2444188587022394) - present_state_Q (0.2444188587022394)) * f3(0.381719336812397)
w4 ( 1.0634060240827727 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2444188587022394) - present_state_Q (0.2444188587022394)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.48776760550276277 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.24749407370521395) - present_state_Q (0.24749407370521395)) * f3(0.42681580637452193)
w4 ( 1.064115045417434 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.24749407370521395) - present_state_Q (0.24749407370521395)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.49399011146467586 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3040443669427304) - present_state_Q (0.3040443669427304)) * f3(0.4924424285415647)
w4 ( 1.0648732058359431 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3040443669427304) - present_state_Q (0.3040443669427304)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5001936252692132 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3005930852327424) - present_state_Q (0.3005930852327424)) * f3(0.47916079166194353)
w4 ( 1.0656500031756864 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3005930852327424) - present_state_Q (0.3005930852327424)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5071185707076521 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2002028074604329) - present_state_Q (0.2002028074604329)) * f3(0.3150316185029243)
w4 ( 1.0665292730688287 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2002028074604329) - present_state_Q (0.2002028074604329)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5139764542120001 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.20213214804561552) - present_state_Q (0.20213214804561552)) * f3(0.3144648733733625)
w4 ( 1.0674015973358646 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.20213214804561552) - present_state_Q (0.20213214804561552)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5141029568142466 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2321727018416061) - present_state_Q (0.0015419293626360003)) * f3(0.003)
w4 ( 1.0674015973358646 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2321727018416061) - present_state_Q (0.0015419293626360003)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5192628865831033 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.10929280557887226) - present_state_Q (0.10929280557887226)) * f3(0.17106451629285377)
w4 ( 1.0680048702858227 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.10929280557887226) - present_state_Q (0.10929280557887226)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5243251879884002 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.10823190709895411) - present_state_Q (0.10823190709895411)) * f3(0.16729832217526414)
w4 ( 1.0686100528530447 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.10823190709895411) - present_state_Q (0.10823190709895411)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5299914180162626 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12457085381613585) - present_state_Q (0.12457085381613585)) * f3(0.19682184858408527)
w4 ( 1.0691858253161757 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12457085381613585) - present_state_Q (0.12457085381613585)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5301145543507408 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1204442251500944) - present_state_Q (0.0015899742540487877)) * f3(0.003)
w4 ( 1.0691858253161757 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1204442251500944) - present_state_Q (0.0015899742540487877)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.535228395846741 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11198541768395556) - present_state_Q (0.11198541768395556)) * f3(0.17090966553181455)
w4 ( 1.0697842515643445 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11198541768395556) - present_state_Q (0.11198541768395556)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5353510433737172 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.10430775108215389) - present_state_Q (0.001605685187540223)) * f3(0.003)
w4 ( 1.0697842515643445 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.10430775108215389) - present_state_Q (0.001605685187540223)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5354734340302806 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09574908341380478) - present_state_Q (0.0016060531301211516)) * f3(0.003)
w4 ( 1.0697842515643445 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09574908341380478) - present_state_Q (0.0016060531301211516)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5394233919306366 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08717549488498592) - present_state_Q (0.08717549488498592)) * f3(0.1228442078976774)
w4 ( 1.0704273356735516 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08717549488498592) - present_state_Q (0.08717549488498592)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5425097543585997 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07093439176987029) - present_state_Q (0.07093439176987029)) * f3(0.09181256467047631)
w4 ( 1.071099653768366 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07093439176987029) - present_state_Q (0.07093439176987029)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5451887858498172 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0638530550987188) - present_state_Q (0.0638530550987188)) * f3(0.07821253292213524)
w4 ( 1.0717847182691882 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0638530550987188) - present_state_Q (0.0638530550987188)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5453025566094221 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.023071260722933216) - present_state_Q (0.023071260722933216)) * f3(0.003)
w4 ( 1.072543189999887 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.023071260722933216) - present_state_Q (0.023071260722933216)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5491314563112757 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.21003310166346065) - present_state_Q (0.2529348292634561)) * f3(0.22781783242665102)
w4 ( 1.0745600117707217 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.21003310166346065) - present_state_Q (0.2529348292634561)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5530027849669993 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.15584441380836103) - present_state_Q (0.08599089608576405)) * f3(0.11745765992649289)
w4 ( 1.0752191988613118 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.15584441380836103) - present_state_Q (0.08599089608576405)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5577863756248557 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1393475109562883) - present_state_Q (0.1393475109562883)) * f3(0.1742102311611051)
w4 ( 1.0763175478218692 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1393475109562883) - present_state_Q (0.1393475109562883)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5579096937029309 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1273361937751225) - present_state_Q (0.001673359126874567)) * f3(0.003)
w4 ( 1.0763175478218692 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1273361937751225) - present_state_Q (0.001673359126874567)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5606269214386227 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09066445493930006) - present_state_Q (0.09066445493930006)) * f3(0.08533953355500762)
w4 ( 1.0775911557840876 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09066445493930006) - present_state_Q (0.09066445493930006)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3626309350737709 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.42627801323817605) - present_state_Q (0.568730453891204)) * f3(0.7838002393276454)
w4 ( 1.047277923953279 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.42627801323817605) - present_state_Q (0.568730453891204)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1975267048104261 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.37975112294194624) - present_state_Q (0.3623145324623236)) * f3(0.7103275400776112)
w4 ( 1.0240345297515978 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.37975112294194624) - present_state_Q (0.3623145324623236)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1194482671893774 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.29116743551444924) - present_state_Q (0.17429751750929942)) * f3(0.36397136581172196)
w4 ( 1.0025827220120194 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.29116743551444924) - present_state_Q (0.17429751750929942)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.04015109089606783 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.20327671851575052) - present_state_Q (0.18889914066604194)) * f3(0.7420858464552332)
w4 ( 0.9918970073238746 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.20327671851575052) - present_state_Q (0.18889914066604194)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.04027750640192326 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.21505472790798644) - present_state_Q (0.0001204532726882035)) * f3(0.003)
w4 ( 0.9918970073238746 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.21505472790798644) - present_state_Q (0.0001204532726882035)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.054848419207194056 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.14234443508774733) - present_state_Q (0.18421824772370834)) * f3(0.6334733411070872)
w4 ( 0.9955772664564357 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.14234443508774733) - present_state_Q (0.18421824772370834)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.05497466864576926 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.20996007174980344) - present_state_Q (0.00016454525762158218)) * f3(0.003)
w4 ( 0.9955772664564357 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.20996007174980344) - present_state_Q (0.00016454525762158218)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.06597747256325188 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0738773645716446) - present_state_Q (0.05709058774649614)) * f3(0.3140991571864178)
w4 ( 0.9969784550512785 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0738773645716446) - present_state_Q (0.05709058774649614)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.07649655610623528 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07865064293135474) - present_state_Q (0.05981971634630383)) * f3(0.302233131545557)
w4 ( 0.9983706364430658 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07865064293135474) - present_state_Q (0.05981971634630383)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.08842983381895927 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06679243274975183) - present_state_Q (0.06679243274975183)) * f3(0.35109563958317885)
w4 ( 0.9997301836851666 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06679243274975183) - present_state_Q (0.06679243274975183)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.0884866284018859 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.09575169597227845) - present_state_Q (0.02025989317516021)) * f3(0.003)
w4 ( 1.0001088142380108 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.09575169597227845) - present_state_Q (0.02025989317516021)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.08860938162316215 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09442864139367382) - present_state_Q (0.0002654598852056577)) * f3(0.003)
w4 ( 1.0001088142380108 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09442864139367382) - present_state_Q (0.0002654598852056577)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.0941923863836843 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06640522260038145) - present_state_Q (0.03325126111133257)) * f3(0.14952237092589185)
w4 ( 1.0008555927603082 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06640522260038145) - present_state_Q (0.03325126111133257)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09882789913690684 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06416784454164871) - present_state_Q (0.03166839634893501)) * f3(0.12369666956168168)
w4 ( 1.0016050895365187 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06416784454164871) - present_state_Q (0.03166839634893501)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10287001475394762 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05999252267763362) - present_state_Q (0.030675548788549577)) * f3(0.10769678492380756)
w4 ( 1.0023557369434772 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05999252267763362) - present_state_Q (0.030675548788549577)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10299134379075765 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.047387327443760965) - present_state_Q (0.00030861004426184285)) * f3(0.003)
w4 ( 1.0023557369434772 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.047387327443760965) - present_state_Q (0.00030861004426184285)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10616765613652232 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.028791937540388418) - present_state_Q (0.028791937540388418)) * f3(0.08490832801720977)
w4 ( 1.0031039114559046 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.028791937540388418) - present_state_Q (0.028791937540388418)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10628848249923487 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.03073045343550724) - present_state_Q (0.00031850296840956697)) * f3(0.003)
w4 ( 1.0031039114559046 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.03073045343550724) - present_state_Q (0.00031850296840956697)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1105436269454493 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.032253650476784634) - present_state_Q (0.032253650476784634)) * f3(0.11470266543465144)
w4 ( 1.0038458548850464 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.032253650476784634) - present_state_Q (0.032253650476784634)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1153315934189218 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.03441965926017223) - present_state_Q (0.03441965926017223)) * f3(0.12974734553941417)
w4 ( 1.004583899498378 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.03441965926017223) - present_state_Q (0.03441965926017223)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.12061295973360048 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.03668956911849889) - present_state_Q (0.03668956911849889)) * f3(0.14391452191458412)
w4 ( 1.0053178582739648 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.03668956911849889) - present_state_Q (0.03668956911849889)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1263341278837243 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.03901776466489178) - present_state_Q (0.03901776466489178)) * f3(0.1567941582826785)
w4 ( 1.006047626297568 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.03901776466489178) - present_state_Q (0.03901776466489178)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.13148557468394992 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.03790817336203603) - present_state_Q (0.03790817336203603)) * f3(0.14079505778878465)
w4 ( 1.0067793915855163 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.03790817336203603) - present_state_Q (0.03790817336203603)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.13160655069745453 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.036478350727786796) - present_state_Q (0.0003944567240518498)) * f3(0.003)
w4 ( 1.0067793915855163 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.036478350727786796) - present_state_Q (0.0003944567240518498)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.13645792700251846 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.037571352167742336) - present_state_Q (0.037571352167742336)) * f3(0.1324840157547663)
w4 ( 1.0075117631516144 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.037571352167742336) - present_state_Q (0.037571352167742336)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.13657852586321662 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.024055761082068132) - present_state_Q (0.0004093737810075554)) * f3(0.003)
w4 ( 1.0075117631516144 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.024055761082068132) - present_state_Q (0.0004093737810075554)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.13669901974166856 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.02055997084062194) - present_state_Q (0.0004097355775896499)) * f3(0.003)
w4 ( 1.0075117631516144 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.02055997084062194) - present_state_Q (0.0004097355775896499)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.15184871397742147 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.29387061922611923) - present_state_Q (0.29387061922611923)) * f3(1.1179229571191354)
w4 ( 1.0094089933493653 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.29387061922611923) - present_state_Q (0.29387061922611923)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1673083594851923 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2898273446912853) - present_state_Q (0.2898273446912853)) * f3(1.1109627541162144)
w4 ( 1.0110788580266994 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2898273446912853) - present_state_Q (0.2898273446912853)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.18090755367470596 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3115255413335729) - present_state_Q (0.3115255413335729)) * f3(1.1367996133343377)
w4 ( 1.0125143821802969 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3115255413335729) - present_state_Q (0.3115255413335729)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1922166007478489 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3407733108381873) - present_state_Q (0.3407733108381873)) * f3(1.2120642865517322)
w4 ( 1.0136340304232445 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3407733108381873) - present_state_Q (0.3407733108381873)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.19234879736762373 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4123204905162648) - present_state_Q (0.0005766498022435467)) * f3(0.003)
w4 ( 1.0136340304232445 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4123204905162648) - present_state_Q (0.0005766498022435467)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10575425644109923 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.32594405538790006) - present_state_Q (0.12032738307987964)) * f3(0.41477785645037163)
w4 ( 1.00528309851308 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.32594405538790006) - present_state_Q (0.12032738307987964)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10792600553053527 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.10693713936195628) - present_state_Q (0.02607710746337693)) * f3(0.056465296944725615)
w4 ( 1.0060523317260257 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.10693713936195628) - present_state_Q (0.02607710746337693)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.11507255421642888 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0626910983637531) - present_state_Q (0.0626910983637531)) * f3(0.2080036686650153)
w4 ( 1.0074266437719162 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0626910983637531) - present_state_Q (0.0626910983637531)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.12237325148189654 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06489055427822685) - present_state_Q (0.06489055427822685)) * f3(0.2137215836983567)
w4 ( 1.0087930377765146 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06489055427822685) - present_state_Q (0.06489055427822685)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1289715634861009 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04582724392415599) - present_state_Q (0.04247464207752077)) * f3(0.1822194070351173)
w4 ( 1.0095172539411443 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04582724392415599) - present_state_Q (0.04247464207752077)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.13608382739534317 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04575403429002675) - present_state_Q (0.04575403429002675)) * f3(0.19821182685715702)
w4 ( 1.0102348966794223 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04575403429002675) - present_state_Q (0.04575403429002675)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1437005948599639 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04935472583723351) - present_state_Q (0.04935472583723351)) * f3(0.21420640837033497)
w4 ( 1.0109460581729153 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04935472583723351) - present_state_Q (0.04935472583723351)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.14888208607400497 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04071050678647907) - present_state_Q (0.04071050678647907)) * f3(0.14259917046961285)
w4 ( 1.0116727792606997 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04071050678647907) - present_state_Q (0.04071050678647907)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.15457938271515945 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04375471419040643) - present_state_Q (0.04375471419040643)) * f3(0.15798582103088415)
w4 ( 1.012394020775157 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04375471419040643) - present_state_Q (0.04375471419040643)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.16141333496834606 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05000572410979229) - present_state_Q (0.05000572410979229)) * f3(0.19250849092290254)
w4 ( 1.0131040104717592 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05000572410979229) - present_state_Q (0.05000572410979229)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1681472947829941 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05095470338819236) - present_state_Q (0.05095470338819236)) * f3(0.19014924129271066)
w4 ( 1.0138122920056605 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05095470338819236) - present_state_Q (0.05095470338819236)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.17511620319269805 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05358777798156737) - present_state_Q (0.05358777798156737)) * f3(0.19810923621724058)
w4 ( 1.0145158340052935 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05358777798156737) - present_state_Q (0.05358777798156737)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.18226769648871674 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05612389560522532) - present_state_Q (0.05612389560522532)) * f3(0.20462743179560686)
w4 ( 1.0152148109932042 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05612389560522532) - present_state_Q (0.05612389560522532)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.18986090249460147 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06033954496878642) - present_state_Q (0.06033954496878642)) * f3(0.21965081865946945)
w4 ( 1.0159061998122605 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06033954496878642) - present_state_Q (0.06033954496878642)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.189982653338292 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06405728342645453) - present_state_Q (0.0005695827074838044)) * f3(0.003)
w4 ( 1.0159061998122605 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06405728342645453) - present_state_Q (0.0005695827074838044)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.10635925477532976 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.4383051428324133) - present_state_Q (0.4383051428324133)) * f3(1.2376072169667434)
w4 ( 0.9680167072412771 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.4383051428324133) - present_state_Q (0.4383051428324133)) * f4(0.2)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.1065548573234619 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.08078530589844021) - present_state_Q (0.012658689529581185)) * f3(0.4270649789794431)
w4 ( 0.9679892262876386 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.08078530589844021) - present_state_Q (0.012658689529581185)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.10643420086867561 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.01868518049015052) - present_state_Q (-0.0003196645719703857)) * f3(0.003)
w4 ( 0.9679892262876386 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.01868518049015052) - present_state_Q (-0.0003196645719703857)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.10631352317513025 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.019396758819169788) - present_state_Q (-0.00031930260260602686)) * f3(0.003)
w4 ( 0.9679892262876386 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.019396758819169788) - present_state_Q (-0.00031930260260602686)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.11924995222022862 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.012272079639564532) - present_state_Q (0.012272079639564532)) * f3(0.6129705470873811)
w4 ( 0.9663008673142337 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.012272079639564532) - present_state_Q (0.012272079639564532)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.11931949660797353 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.010770916510183633) - present_state_Q (0.010770916510183633)) * f3(0.0717409162588312)
w4 ( 0.9662814796645154 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.010770916510183633) - present_state_Q (0.010770916510183633)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.11827258461535387 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.004919748309322465) - present_state_Q (0.012674645244441701)) * f3(0.05574096889379734)
w4 ( 0.9666571143236884 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.004919748309322465) - present_state_Q (0.012674645244441701)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.11912333440986378 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.005597239478686726) - present_state_Q (0.014632861904826835)) * f3(0.039741081138398957)
w4 ( 0.9662289680477745 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.005597239478686726) - present_state_Q (0.014632861904826835)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.11918872907621819 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.009849881763681137) - present_state_Q (0.018967209357725896)) * f3(0.003)
w4 ( 0.9657930036054118 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.009849881763681137) - present_state_Q (0.018967209357725896)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.11924899578434424 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.012862240779806543) - present_state_Q (0.007229264080352899)) * f3(0.10140720591144373)
w4 ( 0.965781117525407 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.012862240779806543) - present_state_Q (0.007229264080352899)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.11582554265856194 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.017169925938069715) - present_state_Q (0.008922320794401575)) * f3(0.08715630255622718)
w4 ( 0.9665667068690058 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.017169925938069715) - present_state_Q (0.008922320794401575)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.112525883673087 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.01729651410561812) - present_state_Q (0.009585310723869062)) * f3(0.08414399095233265)
w4 ( 0.9673509955503792 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.01729651410561812) - present_state_Q (0.009585310723869062)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.11252496529096716 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.027236960817955312) - present_state_Q (-0.000337577651019261)) * f3(0.003)
w4 ( 0.9673509955503792 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.027236960817955312) - present_state_Q (-0.000337577651019261)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.12450892914959161 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.02036004189521537) - present_state_Q (0.00440304415034069)) * f3(0.13280586865345614)
w4 ( 0.9655462614704575 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.02036004189521537) - present_state_Q (0.00440304415034069)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.12510808507560447 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.024400531696475256) - present_state_Q (-0.0003735267874487748)) * f3(0.003)
w4 ( 0.9655462614704575 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.024400531696475256) - present_state_Q (-0.0003735267874487748)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.1506092150511337 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.003289205241754009) - present_state_Q (0.003289205241754009)) * f3(0.28241696126762955)
w4 ( 0.9619344203315872 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.003289205241754009) - present_state_Q (0.003289205241754009)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.1508790930576695 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( -0.0004518276451534011) - present_state_Q (-0.0004518276451534011)) * f3(0.003)
w4 ( 0.9619344203315872 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( -0.0004518276451534011) - present_state_Q (-0.0004518276451534011)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.15114897084560414 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( -0.00045263727917300853) - present_state_Q (-0.00045263727917300853)) * f3(0.003)
w4 ( 0.9619344203315872 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( -0.00045263727917300853) - present_state_Q (-0.00045263727917300853)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.15141884841493775 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( -0.0004534469125368124) - present_state_Q (-0.0004534469125368124)) * f3(0.003)
w4 ( 0.9619344203315872 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( -0.0004534469125368124) - present_state_Q (-0.0004534469125368124)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.15201859327755612 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.003962013935045522) - present_state_Q (-0.00045425654524481327)) * f3(0.003)
w4 ( 0.9619344203315872 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.003962013935045522) - present_state_Q (-0.00045425654524481327)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.15261847014249558 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0004560557798326684) - present_state_Q (-0.0004560557798326684)) * f3(0.003)
w4 ( 0.9619344203315872 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0004560557798326684) - present_state_Q (-0.0004560557798326684)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.1532185112638977 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0059492675084091284) - present_state_Q (-0.0004578554104274867)) * f3(0.003)
w4 ( 0.9619344203315872 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0059492675084091284) - present_state_Q (-0.0004578554104274867)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.15381841625463613 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0014295799517397914) - present_state_Q (-0.00045965553379169314)) * f3(0.003)
w4 ( 0.9619344203315872 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0014295799517397914) - present_state_Q (-0.00045965553379169314)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.17647402517202018 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.0018287663980122333) - present_state_Q (0.0018287663980122333)) * f3(0.11318489965335843)
w4 ( 0.9579311285520707 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.0018287663980122333) - present_state_Q (0.0018287663980122333)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.19594011635484232 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.0019977526722145117) - present_state_Q (0.0019977526722145117)) * f3(0.0972430355237783)
w4 ( 0.9539275325972607 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.0019977526722145117) - present_state_Q (0.0019977526722145117)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.20330298245855272 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.0030982748151524575) - present_state_Q (0.0030982748151524575)) * f3(0.0815569375688892)
w4 ( 0.9521219557025934 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.0030982748151524575) - present_state_Q (0.0030982748151524575)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.205969660582029 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.010421109179745789) - present_state_Q (0.005642971424308307)) * f3(0.0659088594161441)
w4 ( 0.9513127539815808 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.010421109179745789) - present_state_Q (0.005642971424308307)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.20591463083547543 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01840834609788553) - present_state_Q (0.01840834609788553)) * f3(0.003)
w4 ( 0.9516796189586045 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01840834609788553) - present_state_Q (0.01840834609788553)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.20579365514718473 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.026345504098459566) - present_state_Q (-0.0006177438925064263)) * f3(0.003)
w4 ( 0.9516796189586045 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.026345504098459566) - present_state_Q (-0.0006177438925064263)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.20567348845432407 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0006173809654415542) - present_state_Q (-0.0006173809654415542)) * f3(0.003)
w4 ( 0.9516796189586045 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0006173809654415542) - present_state_Q (-0.0006173809654415542)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.19912931452437455 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.013615304172214772) - present_state_Q (-0.013615304172214772)) * f3(0.15874139538717225)
w4 ( 0.9525041265061145 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.013615304172214772) - present_state_Q (-0.013615304172214772)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.19900915322962978 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0005973879435731236) - present_state_Q (-0.0005973879435731236)) * f3(0.003)
w4 ( 0.9525041265061145 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0005973879435731236) - present_state_Q (-0.0005973879435731236)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.19888899203221566 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0005970274596888894) - present_state_Q (-0.0005970274596888894)) * f3(0.003)
w4 ( 0.9525041265061145 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0005970274596888894) - present_state_Q (-0.0005970274596888894)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.19876883093213213 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.000596666976096647) - present_state_Q (-0.000596666976096647)) * f3(0.003)
w4 ( 0.9525041265061145 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.000596666976096647) - present_state_Q (-0.000596666976096647)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.19864866992937907 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0005963064927963964) - present_state_Q (-0.0005963064927963964)) * f3(0.003)
w4 ( 0.9525041265061145 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0005963064927963964) - present_state_Q (-0.0005963064927963964)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.19852850902395644 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0005959460097881372) - present_state_Q (-0.0005959460097881372)) * f3(0.003)
w4 ( 0.9525041265061145 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0005959460097881372) - present_state_Q (-0.0005959460097881372)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.19840834821586414 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0005955855270718694) - present_state_Q (-0.0005955855270718694)) * f3(0.003)
w4 ( 0.9525041265061145 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0005955855270718694) - present_state_Q (-0.0005955855270718694)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.17978298071827276 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0005952250446475925) - present_state_Q (-0.029001855323433634)) * f3(0.43421611887050643)
w4 ( 0.9550777805030283 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0005952250446475925) - present_state_Q (-0.029001855323433634)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.17036315180671477 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.016096812650069944) - present_state_Q (-0.003591552257433815)) * f3(0.23247285872431322)
w4 ( 0.956698585437118 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.016096812650069944) - present_state_Q (-0.003591552257433815)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.15788787428436946 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.007259589139371497) - present_state_Q (0.0038504255595384063)) * f3(0.3143372789172475)
w4 ( 0.9590798386372444 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.007259589139371497) - present_state_Q (0.0038504255595384063)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.1515320716975446 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.025762326632784736) - present_state_Q (-0.009054501435306582)) * f3(0.3003251212021074)
w4 ( 0.9599263615736388 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.025762326632784736) - present_state_Q (-0.009054501435306582)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.1489951547854111 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.009380699639526017) - present_state_Q (0.009380699639526017)) * f3(0.06479042675231797)
w4 ( 0.9607094763142876 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.009380699639526017) - present_state_Q (0.009380699639526017)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.13989719809506238 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.011538409564335453) - present_state_Q (0.004273234106847039)) * f3(0.22923661507594728)
w4 ( 0.962296998741686 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.011538409564335453) - present_state_Q (0.004273234106847039)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.13150792721234364 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.018826248380548534) - present_state_Q (0.008646326629689751)) * f3(0.2133391785280586)
w4 ( 0.9638699439345194 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.018826248380548534) - present_state_Q (0.008646326629689751)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.1278006144049546 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01270013682469975) - present_state_Q (0.01270013682469975)) * f3(0.19660153939567415)
w4 ( 0.9646242234419505 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01270013682469975) - present_state_Q (0.01270013682469975)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.12779989884541154 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.020017966336500083) - present_state_Q (-0.00038340184321486383)) * f3(0.003)
w4 ( 0.9646242234419505 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.020017966336500083) - present_state_Q (-0.00038340184321486383)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.13354858288968072 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0009652570784695891) - present_state_Q (0.0009652570784695891)) * f3(0.14340564864247882)
w4 ( 0.9638224859792093 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0009652570784695891) - present_state_Q (0.0009652570784695891)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.14689228354856865 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( -0.00040064574866904216) - present_state_Q (-0.0005347996753558605)) * f3(0.14834488667921955)
w4 ( 0.9620234754494102 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( -0.00040064574866904216) - present_state_Q (-0.0005347996753558605)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.14749216456581898 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0004406768506457059) - present_state_Q (-0.0004406768506457059)) * f3(0.003)
w4 ( 0.9620234754494102 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0004406768506457059) - present_state_Q (-0.0004406768506457059)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.1480920450971657 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.00044247649369745696) - present_state_Q (-0.00044247649369745696)) * f3(0.003)
w4 ( 0.9620234754494102 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.00044247649369745696) - present_state_Q (-0.00044247649369745696)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.17959199565548947 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0004442761352914971) - present_state_Q (-0.004131755964116947)) * f3(0.15782228854878896)
w4 ( 0.9580316501061115 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0004442761352914971) - present_state_Q (-0.004131755964116947)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.180191850185973 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0005387759869664684) - present_state_Q (-0.0005387759869664684)) * f3(0.003)
w4 ( 0.9580316501061115 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0005387759869664684) - present_state_Q (-0.0005387759869664684)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.1949196954073261 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.03150515548423253) - present_state_Q (0.017437423149926155)) * f3(0.2850547633677411)
w4 ( 0.9547653236977925 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.03150515548423253) - present_state_Q (0.017437423149926155)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.2055127776037979 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0020591463083547545) - present_state_Q (-0.0020591463083547545)) * f3(0.01)
w4 ( 0.9516796189586045 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0020591463083547545) - present_state_Q (-0.0020591463083547545)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.10502404670712949 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.1241776211443612) - present_state_Q (-0.26120960769665585)) * f3(1.5488593387990377)
w4 ( 0.9555723700320978 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.1241776211443612) - present_state_Q (-0.26120960769665585)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.10462310149070912 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0010502404670712949) - present_state_Q (-0.0010502404670712949)) * f3(0.01)
w4 ( 0.9555723700320978 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0010502404670712949) - present_state_Q (-0.0010502404670712949)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.05556053537165388 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0010462310149070913) - present_state_Q (-0.163619467546193)) * f3(2.842580607086063)
w4 ( 0.9634615778543236 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( -0.0010462310149070913) - present_state_Q (-0.163619467546193)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09778228912206038 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.24893345843492137) - present_state_Q (0.24893345843492137)) * f3(2.3995101595154775)
w4 ( 0.9655730965032264 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.24893345843492137) - present_state_Q (0.24893345843492137)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.12815856396948155 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.23427834919160961) - present_state_Q (0.23427834919160961)) * f3(1.6059401235261515)
w4 ( 0.9670862923890469 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.23427834919160961) - present_state_Q (0.23427834919160961)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.15126876705991796 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.26010151743057086) - present_state_Q (0.2794432432783518)) * f3(1.576768134943745)
w4 ( 0.9682588276567645 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.26010151743057086) - present_state_Q (0.2794432432783518)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.15132474145497216 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4441879056530398) - present_state_Q (0.4441879056530398)) * f3(2.4243418292372083)
w4 ( 0.9682606747360626 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4441879056530398) - present_state_Q (0.4441879056530398)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.15130619509517165 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4445293974881491) - present_state_Q (0.4445293974881491)) * f3(2.425700780850091)
w4 ( 0.9682600630741479 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4445293974881491) - present_state_Q (0.4445293974881491)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.17649641193611493 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.326512634485073) - present_state_Q (0.2096321966087975)) * f3(1.1295095615770014)
w4 ( 0.9691521393415068 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.326512634485073) - present_state_Q (0.2096321966087975)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1894169438450856 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3606948404375493) - present_state_Q (0.3606948404375493)) * f3(1.714174859183931)
w4 ( 0.969604387203144 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3606948404375493) - present_state_Q (0.3606948404375493)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.20447831638967603 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.326157662731856) - present_state_Q (0.326157662731856)) * f3(1.4147699464459504)
w4 ( 0.970243135824392 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.326157662731856) - present_state_Q (0.326157662731856)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.21346417404093418 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07460662847944627) - present_state_Q (0.07460662847944627)) * f3(0.26996390980528207)
w4 ( 0.970908843893129 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07460662847944627) - present_state_Q (0.07460662847944627)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.22291944995690335 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08114808808265829) - present_state_Q (0.08114808808265829)) * f3(0.28918159912378694)
w4 ( 0.9715627773345803 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08114808808265829) - present_state_Q (0.08114808808265829)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.23335266026926027 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09295147026847078) - present_state_Q (0.09295147026847078)) * f3(0.32980619114210413)
w4 ( 0.972195464688097 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09295147026847078) - present_state_Q (0.09295147026847078)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.24611451474755103 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12209275993165136) - present_state_Q (0.12209275993165136)) * f3(0.43988720985415497)
w4 ( 0.9727756977202201 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12209275993165136) - present_state_Q (0.12209275993165136)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2595422000373107 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.14011059348797944) - present_state_Q (0.14011059348797944)) * f3(0.4902395929688889)
w4 ( 0.9733234986519418 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.14011059348797944) - present_state_Q (0.14011059348797944)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.272670826860884 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.14656689543103588) - present_state_Q (0.14656689543103588)) * f3(0.48971005655236655)
w4 ( 0.973859678240166 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.14656689543103588) - present_state_Q (0.14656689543103588)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.27288383252434945 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.15732371734020512) - present_state_Q (0.00272670826860884)) * f3(0.01)
w4 ( 0.973859678240166 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.15732371734020512) - present_state_Q (0.00272670826860884)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2730983481874609 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.17244501436709123) - present_state_Q (0.0027288383252434944)) * f3(0.01)
w4 ( 0.973859678240166 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.17244501436709123) - present_state_Q (0.0027288383252434944)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2750372040395298 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.18712996043658317) - present_state_Q (0.18712996043658317)) * f3(0.6138915448756181)
w4 ( 0.9739228443113801 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.18712996043658317) - present_state_Q (0.18712996043658317)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2754515518898545 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17098222365101165) - present_state_Q (0.0027503720403952983)) * f3(0.01)
w4 ( 0.9739228443113801 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17098222365101165) - present_state_Q (0.0027503720403952983)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.26791544447858917 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.16192220358238865) - present_state_Q (0.16192220358238865)) * f3(0.517128132765505)
w4 ( 0.9736313843449318 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.16192220358238865) - present_state_Q (0.16192220358238865)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.26596936852725567 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.5660320311129501) - present_state_Q (0.0026791544447858917)) * f3(0.01)
w4 ( 0.9736313843449318 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.5660320311129501) - present_state_Q (0.0026791544447858917)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.07479582332375939 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.40134709315923894) - present_state_Q (0.2849258473654323)) * f3(0.8516317708274914)
w4 ( 0.9601626375166348 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.40134709315923894) - present_state_Q (0.2849258473654323)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.083250992681973 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.09508737812916032) - present_state_Q (0.09508737812916032)) * f3(0.7578079912717515)
w4 ( 0.9518203229553698 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.09508737812916032) - present_state_Q (0.09508737812916032)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.22919061820851003 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0008325099268197301) - present_state_Q (-0.023391597451265483)) * f3(0.7383024320716557)
w4 ( 0.9439135563412041 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0008325099268197301) - present_state_Q (-0.023391597451265483)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.23118855549294615 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0022919061820851003) - present_state_Q (-0.0022919061820851003)) * f3(0.01)
w4 ( 0.9439135563412041 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0022919061820851003) - present_state_Q (-0.0022919061820851003)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.2331864747959467 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0023118855549294614) - present_state_Q (-0.0023118855549294614)) * f3(0.01)
w4 ( 0.9439135563412041 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0023118855549294614) - present_state_Q (-0.0023118855549294614)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.23518437611767354 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0023318647479594673) - present_state_Q (-0.0023318647479594673)) * f3(0.01)
w4 ( 0.9439135563412041 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0023318647479594673) - present_state_Q (-0.0023318647479594673)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.23718225945828847 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0023518437611767355) - present_state_Q (-0.0023518437611767355)) * f3(0.01)
w4 ( 0.9439135563412041 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0023518437611767355) - present_state_Q (-0.0023518437611767355)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.4608841657096957 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0023718225945828847) - present_state_Q (-0.24578509239084032)) * f3(1.27505280733063)
w4 ( 0.9333868438019924 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0023718225945828847) - present_state_Q (-0.24578509239084032)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.6459620720034209 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.004608841657096957) - present_state_Q (-0.5202704548803261)) * f3(1.2503655113016663)
w4 ( 0.9245057012262802 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.004608841657096957) - present_state_Q (-0.5202704548803261)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.6479562583447729 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0064596207200342095) - present_state_Q (-0.0064596207200342095)) * f3(0.01)
w4 ( 0.9245057012262802 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.0064596207200342095) - present_state_Q (-0.0064596207200342095)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.6500318739120727 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.8209512988330288) - present_state_Q (-0.006479562583447729)) * f3(0.01)
w4 ( 0.9245057012262802 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.8209512988330288) - present_state_Q (-0.006479562583447729)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.8068981014519656 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.006500318739120728) - present_state_Q (-0.7796461494142856)) * f3(1.2847316031780087)
w4 ( 0.9171796779315224 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.006500318739120728) - present_state_Q (-0.7796461494142856)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.9378411935531216 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.008068981014519656) - present_state_Q (-0.9665780489324174)) * f3(1.2660939810987086)
w4 ( 0.9109743048365082 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.008068981014519656) - present_state_Q (-0.9665780489324174)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( -1.046979253410526 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.009378411935531216) - present_state_Q (-1.154322895489508)) * f3(1.2891109519292179)
w4 ( 0.905894615162284 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.009378411935531216) - present_state_Q (-1.154322895489508)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( -1.0490975216248537 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.287380068617387) - present_state_Q (-0.01046979253410526)) * f3(0.01)
w4 ( 0.905894615162284 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.287380068617387) - present_state_Q (-0.01046979253410526)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -1.135668359053559 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.010490975216248538) - present_state_Q (-1.3580003215938516)) * f3(1.346256157688867)
w4 ( 0.9020363225067174 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.010490975216248538) - present_state_Q (-1.3580003215938516)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( -1.1378103059981755 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.5330362820699237) - present_state_Q (-0.01135668359053559)) * f3(0.01)
w4 ( 0.9020363225067174 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.5330362820699237) - present_state_Q (-0.01135668359053559)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -1.1398000657054215 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.011378103059981754) - present_state_Q (-0.011378103059981754)) * f3(0.01)
w4 ( 0.9020363225067174 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.011378103059981754) - present_state_Q (-0.011378103059981754)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -1.14192990914907 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.4124144430556205) - present_state_Q (-0.011398000657054215)) * f3(0.01)
w4 ( 0.9020363225067174 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.4124144430556205) - present_state_Q (-0.011398000657054215)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -1.233364955182722 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.19703416089742595) - present_state_Q (-1.10333998584734)) * f3(0.9978033061562154)
w4 ( 0.8983708687857478 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.19703416089742595) - present_state_Q (-1.10333998584734)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -1.318421420925338 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.01233364955182722) - present_state_Q (-1.056363564634697)) * f3(0.9001924467663807)
w4 ( 0.8927016499838248 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.01233364955182722) - present_state_Q (-1.056363564634697)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( -1.3967079791223513 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.01318421420925338) - present_state_Q (-1.0550718687817315)) * f3(0.827337843172722)
w4 ( 0.8889166637732681 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.01318421420925338) - present_state_Q (-1.0550718687817315)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -1.398799813376315 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.0580133375497547) - present_state_Q (-0.013967079791223514)) * f3(0.01)
w4 ( 0.8889166637732681 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.0580133375497547) - present_state_Q (-0.013967079791223514)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -1.4008908186704174 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.0499329223614755) - present_state_Q (-0.013987998133763151)) * f3(0.01)
w4 ( 0.8889166637732681 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.0499329223614755) - present_state_Q (-0.013987998133763151)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.25345319242739767 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.588368306091819) - present_state_Q (0.5453309976886556)) * f3(1.6720494039676845)
w4 ( 0.972766442674137 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.588368306091819) - present_state_Q (0.5453309976886556)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.26190098626974495 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.38980733638177895) - present_state_Q (0.3703520075282962)) * f3(1.2309413741443294)
w4 ( 0.9731782150307964 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.38980733638177895) - present_state_Q (0.3703520075282962)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2752602592858084 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.28896625275498045) - present_state_Q (0.28896625275498045)) * f3(0.9547086008153507)
w4 ( 0.9737379365208785 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.28896625275498045) - present_state_Q (0.28896625275498045)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.27570234482950673 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.44838146291227404) - present_state_Q (0.002752602592858084)) * f3(0.01)
w4 ( 0.9737379365208785 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.44838146291227404) - present_state_Q (0.002752602592858084)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2868111900645247 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3258168277368496) - present_state_Q (0.3258168277368496)) * f3(1.0404964471862295)
w4 ( 0.9741649959410258 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3258168277368496) - present_state_Q (0.3258168277368496)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.29697211427362435 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3350989308389758) - present_state_Q (0.3350989308389758)) * f3(1.0324992233905275)
w4 ( 0.9745586397900055 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3350989308389758) - present_state_Q (0.3350989308389758)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.30611875146519113 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.34620650328971125) - present_state_Q (0.34620650328971125)) * f3(1.0345219060367419)
w4 ( 0.9749122963781625 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.34620650328971125) - present_state_Q (0.34620650328971125)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.29348963191826605 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.3572116234746247) - present_state_Q (0.3572116234746247)) * f3(1.0395153191250441)
w4 ( 0.9744263345336538 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.3572116234746247) - present_state_Q (0.3572116234746247)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2484004934919877 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.25054280081775565) - present_state_Q (0.25054280081775565)) * f3(0.7208627645671942)
w4 ( 0.9719243804507098 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.25054280081775565) - present_state_Q (0.25054280081775565)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.19629919737042423 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.14502513114090598) - present_state_Q (0.14502513114090598)) * f3(0.5055812964234012)
w4 ( 0.9698633352146562 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.14502513114090598) - present_state_Q (0.14502513114090598)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1512474592230221 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.10807572324865891) - present_state_Q (0.10807572324865891)) * f3(0.45175149838756645)
w4 ( 0.9678687989128086 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.10807572324865891) - present_state_Q (0.10807572324865891)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.07921573383306706 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.07211819637863248) - present_state_Q (0.07211819637863248)) * f3(0.34883773037521104)
w4 ( 0.9637389861593271 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.07211819637863248) - present_state_Q (0.07211819637863248)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.5272676322549832 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.9112218063015352) - present_state_Q (0.9112218063015352)) * f3(2.819698529424339)
w4 ( 0.9285097903341897 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.9112218063015352) - present_state_Q (0.9112218063015352)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2758636006980874 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2816253735031814) - present_state_Q (0.2816253735031814)) * f3(0.5423986660332458)
w4 ( 0.9756829046387917 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2816253735031814) - present_state_Q (0.2816253735031814)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2815542882275218 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.26337862088872904) - present_state_Q (0.13125507763714306)) * f3(0.19285054328085763)
w4 ( 0.9780435669144055 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.26337862088872904) - present_state_Q (0.13125507763714306)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.28322903655419696 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.31917202326229455) - present_state_Q (0.031331963412368394)) * f3(0.04180753966911049)
w4 ( 0.9788447373922332 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.31917202326229455) - present_state_Q (0.031331963412368394)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.29325767940130687 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.21717172032840631) - present_state_Q (0.21717172032840631)) * f3(0.4902892126685446)
w4 ( 0.9804811010058687 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.21717172032840631) - present_state_Q (0.21717172032840631)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3032552568710597 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2570489559942911) - present_state_Q (0.22326499533313113)) * f3(0.49385409974029904)
w4 ( 0.9821006202079992 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2570489559942911) - present_state_Q (0.22326499533313113)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.31179725661558094 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.16387993496598152) - present_state_Q (0.15993507970929158)) * f3(0.33308257716290607)
w4 ( 0.983639337690723 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.16387993496598152) - present_state_Q (0.15993507970929158)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.31801554050535064 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1163058186745749) - present_state_Q (0.10195430382185555)) * f3(0.20079949064920022)
w4 ( 0.9848780428029054 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1163058186745749) - present_state_Q (0.10195430382185555)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3237354546121884 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11499576648417814) - present_state_Q (0.09728645193559751)) * f3(0.18203931207728907)
w4 ( 0.9861348953017567 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11499576648417814) - present_state_Q (0.09728645193559751)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3264046938476201 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06326470052088262) - present_state_Q (0.04354200261484749)) * f3(0.07357644758849832)
w4 ( 0.9868604642366312 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06326470052088262) - present_state_Q (0.04354200261484749)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.32938876697425723 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.046964748936486736) - present_state_Q (0.046964748936486736)) * f3(0.08341650768191804)
w4 ( 0.9875759276885455 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.046964748936486736) - present_state_Q (0.046964748936486736)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.33321819139527636 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05581467287268807) - present_state_Q (0.05581467287268807)) * f3(0.10948507640436814)
w4 ( 0.9882754612773746 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05581467287268807) - present_state_Q (0.05581467287268807)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3332999833745466 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09626332733780377) - present_state_Q (0.0006664363827905528)) * f3(0.002)
w4 ( 0.9882754612773746 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09626332733780377) - present_state_Q (0.0006664363827905528)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3379504582388549 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06517447697678605) - present_state_Q (0.06517447697678605)) * f3(0.13624053410230785)
w4 ( 0.9889581472188165 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06517447697678605) - present_state_Q (0.06517447697678605)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3419964649185367 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.059217689725016925) - present_state_Q (0.059217689725016925)) * f3(0.11669913686806259)
w4 ( 0.9896515553773114 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.059217689725016925) - present_state_Q (0.059217689725016925)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3440004687836216 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.038554614706750145) - present_state_Q (0.038554614706750145)) * f3(0.05485899862641244)
w4 ( 0.9903821570708393 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.038554614706750145) - present_state_Q (0.038554614706750145)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3456289179028874 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0350098334963479) - present_state_Q (0.0350098334963479)) * f3(0.04419235359964982)
w4 ( 0.9911191393705459 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0350098334963479) - present_state_Q (0.0350098334963479)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.35186698283879075 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1375193253026479) - present_state_Q (0.1375193253026479)) * f3(0.2258265234691553)
w4 ( 0.9927765350139116 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1375193253026479) - present_state_Q (0.1375193253026479)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.35734302091794523 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12124643540213478) - present_state_Q (0.10180258720338131)) * f3(0.17646306368924736)
w4 ( 0.9940178232392589 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12124643540213478) - present_state_Q (0.10180258720338131)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3605380815618393 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1415400820095892) - present_state_Q (0.051350040484245664)) * f3(0.08806575804564741)
w4 ( 0.9947434311746923 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1415400820095892) - present_state_Q (0.051350040484245664)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3670416463995345 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1201203043949535) - present_state_Q (0.1201203043949535)) * f3(0.22280744047889864)
w4 ( 0.9959109980788705 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1201203043949535) - present_state_Q (0.1201203043949535)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3731858808051427 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11616725598655755) - present_state_Q (0.11616725598655755)) * f3(0.20796227570403447)
w4 ( 0.9970927959573189 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11616725598655755) - present_state_Q (0.11616725598655755)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3791978245767056 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09776273200275264) - present_state_Q (0.1163431204088064)) * f3(0.20488290823209512)
w4 ( 0.9982665285684847 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09776273200275264) - present_state_Q (0.1163431204088064)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3846680018140079 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.16408168746656832) - present_state_Q (0.10696283365236903)) * f3(0.17677362095749607)
w4 ( 0.9995043099088619 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.16408168746656832) - present_state_Q (0.10696283365236903)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.38475165321046834 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1902631830577412) - present_state_Q (0.0007693360036280158)) * f3(0.002)
w4 ( 0.9995043099088619 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1902631830577412) - present_state_Q (0.0007693360036280158)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3882147662314684 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0988874842209479) - present_state_Q (0.05783799433709118)) * f3(0.09836970893588397)
w4 ( 1.0002084114170318 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0988874842209479) - present_state_Q (0.05783799433709118)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.39226961546579975 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07847096161725389) - present_state_Q (0.06606079286232652)) * f3(0.11863697272793888)
w4 ( 1.0008919840236306 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07847096161725389) - present_state_Q (0.06606079286232652)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.39235179788174196 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11696618941958965) - present_state_Q (0.0007845392309315995)) * f3(0.002)
w4 ( 1.0008919840236306 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11696618941958965) - present_state_Q (0.0007845392309315995)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.39542079593729534 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.054311784271220576) - present_state_Q (0.054311784271220576)) * f3(0.08740611047508043)
w4 ( 1.0015942228119423 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.054311784271220576) - present_state_Q (0.054311784271220576)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.39550229692662964 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08295788263446943) - present_state_Q (0.0007908415918745907)) * f3(0.002)
w4 ( 1.0015942228119423 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08295788263446943) - present_state_Q (0.0007908415918745907)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.39763137903492074 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04335905525819589) - present_state_Q (0.04335905525819589)) * f3(0.05898112598391434)
w4 ( 1.0023161765124775 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04335905525819589) - present_state_Q (0.04335905525819589)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.39939379494493277 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.039263869484947866) - present_state_Q (0.039263869484947866)) * f3(0.04833005383363016)
w4 ( 1.0030455015474047 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.039263869484947866) - present_state_Q (0.039263869484947866)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4006444371138026 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.033568605729798875) - present_state_Q (0.033568605729798875)) * f3(0.0338204946341572)
w4 ( 1.003785078057091 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.033568605729798875) - present_state_Q (0.033568605729798875)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.40072469439583647 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.020876990435369423) - present_state_Q (0.0008012888742276052)) * f3(0.002)
w4 ( 1.003785078057091 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.020876990435369423) - present_state_Q (0.0008012888742276052)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.40785285846239516 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22480160296379237) - present_state_Q (0.22480160296379237)) * f3(0.3605936912300417)
w4 ( 1.0053665065157515 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22480160296379237) - present_state_Q (0.22480160296379237)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.41444960095558836 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.13765872536038493) - present_state_Q (0.13765872536038493)) * f3(0.23891965712124438)
w4 ( 1.006470935104454 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.13765872536038493) - present_state_Q (0.13765872536038493)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4170876160158139 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18994970677307998) - present_state_Q (0.07174396711778948)) * f3(0.07596853668339086)
w4 ( 1.0078599391186922 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18994970677307998) - present_state_Q (0.07174396711778948)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4205633525038801 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18620421412758814) - present_state_Q (0.0606551700265945)) * f3(0.09709703594432585)
w4 ( 1.0085758696214646 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18620421412758814) - present_state_Q (0.0606551700265945)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4262851599805428 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12370547733660475) - present_state_Q (0.12370547733660475)) * f3(0.19821613570330543)
w4 ( 1.0097305299030528 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12370547733660475) - present_state_Q (0.12370547733660475)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4328522945305723 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17680417829659473) - present_state_Q (0.17680417829659473)) * f3(0.27263521560946735)
w4 ( 1.0111757873402512 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17680417829659473) - present_state_Q (0.17680417829659473)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.43852928389379775 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12625551579010014) - present_state_Q (0.12625551579010014)) * f3(0.1982396429007019)
w4 ( 1.0123212674834068 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12625551579010014) - present_state_Q (0.12625551579010014)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4386132051211799 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.20483195478523236) - present_state_Q (0.0008770585677875955)) * f3(0.002)
w4 ( 1.0123212674834068 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.20483195478523236) - present_state_Q (0.0008770585677875955)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.43479399902290344 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05733971422974639) - present_state_Q (0.05733971422974639)) * f3(0.08456947590036677)
w4 ( 1.0114180559977932 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05733971422974639) - present_state_Q (0.05733971422974639)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.41522076773818745 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.06163168802329053) - present_state_Q (0.06163168802329053)) * f3(0.0952251571925529)
w4 ( 1.0073071189593512 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.06163168802329053) - present_state_Q (0.06163168802329053)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4072852509393462 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1996127503124994) - present_state_Q (0.1996127503124994)) * f3(0.29773544215390324)
w4 ( 1.005547866254841 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1996127503124994) - present_state_Q (0.1996127503124994)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.41151049337955964 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.25679545843985363) - present_state_Q (0.31116925602748835)) * f3(0.36898364740709466)
w4 ( 1.007380030891905 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.25679545843985363) - present_state_Q (0.31116925602748835)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.41811783107585193 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17087568359309158) - present_state_Q (0.17087568359309158)) * f3(0.26835981953373594)
w4 ( 1.0088573022005023 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17087568359309158) - present_state_Q (0.17087568359309158)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4244539070936148 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12816792131707583) - present_state_Q (0.16933928729454398)) * f3(0.26023250164323825)
w4 ( 1.0103181672295252 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12816792131707583) - present_state_Q (0.16933928729454398)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4304173495447109 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12979692417395458) - present_state_Q (0.12979692417395458)) * f3(0.21058634634045098)
w4 ( 1.011450898302499 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12979692417395458) - present_state_Q (0.12979692417395458)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.43616366195717765 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1601930719815476) - present_state_Q (0.1256304772702976)) * f3(0.19788338325184104)
w4 ( 1.0126124536222105 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1601930719815476) - present_state_Q (0.1256304772702976)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4362479767796365 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22446439618102504) - present_state_Q (0.0008723273239143553)) * f3(0.002)
w4 ( 1.0126124536222105 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22446439618102504) - present_state_Q (0.0008723273239143553)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.44179325059844315 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1529762392355041) - present_state_Q (0.1529762392355041)) * f3(0.21139236610088538)
w4 ( 1.0141863819303387 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1529762392355041) - present_state_Q (0.1529762392355041)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.44188308251088476 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.5004314870920451) - present_state_Q (0.0008835865011968863)) * f3(0.002)
w4 ( 1.0141863819303387 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.5004314870920451) - present_state_Q (0.0008835865011968863)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.44197269940600714 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.48968241776815424) - present_state_Q (0.0008837661650217695)) * f3(0.002)
w4 ( 1.0141863819303387 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.48968241776815424) - present_state_Q (0.0008837661650217695)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.44869222420781957 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2631893504690062) - present_state_Q (0.2631893504690062)) * f3(0.41191331536824033)
w4 ( 1.015491418606962 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2631893504690062) - present_state_Q (0.2631893504690062)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.45530212731976766 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.26794322066060283) - present_state_Q (0.26794322066060283)) * f3(0.4161068480776051)
w4 ( 1.0167622274182055 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.26794322066060283) - present_state_Q (0.26794322066060283)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.46178711864044203 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.27530351222653093) - present_state_Q (0.27530351222653093)) * f3(0.42600840715345656)
w4 ( 1.0179800421301746 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.27530351222653093) - present_state_Q (0.27530351222653093)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.44773658715405806 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.22300314893310075) - present_state_Q (0.22300314893310075)) * f3(0.3506471702415941)
w4 ( 1.015575825125936 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.22300314893310075) - present_state_Q (0.22300314893310075)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.42766098628675425 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.21287464153546082) - present_state_Q (0.21287464153546082)) * f3(0.3393515213792989)
w4 ( 1.0120263020616445 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.21287464153546082) - present_state_Q (0.21287464153546082)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.43116577632868874 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06401774180911285) - present_state_Q (0.06401774180911285)) * f3(0.10236429595316549)
w4 ( 1.012711070126388 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06401774180911285) - present_state_Q (0.06401774180911285)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.43467233068083366 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06446431803013745) - present_state_Q (0.06446431803013745)) * f3(0.10253619154110971)
w4 ( 1.0133950343539337 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06446431803013745) - present_state_Q (0.06446431803013745)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.43827486095202095 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06627691013568947) - present_state_Q (0.06627691013568947)) * f3(0.10584756884926677)
w4 ( 1.0140757359156896 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06627691013568947) - present_state_Q (0.06627691013568947)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.44164737058404246 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06337964357098574) - present_state_Q (0.06337964357098574)) * f3(0.09833584513392843)
w4 ( 1.0147616525572618 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06337964357098574) - present_state_Q (0.06337964357098574)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4428804231835582 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.03507612042809688) - present_state_Q (0.03507612042809688)) * f3(0.03346762227386327)
w4 ( 1.0154985155404912 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.03507612042809688) - present_state_Q (0.03507612042809688)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.45004149005705485 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2861786645925157) - present_state_Q (0.19912692947538532)) * f3(0.31204138026592815)
w4 ( 1.0168754611623945 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2861786645925157) - present_state_Q (0.19912692947538532)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4569880224399435 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2246615654949037) - present_state_Q (0.2043240562716558)) * f3(0.31844070328658713)
w4 ( 1.0181843137640614 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2246615654949037) - present_state_Q (0.2043240562716558)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4630466596794652 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.14266963703051647) - present_state_Q (0.14266963703051647)) * f3(0.2230742590050072)
w4 ( 1.0192707030707515 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.14266963703051647) - present_state_Q (0.14266963703051647)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4686863182665714 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.13433823611921836) - present_state_Q (0.13433823611921836)) * f3(0.2020690702339986)
w4 ( 1.0203870854207224 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.13433823611921836) - present_state_Q (0.13433823611921836)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4738602997133964 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12522074159916535) - present_state_Q (0.12522074159916535)) * f3(0.1800890166679239)
w4 ( 1.0215362907509655 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12522074159916535) - present_state_Q (0.12522074159916535)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.47710853465117115 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08897315319492934) - present_state_Q (0.08897315319492934)) * f3(0.1015314040741332)
w4 ( 1.0228159873994638 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08897315319492934) - present_state_Q (0.08897315319492934)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.48055908318619883 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06920389950380337) - present_state_Q (0.06920389950380337)) * f3(0.10217293595775846)
w4 ( 1.023491420380357 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06920389950380337) - present_state_Q (0.06920389950380337)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.48405291056243577 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07033628960197139) - present_state_Q (0.07033628960197139)) * f3(0.10376759682439056)
w4 ( 1.0241648150590734 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07033628960197139) - present_state_Q (0.07033628960197139)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4876811293783682 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07302147873777859) - present_state_Q (0.07302147873777859)) * f3(0.10853809839827512)
w4 ( 1.0248333763973454 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07302147873777859) - present_state_Q (0.07302147873777859)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.49186259693259055 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08322278192396482) - present_state_Q (0.08322278192396482)) * f3(0.1286211637427368)
w4 ( 1.0254835753898823 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08322278192396482) - present_state_Q (0.08322278192396482)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4919442694604808 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09346364645176493) - present_state_Q (0.000983725193865181)) * f3(0.002)
w4 ( 1.0254835753898823 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09346364645176493) - present_state_Q (0.000983725193865181)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.49687060337407635 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09830329728926258) - present_state_Q (0.09830329728926258)) * f3(0.15813503807409288)
w4 ( 1.0261066294547616 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09830329728926258) - present_state_Q (0.09830329728926258)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5007849690809097 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07978370707891859) - present_state_Q (0.07978370707891859)) * f3(0.11926963295352655)
w4 ( 1.0267630187820196 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07978370707891859) - present_state_Q (0.07978370707891859)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5044086766142292 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07513218647487753) - present_state_Q (0.07513218647487753)) * f3(0.10902269331173983)
w4 ( 1.0274277808463648 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07513218647487753) - present_state_Q (0.07513218647487753)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.504489883104759 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07041270002390633) - present_state_Q (0.0010088173532284584)) * f3(0.002)
w4 ( 1.0274277808463648 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07041270002390633) - present_state_Q (0.0010088173532284584)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5075536122492366 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06591807523232038) - present_state_Q (0.06591807523232038)) * f3(0.08993147560497652)
w4 ( 1.0281091283109467 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06591807523232038) - present_state_Q (0.06591807523232038)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5123099040117106 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22561959988171001) - present_state_Q (0.15037985265602932)) * f3(0.17474667269990635)
w4 ( 1.0297422209549396 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22561959988171001) - present_state_Q (0.15037985265602932)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5171384859362291 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1280664379373581) - present_state_Q (0.1280664379373581)) * f3(0.169578507889191)
w4 ( 1.0308811817783652 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1280664379373581) - present_state_Q (0.1280664379373581)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5223559860000565 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.13956958596571603) - present_state_Q (0.13956958596571603)) * f3(0.19015088098994729)
w4 ( 1.0319787312688886 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.13956958596571603) - present_state_Q (0.13956958596571603)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.527923147441626 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1516258001101225) - present_state_Q (0.1516258001101225)) * f3(0.2112479876115654)
w4 ( 1.0330328783884921 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1516258001101225) - present_state_Q (0.1516258001101225)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5280062168477229 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1640287677902363) - present_state_Q (0.0010558462948832522)) * f3(0.002)
w4 ( 1.0330328783884921 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1640287677902363) - present_state_Q (0.0010558462948832522)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5331739701885798 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.14134854514689313) - present_state_Q (0.14134854514689313)) * f3(0.18944328081690243)
w4 ( 1.0341240236259632 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.14134854514689313) - present_state_Q (0.14134854514689313)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5386883266870216 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1537398909944775) - present_state_Q (0.1537398909944775)) * f3(0.21076597195788227)
w4 ( 1.0351705600183831 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1537398909944775) - present_state_Q (0.1537398909944775)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5444955205133345 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1664318223028618) - present_state_Q (0.1664318223028618)) * f3(0.23209153365368193)
w4 ( 1.0361714054580928 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1664318223028618) - present_state_Q (0.1664318223028618)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5447354298083918 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.21380095883310676) - present_state_Q (0.21380095883310676)) * f3(0.3165390643660257)
w4 ( 1.0362017220062936 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.21380095883310676) - present_state_Q (0.21380095883310676)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5332449401929684 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.20444851411730058) - present_state_Q (0.20444851411730058)) * f3(0.2992286462703252)
w4 ( 1.0346657073554713 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.20444851411730058) - present_state_Q (0.20444851411730058)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5178923557111559 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18573218955908094) - present_state_Q (0.18573218955908094)) * f3(0.2706927912201603)
w4 ( 1.0323970714730586 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18573218955908094) - present_state_Q (0.18573218955908094)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.49142921092269426 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.17130355520467477) - present_state_Q (0.17130355520467477)) * f3(0.251032228825292)
w4 ( 1.0281803786743218 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.17130355520467477) - present_state_Q (0.17130355520467477)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4914317932296415 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.13894393158008023) - present_state_Q (0.0009828584218453886)) * f3(0.002)
w4 ( 1.0281803786743218 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.13894393158008023) - present_state_Q (0.0009828584218453886)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4915079148648327 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.02154647115994572) - present_state_Q (0.02154647115994572)) * f3(0.002)
w4 ( 1.028941595026234 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.02154647115994572) - present_state_Q (0.02154647115994572)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.49745461723062406 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2473809518728094) - present_state_Q (0.24431665499665217)) * f3(0.3296006483214104)
w4 ( 1.030384966547759 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2473809518728094) - present_state_Q (0.24431665499665217)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5033667949070343 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2542046890232196) - present_state_Q (0.2542046890232196)) * f3(0.345305653520074)
w4 ( 1.0317546927867918 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2542046890232196) - present_state_Q (0.2542046890232196)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5092198232314382 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2662959459289581) - present_state_Q (0.2662959459289581)) * f3(0.3650530236901148)
w4 ( 1.0330373619761033 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2662959459289581) - present_state_Q (0.2662959459289581)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5093074413838161 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.391092015359875) - present_state_Q (0.0010184396464628764)) * f3(0.002)
w4 ( 1.0330373619761033 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.391092015359875) - present_state_Q (0.0010184396464628764)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5093951290433187 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.39456912395883614) - present_state_Q (0.0010186148827676321)) * f3(0.002)
w4 ( 1.0330373619761033 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.39456912395883614) - present_state_Q (0.0010186148827676321)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5094827635125699 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3919113651426405) - present_state_Q (0.0010187902580866375)) * f3(0.002)
w4 ( 1.0330373619761033 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3919113651426405) - present_state_Q (0.0010187902580866375)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5095705943784579 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4017329496674444) - present_state_Q (0.0010189655270251398)) * f3(0.002)
w4 ( 1.0330373619761033 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4017329496674444) - present_state_Q (0.0010189655270251398)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5096580417300254 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.38255899026193474) - present_state_Q (0.0010191411887569158)) * f3(0.002)
w4 ( 1.0330373619761033 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.38255899026193474) - present_state_Q (0.0010191411887569158)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5144932115888071 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3366474022112076) - present_state_Q (0.3366474022112076)) * f3(0.4983820374753742)
w4 ( 1.0338135006801825 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3366474022112076) - present_state_Q (0.3366474022112076)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5207265027825804 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2836874322429128) - present_state_Q (0.2836874322429128)) * f3(0.4308290512086595)
w4 ( 1.0346815885460707 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2836874322429128) - present_state_Q (0.2836874322429128)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.526750325197075 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2944638570338049) - present_state_Q (0.2944638570338049)) * f3(0.44626682237079807)
w4 ( 1.0354914837180882 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2944638570338049) - present_state_Q (0.2944638570338049)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5324341378991694 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3105151771855564) - present_state_Q (0.3105151771855564)) * f3(0.47154349277248514)
w4 ( 1.0362147017612862 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3105151771855564) - present_state_Q (0.3105151771855564)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5381891111477711 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.175354661305691) - present_state_Q (0.1607978296764847)) * f3(0.2241577560690431)
w4 ( 1.0372416523071024 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.175354661305691) - present_state_Q (0.1607978296764847)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5436307217635056 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18679156311367778) - present_state_Q (0.1508264647359407)) * f3(0.20315683907182558)
w4 ( 1.038313063073404 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18679156311367778) - present_state_Q (0.1508264647359407)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.548388262008158 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2109290253382456) - present_state_Q (0.13055026839214098)) * f3(0.16374671685300743)
w4 ( 1.0394752336099709 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2109290253382456) - present_state_Q (0.13055026839214098)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5541077368342383 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2128406870866661) - present_state_Q (0.2128406870866661)) * f3(0.27438985021132595)
w4 ( 1.0407258938997028 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2128406870866661) - present_state_Q (0.2128406870866661)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5590619592128381 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.16305521669414336) - present_state_Q (0.1415379485407609)) * f3(0.18030593356371166)
w4 ( 1.0418249641922175 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.16305521669414336) - present_state_Q (0.1415379485407609)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5639998398175975 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17262647991462365) - present_state_Q (0.14194020400423282)) * f3(0.1793490037807631)
w4 ( 1.0429262539681663 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17262647991462365) - present_state_Q (0.14194020400423282)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5700180951393252 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11684747395265815) - present_state_Q (0.210085427815625)) * f3(0.2985255770841179)
w4 ( 1.0437326512464848 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11684747395265815) - present_state_Q (0.210085427815625)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5701038214163124 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.29771421126621983) - present_state_Q (0.0011400361902786506)) * f3(0.002)
w4 ( 1.0437326512464848 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.29771421126621983) - present_state_Q (0.0011400361902786506)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5744341964008629 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22552312954438097) - present_state_Q (0.09661910920319705)) * f3(0.13286081119416976)
w4 ( 1.0443845176539874 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22552312954438097) - present_state_Q (0.09661910920319705)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5803516484674133 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.19050904518939354) - present_state_Q (0.19050904518939354)) * f3(0.2589220234713217)
w4 ( 1.0452986850913055 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.19050904518939354) - present_state_Q (0.19050904518939354)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5860127767911957 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17969881982076724) - present_state_Q (0.17969881982076724)) * f3(0.23759193720091132)
w4 ( 1.0462517693399507 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17969881982076724) - present_state_Q (0.17969881982076724)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5918815806898865 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.26678804100202363) - present_state_Q (0.18296777275690415)) * f3(0.24080994062282754)
w4 ( 1.0472266134653239 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.26678804100202363) - present_state_Q (0.18296777275690415)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5974306701680657 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.429920368821359) - present_state_Q (0.19558855171609402)) * f3(0.22429310057839238)
w4 ( 1.0487110343763202 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.429920368821359) - present_state_Q (0.19558855171609402)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6023522832000503 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3936171098004675) - present_state_Q (0.32875251874201483)) * f3(0.44495515539008723)
w4 ( 1.0493746895297484 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3936171098004675) - present_state_Q (0.32875251874201483)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6065516432559483 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.33040578477399984) - present_state_Q (0.33040578477399984)) * f3(0.40915559961406883)
w4 ( 1.0501957678793756 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.33040578477399984) - present_state_Q (0.33040578477399984)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6114725246517982 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.31037285860285924) - present_state_Q (0.31037285860285924)) * f3(0.4078154189843931)
w4 ( 1.0509197544429203 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.31037285860285924) - present_state_Q (0.31037285860285924)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6145248875068323 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3056868903225063) - present_state_Q (0.3638591789457865)) * f3(0.4575603764857239)
w4 ( 1.051453430523612 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3056868903225063) - present_state_Q (0.3638591789457865)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6167965441092594 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.36647457529218624) - present_state_Q (0.057885737141600876)) * f3(0.05997587612872532)
w4 ( 1.0522109539643874 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.36647457529218624) - present_state_Q (0.057885737141600876)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6215831852718672 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.31333186392057566) - present_state_Q (0.31333186392057566)) * f3(0.4056430099556332)
w4 ( 1.0529189618992163 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.31333186392057566) - present_state_Q (0.31333186392057566)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.62606709018599 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.19140099218010065) - present_state_Q (0.14307586819736876)) * f3(0.16242252382879815)
w4 ( 1.054023218823299 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.19140099218010065) - present_state_Q (0.14307586819736876)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6306729330284427 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18417787168320948) - present_state_Q (0.14931627839790385)) * f3(0.17115633663660315)
w4 ( 1.0550996248583806 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18417787168320948) - present_state_Q (0.14931627839790385)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6355697212484156 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18270037424308877) - present_state_Q (0.16335127987242243)) * f3(0.19209211071790772)
w4 ( 1.0561192998885882 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18270037424308877) - present_state_Q (0.16335127987242243)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6410122414638183 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.19854853752639673) - present_state_Q (0.19854853752639673)) * f3(0.24592701682489543)
w4 ( 1.0570045251534932 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.19854853752639673) - present_state_Q (0.19854853752639673)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6456957295397976 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3081299151859724) - present_state_Q (0.3081299151859724)) * f3(0.3817550240818222)
w4 ( 1.057740623611489 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3081299151859724) - present_state_Q (0.3081299151859724)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6511230368724812 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2047707418700984) - present_state_Q (0.2047707418700984)) * f3(0.25160630540553314)
w4 ( 1.0586034489407568 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2047707418700984) - present_state_Q (0.2047707418700984)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6559937482895584 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17140105377857878) - present_state_Q (0.17140105377857878)) * f3(0.19820664991495854)
w4 ( 1.059586405147154 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17140105377857878) - present_state_Q (0.17140105377857878)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6584858520558119 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09425375045883999) - present_state_Q (0.09425375045883999)) * f3(0.07907132406093918)
w4 ( 1.0608470916455022 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09425375045883999) - present_state_Q (0.09425375045883999)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6585617959513752 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.022533913537021666) - present_state_Q (0.022533913537021666)) * f3(0.002)
w4 ( 1.0616065306011355 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.022533913537021666) - present_state_Q (0.022533913537021666)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6630638827531284 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.33682042615968066) - present_state_Q (0.28684127280758404)) * f3(0.30659651319099807)
w4 ( 1.0627812567596027 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.33682042615968066) - present_state_Q (0.28684127280758404)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6668981964129747 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3283510894270617) - present_state_Q (0.3283510894270617)) * f3(0.3669760866418499)
w4 ( 1.063617128915728 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3283510894270617) - present_state_Q (0.3283510894270617)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6712867303346778 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.31496131370904734) - present_state_Q (0.31496131370904734)) * f3(0.3765856427936466)
w4 ( 1.064316337821699 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.31496131370904734) - present_state_Q (0.31496131370904734)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6759497032678993 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2919857498980912) - present_state_Q (0.2919857498980912)) * f3(0.3398350649878838)
w4 ( 1.0651396147722494 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2919857498980912) - present_state_Q (0.2919857498980912)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6768090893649292 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.42547547197506136) - present_state_Q (0.42547547197506136)) * f3(0.5033870140755493)
w4 ( 1.065276191374029 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.42547547197506136) - present_state_Q (0.42547547197506136)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6788763909287397 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.39789567411691845) - present_state_Q (0.39789567411691845)) * f3(0.4934613141024149)
w4 ( 1.0655275547337977 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.39789567411691845) - present_state_Q (0.39789567411691845)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6806100370120228 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4062422515230454) - present_state_Q (0.4062422515230454)) * f3(0.504231113076002)
w4 ( 1.0657338465755732 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4062422515230454) - present_state_Q (0.4062422515230454)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6845514942634449 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3341224930846086) - present_state_Q (0.3341224930846086)) * f3(0.3969651453807484)
w4 ( 1.0663295851129164 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3341224930846086) - present_state_Q (0.3341224930846086)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6891043848659656 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.35496513052024675) - present_state_Q (0.120165073053415)) * f3(0.14438428982980114)
w4 ( 1.0669602479929137 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.35496513052024675) - present_state_Q (0.120165073053415)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6920451026914031 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.37112800883241914) - present_state_Q (0.37112800883241914)) * f3(0.4456659987914297)
w4 ( 1.0673561567452186 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.37112800883241914) - present_state_Q (0.37112800883241914)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6972885015626485 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.24924970009717867) - present_state_Q (0.24924970009717867)) * f3(0.2984710866734898)
w4 ( 1.0680588578248686 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.24924970009717867) - present_state_Q (0.24924970009717867)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7016524989064921 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.30282201440970563) - present_state_Q (0.30282201440970563)) * f3(0.3423812129487178)
w4 ( 1.0688236189470561 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.30282201440970563) - present_state_Q (0.30282201440970563)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7057739254188145 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.317758708287887) - present_state_Q (0.317758708287887)) * f3(0.3614742219921379)
w4 ( 1.0695077219223015 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.317758708287887) - present_state_Q (0.317758708287887)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7087156506143454 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.13992535409870693) - present_state_Q (0.13992535409870693)) * f3(0.10733591601363708)
w4 ( 1.0711521250101685 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.13992535409870693) - present_state_Q (0.13992535409870693)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7087979193030693 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.127608749211738) - present_state_Q (0.001417431301228691)) * f3(0.002)
w4 ( 1.0711521250101685 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.127608749211738) - present_state_Q (0.001417431301228691)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7119678875509857 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09232226148759856) - present_state_Q (0.09232226148759856)) * f3(0.10002740845671128)
w4 ( 1.0717859449394909 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09232226148759856) - present_state_Q (0.09232226148759856)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.715821531766009 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11357148067587186) - present_state_Q (0.11357148067587186)) * f3(0.1294099964171263)
w4 ( 1.0723815162742742 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11357148067587186) - present_state_Q (0.11357148067587186)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7198804566952132 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12137264366104071) - present_state_Q (0.12137264366104071)) * f3(0.13959486953267447)
w4 ( 1.0729630455156844 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12137264366104071) - present_state_Q (0.12137264366104071)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7241358623869572 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12955203101863005) - present_state_Q (0.12955203101863005)) * f3(0.15015377775991112)
w4 ( 1.0735298518598508 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12955203101863005) - present_state_Q (0.12955203101863005)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7184614166351936 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1455975135717946) - present_state_Q (0.1455975135717946)) * f3(0.17141385060731568)
w4 ( 1.0728677763354215 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1455975135717946) - present_state_Q (0.1455975135717946)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6795537254887887 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.1522631269242357) - present_state_Q (0.1522631269242357)) * f3(0.18206373838436096)
w4 ( 1.0685937027069579 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.1522631269242357) - present_state_Q (0.1522631269242357)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6383677758726968 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.15233462841623124) - present_state_Q (0.15233462841623124)) * f3(0.19271876446250566)
w4 ( 1.0643195003758086 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.15233462841623124) - present_state_Q (0.15233462841623124)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6379720535178499 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.22664961317256987) - present_state_Q (0.0012767355517453935)) * f3(0.002)
w4 ( 1.0643195003758086 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.22664961317256987) - present_state_Q (0.0012767355517453935)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6405478441321409 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07005573963166734) - present_state_Q (0.07005573963166734)) * f3(0.0764443353830806)
w4 ( 1.0649934000444716 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07005573963166734) - present_state_Q (0.07005573963166734)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.642803427719194 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06343367905767536) - present_state_Q (0.06343367905767536)) * f3(0.06577777357735355)
w4 ( 1.0656792194221678 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.06343367905767536) - present_state_Q (0.06343367905767536)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6428836225816478 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.022599191243881746) - present_state_Q (0.001285606855438388)) * f3(0.002)
w4 ( 1.0656792194221678 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.022599191243881746) - present_state_Q (0.001285606855438388)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6417006211656257 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4334727494248596) - present_state_Q (0.46884013561985116)) * f3(0.46405204617639095)
w4 ( 1.06527133365133 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4334727494248596) - present_state_Q (0.46884013561985116)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6450211908270623 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3452807935805057) - present_state_Q (0.3452807935805057)) * f3(0.37206393813626887)
w4 ( 1.0661638065091055 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3452807935805057) - present_state_Q (0.3452807935805057)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6498596215212644 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.21530117075495128) - present_state_Q (0.21530117075495128)) * f3(0.23461452819924275)
w4 ( 1.0674011801870287 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.21530117075495128) - present_state_Q (0.21530117075495128)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.654734319992945 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22297832088794545) - present_state_Q (0.22297832088794545)) * f3(0.2445670492723837)
w4 ( 1.0685970972542338 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22297832088794545) - present_state_Q (0.22297832088794545)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6579124793894017 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.23787953977148774) - present_state_Q (0.10880650577246133)) * f3(0.10089989155143697)
w4 ( 1.0698570230470525 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.23787953977148774) - present_state_Q (0.10880650577246133)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6579976569035106 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.27203395503889916) - present_state_Q (0.0013158249587788035)) * f3(0.002)
w4 ( 1.0698570230470525 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.27203395503889916) - present_state_Q (0.0013158249587788035)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.662776880218642 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1702067942297666) - present_state_Q (0.1702067942297666)) * f3(0.19363672799000312)
w4 ( 1.0708442785878254 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1702067942297666) - present_state_Q (0.1702067942297666)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6673985216812095 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.16434125995937443) - present_state_Q (0.16434125995937443)) * f3(0.18333091035972407)
w4 ( 1.0718526500519716 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.16434125995937443) - present_state_Q (0.16434125995937443)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6713530931486541 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.13882891358700925) - present_state_Q (0.13882891358700925)) * f3(0.14377437837772777)
w4 ( 1.0729528659630583 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.13882891358700925) - present_state_Q (0.13882891358700925)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6748037091290341 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09514985454608188) - present_state_Q (0.09514985454608188)) * f3(0.10976459031596918)
w4 ( 1.0735815962248754 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09514985454608188) - present_state_Q (0.09514985454608188)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6779826757833946 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0884202110176952) - present_state_Q (0.0884202110176952)) * f3(0.0992119310956484)
w4 ( 1.0742224398450435 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0884202110176952) - present_state_Q (0.0884202110176952)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6806103789554155 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07507546222454917) - present_state_Q (0.07507546222454917)) * f3(0.07904481241460193)
w4 ( 1.0748873040130393 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07507546222454917) - present_state_Q (0.07507546222454917)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6806925273349983 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12103118671614863) - present_state_Q (0.001361220757910831)) * f3(0.002)
w4 ( 1.0748873040130393 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12103118671614863) - present_state_Q (0.001361220757910831)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6807727122406101 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.022859131134930783) - present_state_Q (0.0013613850546699967)) * f3(0.002)
w4 ( 1.0748873040130393 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.022859131134930783) - present_state_Q (0.0013613850546699967)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5967800400001657 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.5582151135248816) - present_state_Q (0.5582151135248816)) * f3(0.5989236695770335)
w4 ( 1.0552537935826258 ) += alpha ( 0.1) * (reward ( -0.9) + discount_factor ( 0.1) * next_state_max_Q( 0.5582151135248816) - present_state_Q (0.5582151135248816)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5940022279982093 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.5067378725680398) - present_state_Q (0.5067378725680398)) * f3(0.49547085028418925)
w4 ( 1.0541325118764011 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.5067378725680398) - present_state_Q (0.5067378725680398)) * f4(0.2)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.598909183705625 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.270258291454858) - present_state_Q (0.270258291454858)) * f3(0.313008405930266)
w4 ( 1.055386652177926 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.270258291454858) - present_state_Q (0.270258291454858)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6037724577537158 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2707264901795324) - present_state_Q (0.2707264901795324)) * f3(0.3110581087647272)
w4 ( 1.0566374214486334 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2707264901795324) - present_state_Q (0.2707264901795324)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6092078617954011 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18650842421476188) - present_state_Q (0.17947768790977095)) * f3(0.22725811568535592)
w4 ( 1.0575941140666802 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.18650842421476188) - present_state_Q (0.17947768790977095)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6092859287671294 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1270515664639599) - present_state_Q (0.02237029800492441)) * f3(0.002)
w4 ( 1.0583747837839632 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1270515664639599) - present_state_Q (0.02237029800492441)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6124266652977178 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07941578597874618) - present_state_Q (0.07941578597874618)) * f3(0.09560091174422898)
w4 ( 1.0590318353692014 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07941578597874618) - present_state_Q (0.07941578597874618)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.613965614094777 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0475669868339574) - present_state_Q (0.0475669868339574)) * f3(0.043084913870865216)
w4 ( 1.0597462147929002 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0475669868339574) - present_state_Q (0.0475669868339574)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6140458169656419 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.02242285552404756) - present_state_Q (0.001227931228189554)) * f3(0.002)
w4 ( 1.0597462147929002 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.02242285552404756) - present_state_Q (0.001227931228189554)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6190161949521314 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.20551750673975477) - present_state_Q (0.20551750673975477)) * f3(0.23114355627981167)
w4 ( 1.0610364202565055 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.20551750673975477) - present_state_Q (0.20551750673975477)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6242076347994941 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17492217471344707) - present_state_Q (0.17492217471344707)) * f3(0.2140181775267311)
w4 ( 1.062006700427537 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.17492217471344707) - present_state_Q (0.17492217471344707)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6242916390752276 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.21269793936444925) - present_state_Q (0.0012484152695989884)) * f3(0.002)
w4 ( 1.062006700427537 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.21269793936444925) - present_state_Q (0.0012484152695989884)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6243758176017072 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22141215676632936) - present_state_Q (0.001248583278150455)) * f3(0.002)
w4 ( 1.062006700427537 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22141215676632936) - present_state_Q (0.001248583278150455)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.629963663599432 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2031130388768248) - present_state_Q (0.2031130388768248)) * f3(0.25726936619155205)
w4 ( 1.0628754934875806 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2031130388768248) - present_state_Q (0.2031130388768248)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6354708994566223 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2006033039550496) - present_state_Q (0.2006033039550496)) * f3(0.25094825836822904)
w4 ( 1.0637533215933423 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2006033039550496) - present_state_Q (0.2006033039550496)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6388989978515757 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1097897470577508) - present_state_Q (0.0889157147571068)) * f3(0.10644177157927773)
w4 ( 1.0643974481132397 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1097897470577508) - present_state_Q (0.0889157147571068)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6425465726605923 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.10491020929074985) - present_state_Q (0.0952021247690274)) * f3(0.1156899229069284)
w4 ( 1.0650280259055598 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.10491020929074985) - present_state_Q (0.0952021247690274)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6436076938437123 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.14994008767899514) - present_state_Q (0.03945639230433728)) * f3(0.028256055761138425)
w4 ( 1.065779101138487 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.14994008767899514) - present_state_Q (0.03945639230433728)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6472518688659462 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09613464208310164) - present_state_Q (0.09613464208310164)) * f3(0.11624948050807525)
w4 ( 1.0664060587827373 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09613464208310164) - present_state_Q (0.09613464208310164)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6500466544402466 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07585879647491657) - present_state_Q (0.07585879647491657)) * f3(0.08424954476347105)
w4 ( 1.0670695129490824 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07585879647491657) - present_state_Q (0.07585879647491657)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6522108796149041 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.062240019432753535) - present_state_Q (0.062240019432753535)) * f3(0.06291645206449004)
w4 ( 1.0677574809141035 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.062240019432753535) - present_state_Q (0.062240019432753535)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6540403409269178 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0554359404642249) - present_state_Q (0.0554359404642249)) * f3(0.05225425075102354)
w4 ( 1.068457696221268 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.0554359404642249) - present_state_Q (0.0554359404642249)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6555409640593999 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04894219759482886) - present_state_Q (0.04894219759482886)) * f3(0.042158016784295725)
w4 ( 1.0691696002655973 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.04894219759482886) - present_state_Q (0.04894219759482886)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6585350268814812 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2905567485906339) - present_state_Q (0.3333235326012578)) * f3(0.31275418594711735)
w4 ( 1.070318385972691 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2905567485906339) - present_state_Q (0.3333235326012578)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6628726913398203 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3206936184142307) - present_state_Q (0.3206936184142307)) * f3(0.389462222640479)
w4 ( 1.0709866404332542 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3206936184142307) - present_state_Q (0.3206936184142307)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6671012317924411 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3249983978844251) - present_state_Q (0.3249983978844251)) * f3(0.3933473242522861)
w4 ( 1.0716316490846782 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3249983978844251) - present_state_Q (0.3249983978844251)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6716944595240478 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2999974961603739) - present_state_Q (0.2999974961603739)) * f3(0.35331908559363556)
w4 ( 1.0724116626054123 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2999974961603739) - present_state_Q (0.2999974961603739)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6717814974016738 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3653277704883593) - present_state_Q (0.0013433889190480957)) * f3(0.002)
w4 ( 1.0724116626054123 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3653277704883593) - present_state_Q (0.0013433889190480957)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6718683521361251 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3561723525101304) - present_state_Q (0.0013435629948033477)) * f3(0.002)
w4 ( 1.0724116626054123 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3561723525101304) - present_state_Q (0.0013435629948033477)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6750866350418101 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3552995543487212) - present_state_Q (0.3552995543487212)) * f3(0.40113010306769786)
w4 ( 1.0730535058141015 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3552995543487212) - present_state_Q (0.3552995543487212)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6795767029737672 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.30372714947620993) - present_state_Q (0.30372714947620993)) * f3(0.35453810919029755)
w4 ( 1.07381337920693 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.30372714947620993) - present_state_Q (0.30372714947620993)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6848997950345619 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.23344877706281814) - present_state_Q (0.23344877706281814)) * f3(0.2803160276992227)
w4 ( 1.0745729636095038 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.23344877706281814) - present_state_Q (0.23344877706281814)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6896345602064242 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.24653724549537695) - present_state_Q (0.24653724549537695)) * f3(0.26582409426713194)
w4 ( 1.0756416624838288 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.24653724549537695) - present_state_Q (0.24653724549537695)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6948749448492009 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.23236602564805436) - present_state_Q (0.23236602564805436)) * f3(0.27455172648544046)
w4 ( 1.0764051447914957 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.23236602564805436) - present_state_Q (0.23236602564805436)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6998977633931001 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.20504906197211534) - present_state_Q (0.20504906197211534)) * f3(0.23312519379384242)
w4 ( 1.0772669681683962 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.20504906197211534) - present_state_Q (0.20504906197211534)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7046933619572354 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12139804568658255) - present_state_Q (0.20559190789739973)) * f3(0.2321785233072598)
w4 ( 1.0780931597550811 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12139804568658255) - present_state_Q (0.20559190789739973)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7075108197953718 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08251417643961437) - present_state_Q (0.08251417643961437)) * f3(0.08649480261204967)
w4 ( 1.0787446342374898 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08251417643961437) - present_state_Q (0.08251417643961437)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7075920412800488 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07522445024600541) - present_state_Q (0.0014150216395907437)) * f3(0.002)
w4 ( 1.0787446342374898 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07522445024600541) - present_state_Q (0.0014150216395907437)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7076731844704801 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07131136238897987) - present_state_Q (0.0014151840825600978)) * f3(0.002)
w4 ( 1.0787446342374898 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07131136238897987) - present_state_Q (0.0014151840825600978)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7102158599204539 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07581069458347253) - present_state_Q (0.07581069458347253)) * f3(0.07663961711267177)
w4 ( 1.0794081749872395 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07581069458347253) - present_state_Q (0.07581069458347253)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7132621852560537 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08927198216334613) - present_state_Q (0.08927198216334613)) * f3(0.09530034808175376)
w4 ( 1.0800474854193456 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08927198216334613) - present_state_Q (0.08927198216334613)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7165703431211751 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09707580935244335) - present_state_Q (0.09707580935244335)) * f3(0.10581643216787351)
w4 ( 1.0806727489625112 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09707580935244335) - present_state_Q (0.09707580935244335)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7201271652411835 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.10505443921953737) - present_state_Q (0.10505443921953737)) * f3(0.11644493111010168)
w4 ( 1.081283650971916 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.10505443921953737) - present_state_Q (0.10505443921953737)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7237526987959051 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1077971361910619) - present_state_Q (0.1077971361910619)) * f3(0.11966145332507101)
w4 ( 1.081889616126772 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1077971361910619) - present_state_Q (0.1077971361910619)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7282601714741677 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.14115184633248612) - present_state_Q (0.14115184633248612)) * f3(0.16513106508450215)
w4 ( 1.0824355428033734 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.14115184633248612) - present_state_Q (0.14115184633248612)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7283020278477266 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.10738388137360289) - present_state_Q (0.0014565203429483353)) * f3(0.002)
w4 ( 1.0824355428033734 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.10738388137360289) - present_state_Q (0.0014565203429483353)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7104333788561242 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.7125400733393015) - present_state_Q (0.7125400733393015)) * f3(0.7405586774001529)
w4 ( 1.0785749657472874 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.7125400733393015) - present_state_Q (0.7125400733393015)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6893167830140633 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.7388183619909745) - present_state_Q (0.7388183619909745)) * f3(0.7970435854001221)
w4 ( 1.0743359813346174 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.7388183619909745) - present_state_Q (0.7388183619909745)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6903876417084241 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.5542645447001927) - present_state_Q (0.06172257826023948)) * f3(0.027199597440343004)
w4 ( 1.0759107968394566 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.5542645447001927) - present_state_Q (0.06172257826023948)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6890244134470198 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.47305794986824024) - present_state_Q (0.47305794986824024)) * f3(0.5293647338181128)
w4 ( 1.0756532752906425 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.47305794986824024) - present_state_Q (0.47305794986824024)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6891144630916535 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.5162627199509112) - present_state_Q (0.0013780488268940396)) * f3(0.002)
w4 ( 1.0756532752906425 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.5162627199509112) - present_state_Q (0.0013780488268940396)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6894105764519113 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4375740537529548) - present_state_Q (0.4375740537529548)) * f3(0.4788881149632739)
w4 ( 1.075715108806866 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4375740537529548) - present_state_Q (0.4375740537529548)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6943246873160056 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2432582126402163) - present_state_Q (0.18399329317088198)) * f3(0.2044713174318992)
w4 ( 1.0766764389192385 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2432582126402163) - present_state_Q (0.18399329317088198)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6984466368511021 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.28251982445319807) - present_state_Q (0.28251982445319807)) * f3(0.2828441980059952)
w4 ( 1.0778422961831755 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.28251982445319807) - present_state_Q (0.28251982445319807)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7009472209613685 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22045281498153826) - present_state_Q (0.07136004158783033)) * f3(0.07130565606085676)
w4 ( 1.0785436666629962 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22045281498153826) - present_state_Q (0.07136004158783033)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7051774841994446 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.19887848679052994) - present_state_Q (0.19887848679052994)) * f3(0.19140651789265672)
w4 ( 1.0798697228343273 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.19887848679052994) - present_state_Q (0.19887848679052994)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7091809367733632 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.16984430218043917) - present_state_Q (0.14824690772375262)) * f3(0.14897259365795032)
w4 ( 1.0809446729243044 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.16984430218043917) - present_state_Q (0.14824690772375262)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7123140916348055 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09158639692591386) - present_state_Q (0.09158639692591386)) * f3(0.09865959424370095)
w4 ( 1.0815798174098377 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.09158639692591386) - present_state_Q (0.09158639692591386)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7123917337035272 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11266568139508923) - present_state_Q (0.023056224531466364)) * f3(0.002)
w4 ( 1.0823562380970537 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11266568139508923) - present_state_Q (0.023056224531466364)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7152209714246882 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08373180374392956) - present_state_Q (0.08373180374392956)) * f3(0.08714963417560652)
w4 ( 1.0830055208503147 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.08373180374392956) - present_state_Q (0.08373180374392956)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7153031135381872 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12141009437924065) - present_state_Q (0.0014304419428493764)) * f3(0.002)
w4 ( 1.0830055208503147 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12141009437924065) - present_state_Q (0.0014304419428493764)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6948040844812199 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.09205883584337485) - present_state_Q (0.09205883584337485)) * f3(0.0984180329904439)
w4 ( 1.0788398149457965 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.09205883584337485) - present_state_Q (0.09205883584337485)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6944058926374866 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.104303895026292) - present_state_Q (0.0013896081689624398)) * f3(0.002)
w4 ( 1.0788398149457965 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.104303895026292) - present_state_Q (0.0013896081689624398)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6940072435897443 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.0814357307383184) - present_state_Q (0.0013888117852749733)) * f3(0.002)
w4 ( 1.0788398149457965 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.0814357307383184) - present_state_Q (0.0013888117852749733)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7300767857336049 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3876706139949967) - present_state_Q (0.3888538818462446)) * f3(0.35556899034748185)
w4 ( 1.0830345009580125 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3876706139949967) - present_state_Q (0.3888538818462446)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7335364579078564 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.32831918840324187) - present_state_Q (0.32831918840324187)) * f3(0.33102878087509185)
w4 ( 1.083870602801509 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.32831918840324187) - present_state_Q (0.32831918840324187)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7378525586116036 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.28320651221325477) - present_state_Q (0.28320651221325477)) * f3(0.2974279924237526)
w4 ( 1.0847412876355575 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.28320651221325477) - present_state_Q (0.28320651221325477)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.742086339249915 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.24781181310077854) - present_state_Q (0.16249061222545952)) * f3(0.16141566405102145)
w4 ( 1.085790449911896 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.24781181310077854) - present_state_Q (0.16249061222545952)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7463602550420019 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2235882121431487) - present_state_Q (0.1682398942987975)) * f3(0.1681856540149697)
w4 ( 1.086806925619558 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2235882121431487) - present_state_Q (0.1682398942987975)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7464461071957599 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3075348930032707) - present_state_Q (0.0014927205100840038)) * f3(0.002)
w4 ( 1.086806925619558 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.3075348930032707) - present_state_Q (0.0014927205100840038)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7488630317790905 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2048748512667246) - present_state_Q (0.07376996562318813)) * f3(0.06970875272734296)
w4 ( 1.087500360658565 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2048748512667246) - present_state_Q (0.07376996562318813)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7506936166102353 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2084291633233673) - present_state_Q (0.05970990768640384)) * f3(0.05069004459073158)
w4 ( 1.0882226266758568 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2084291633233673) - present_state_Q (0.05970990768640384)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7535923086558501 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.13621154585300038) - present_state_Q (0.11685317817326676)) * f3(0.09767536513408626)
w4 ( 1.089409698581505 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.13621154585300038) - present_state_Q (0.11685317817326676)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7545251186039403 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13007331150133916) - present_state_Q (0.11616226327111905)) * f3(0.09631981974089825)
w4 ( 1.089797078853021 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13007331150133916) - present_state_Q (0.11616226327111905)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7524784853348134 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13933808626167543) - present_state_Q (0.07986496362008191)) * f3(0.07696101907178872)
w4 ( 1.089265216543033 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13933808626167543) - present_state_Q (0.07986496362008191)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7521765716557192 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.11388597780838108) - present_state_Q (0.06453336235261804)) * f3(0.0568096747679593)
w4 ( 1.0891589270138895 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.11388597780838108) - present_state_Q (0.06453336235261804)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7311840006650298 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.118519429544657) - present_state_Q (0.118519429544657)) * f3(0.09964824123558103)
w4 ( 1.0807322570675288 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.118519429544657) - present_state_Q (0.118519429544657)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7192647149098198 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.09939087191370184) - present_state_Q (0.0640428381643939)) * f3(0.058026697773000846)
w4 ( 1.0766240495655828 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( 0.09939087191370184) - present_state_Q (0.0640428381643939)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7327506089335725 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2523004554942635) - present_state_Q (0.2523004554942635)) * f3(0.25724811378011586)
w4 ( 1.0834731203437045 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2523004554942635) - present_state_Q (0.2523004554942635)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7371691695757437 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1787231977748233) - present_state_Q (0.1787231977748233)) * f3(0.1847617338156977)
w4 ( 1.0844297168317152 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1787231977748233) - present_state_Q (0.1787231977748233)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7401679911533059 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11880653027787466) - present_state_Q (0.11880653027787466)) * f3(0.10232297377278708)
w4 ( 1.0856020133227149 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.11880653027787466) - present_state_Q (0.11880653027787466)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7402481589336344 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.02319237624876091) - present_state_Q (0.0014803359823066119)) * f3(0.002)
w4 ( 1.0856020133227149 ) += alpha ( 0.1) * (reward ( 0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.02319237624876091) - present_state_Q (0.0014803359823066119)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9803723905240125 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.5825719394433319) - present_state_Q (0.5825719394433319)) * f3(0.46257193944333186)
w4 ( 0.994908223054012 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.5825719394433319) - present_state_Q (0.5825719394433319)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9705366876937034 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.5621208479267072) - present_state_Q (0.49811213407544663)) * f3(0.40660193577767006)
w4 ( 0.9924892225611843 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.5621208479267072) - present_state_Q (0.49811213407544663)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9574402374748688 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.4810309242584271) - present_state_Q (0.4810309242584271)) * f3(0.3933720454293606)
w4 ( 0.9891599442428585 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.4810309242584271) - present_state_Q (0.4810309242584271)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9212873918081301 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.8019270745088815) - present_state_Q (0.8019270745088815)) * f3(0.6929358683155361)
w4 ( 0.9818556631040466 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.8019270745088815) - present_state_Q (0.8019270745088815)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9222724917124708 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1491208835509515) - present_state_Q (0.1386633305275274)) * f3(0.12919553477427292)
w4 ( 0.9820081606197018 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1491208835509515) - present_state_Q (0.1386633305275274)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9223169622960624 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.24197462941160505) - present_state_Q (0.0018445449834249418)) * f3(0.002)
w4 ( 0.9820081606197018 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.24197462941160505) - present_state_Q (0.0018445449834249418)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9229338965337844 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1836811043739694) - present_state_Q (0.1836811043739694)) * f3(0.17785744800052636)
w4 ( 0.9820775346318286 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1836811043739694) - present_state_Q (0.1836811043739694)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9236574628931469 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1742206148146708) - present_state_Q (0.1742206148146708)) * f3(0.16748660408137453)
w4 ( 0.9821639375251622 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1742206148146708) - present_state_Q (0.1742206148146708)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9237003821311529 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.16443504955995414) - present_state_Q (0.0018473149257862938)) * f3(0.002)
w4 ( 0.9821639375251622 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.16443504955995414) - present_state_Q (0.0018473149257862938)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9246324475930671 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1472662767021759) - present_state_Q (0.1472662767021759)) * f3(0.1381649292568463)
w4 ( 0.9822988582270983 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1472662767021759) - present_state_Q (0.1472662767021759)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9255601483754836 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.14792242923037371) - present_state_Q (0.14792242923037371)) * f3(0.13873237133279417)
w4 ( 0.9824325978544836 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.14792242923037371) - present_state_Q (0.14792242923037371)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9265143396171297 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.14205671878151363) - present_state_Q (0.14205671878151363)) * f3(0.13225295734617687)
w4 ( 0.9825768957606769 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.14205671878151363) - present_state_Q (0.14205671878151363)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9265568342037437 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1432596174910805) - present_state_Q (0.0018530286792342594)) * f3(0.002)
w4 ( 0.9825768957606769 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1432596174910805) - present_state_Q (0.0018530286792342594)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9265894260896339 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04115618949883456) - present_state_Q (0.04115618949883456)) * f3(0.002)
w4 ( 0.983228733478481 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04115618949883456) - present_state_Q (0.04115618949883456)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8954703686648923 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.5809378358895554) - present_state_Q (0.5809378358895554)) * f3(0.4996283950982126)
w4 ( 0.9757546048508738 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.5809378358895554) - present_state_Q (0.5809378358895554)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8652551518789433 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4241664054872002) - present_state_Q (0.4241664054872002)) * f3(0.3865075263351924)
w4 ( 0.969500606731366 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4241664054872002) - present_state_Q (0.4241664054872002)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8485408729062207 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.39503677948119154) - present_state_Q (0.39503677948119154)) * f3(0.36691689180152953)
w4 ( 0.9658563419191014 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.39503677948119154) - present_state_Q (0.39503677948119154)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8470900847139982 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.3627316962503965) - present_state_Q (0.28945059003884654)) * f3(0.2728203400866529)
w4 ( 0.9655372773966185 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.3627316962503965) - present_state_Q (0.28945059003884654)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8274603006043696 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.23954410479388843) - present_state_Q (0.23954410479388843)) * f3(0.21439498753123604)
w4 ( 0.9600437392307315 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.23954410479388843) - present_state_Q (0.23954410479388843)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8252467980625284 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.30696279960246703) - present_state_Q (0.08198197163745145)) * f3(0.029462860352093154)
w4 ( 0.9555360250806683 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.30696279960246703) - present_state_Q (0.08198197163745145)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.817415325698833 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.23602851362658844) - present_state_Q (0.11943113902990776)) * f3(0.0984065593678654)
w4 ( 0.9523527119299993 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.23602851362658844) - present_state_Q (0.11943113902990776)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8096295288388262 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.23532014666917916) - present_state_Q (0.11818252008409)) * f3(0.0979776242125385)
w4 ( 0.9491741099083306 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.23532014666917916) - present_state_Q (0.11818252008409)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7976534479184416 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.1979733656551294) - present_state_Q (0.1541755242131169)) * f3(0.14353300574825925)
w4 ( 0.9458365971577402 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.1979733656551294) - present_state_Q (0.1541755242131169)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7881811551408218 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.18824789205882111) - present_state_Q (0.11394182457332086)) * f3(0.11913079906837208)
w4 ( 0.9442463630870053 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.18824789205882111) - present_state_Q (0.11394182457332086)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7802953196054072 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.16442254122316208) - present_state_Q (0.11554994627563227)) * f3(0.09868301372703506)
w4 ( 0.941049932318392 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.16442254122316208) - present_state_Q (0.11554994627563227)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7682113931209218 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.1505033023885567) - present_state_Q (0.1505033023885567)) * f3(0.14463921833197027)
w4 ( 0.9377081204297931 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.1505033023885567) - present_state_Q (0.1505033023885567)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7586703025230066 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.11684153063040534) - present_state_Q (0.11050866415849853)) * f3(0.11943913169152891)
w4 ( 0.9361104714076022 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.11684153063040534) - present_state_Q (0.11050866415849853)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7586329361495634 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1468547338892343) - present_state_Q (0.0015173406050460131)) * f3(0.002)
w4 ( 0.9361104714076022 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1468547338892343) - present_state_Q (0.0015173406050460131)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7561369350481717 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.08680498336887589) - present_state_Q (0.08680498336887589)) * f3(0.08974402599269883)
w4 ( 0.9355542224375382 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.08680498336887589) - present_state_Q (0.08680498336887589)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7542589824377794 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07228429378572468) - present_state_Q (0.07228429378572468)) * f3(0.07085120016463803)
w4 ( 0.9350241107087238 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07228429378572468) - present_state_Q (0.07228429378572468)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7282260520853656 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.6076722366321002) - present_state_Q (0.6076722366321002)) * f3(0.5825159619372176)
w4 ( 0.9269798204752838 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.6076722366321002) - present_state_Q (0.6076722366321002)) * f4(0.18)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7226547474402532 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.4479817131811591) - present_state_Q (0.3902236708925426)) * f3(0.3831036964917655)
w4 ( 0.9252347144803907 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.4479817131811591) - present_state_Q (0.3902236708925426)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7180909038586452 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.4190757716479797) - present_state_Q (0.36950462285394586)) * f3(0.35767627353429793)
w4 ( 0.923703549932121 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.4190757716479797) - present_state_Q (0.36950462285394586)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7119796984102225 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.39426400929166205) - present_state_Q (0.39426400929166205)) * f3(0.3946848258024978)
w4 ( 0.921845498631771 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.39426400929166205) - present_state_Q (0.39426400929166205)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7083849181487596 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.2903446284369432) - present_state_Q (0.3346097372003155)) * f3(0.3404945223556921)
w4 ( 0.9207897458882048 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.2903446284369432) - present_state_Q (0.3346097372003155)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7092488924018964 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.22473072588670573) - present_state_Q (0.07969808490823709)) * f3(0.0605129979118316)
w4 ( 0.9213608458389265 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.22473072588670573) - present_state_Q (0.07969808490823709)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7103901761909116 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.22423151863774407) - present_state_Q (0.07237268460127416)) * f3(0.07605999566923172)
w4 ( 0.9216609467734516 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.22423151863774407) - present_state_Q (0.07237268460127416)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7116017610934506 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.20369076108182416) - present_state_Q (0.07955717082308147)) * f3(0.08604278878877102)
w4 ( 0.9219425705840217 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.20369076108182416) - present_state_Q (0.07955717082308147)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7126334583117153 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07316477210318734) - present_state_Q (0.07316477210318734)) * f3(0.07690526314523842)
w4 ( 0.922210873994236 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07316477210318734) - present_state_Q (0.07316477210318734)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7135171086656149 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06215682288655062) - present_state_Q (0.06215682288655062)) * f3(0.06133953562919218)
w4 ( 0.9224989917130402 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06215682288655062) - present_state_Q (0.06215682288655062)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7135572207990525 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.019877014051592035) - present_state_Q (0.0014270342173312298)) * f3(0.002)
w4 ( 0.9224989917130402 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.019877014051592035) - present_state_Q (0.0014270342173312298)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7135973329180497 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01987709427585891) - present_state_Q (0.001427114441598105)) * f3(0.002)
w4 ( 0.9224989917130402 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01987709427585891) - present_state_Q (0.001427114441598105)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7069439428069647 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.39593460477873454) - present_state_Q (0.39593460477873454)) * f3(0.425568722861673)
w4 ( 0.9209355802700315 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.39593460477873454) - present_state_Q (0.39593460477873454)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7068706784023574 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.35091864849157983) - present_state_Q (0.0014138878856139294)) * f3(0.002)
w4 ( 0.9209355802700315 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.35091864849157983) - present_state_Q (0.0014138878856139294)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7068952814485231 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.24428972185033565) - present_state_Q (0.0014137413568047147)) * f3(0.002)
w4 ( 0.9209355802700315 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.24428972185033565) - present_state_Q (0.0014137413568047147)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7082106178742155 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.11305411882840416) - present_state_Q (0.11305411882840416)) * f3(0.1338747190801485)
w4 ( 0.9211320828561405 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.11305411882840416) - present_state_Q (0.11305411882840416)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7095231021205519 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.11286456933378272) - present_state_Q (0.11286456933378272)) * f3(0.1333528830168339)
w4 ( 0.9213289266313397 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.11286456933378272) - present_state_Q (0.11286456933378272)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7108121028002152 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.10545116272866767) - present_state_Q (0.10545116272866767)) * f3(0.12265222081698321)
w4 ( 0.9215391145384281 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.10545116272866767) - present_state_Q (0.10545116272866767)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7120637857446774 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.09803175662049304) - present_state_Q (0.09803175662049304)) * f3(0.11198595805577832)
w4 ( 0.9217626573765112 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.09803175662049304) - present_state_Q (0.09803175662049304)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7122644646808711 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.08842625958557217) - present_state_Q (0.08842625958557217)) * f3(0.09829316957166308)
w4 ( 0.9218034901092572 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.08842625958557217) - present_state_Q (0.08842625958557217)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7075098769360909 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.1838934676896392) - present_state_Q (0.19432671263362788)) * f3(0.220610063551324)
w4 ( 0.9213952422495815 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.1838934676896392) - present_state_Q (0.19432671263362788)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7083866241173374 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13010351107946921) - present_state_Q (0.13010351107946921)) * f3(0.1057508862893977)
w4 ( 0.9218926832897524 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13010351107946921) - present_state_Q (0.13010351107946921)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7084271066122994 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03829248057982477) - present_state_Q (0.0014167732482346749)) * f3(0.002)
w4 ( 0.9218926832897524 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03829248057982477) - present_state_Q (0.0014167732482346749)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7083405827082946 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05673041521060974) - present_state_Q (0.038292561544814696)) * f3(0.002)
w4 ( 0.9201622052096574 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05673041521060974) - present_state_Q (0.038292561544814696)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6927561743701632 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.49644959466155425) - present_state_Q (0.5346096700090667)) * f3(0.5468890624540879)
w4 ( 0.9156027698409709 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.49644959466155425) - present_state_Q (0.5346096700090667)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6900260883545555 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.30594233883116184) - present_state_Q (0.30594233883116184)) * f3(0.36232975168920317)
w4 ( 0.9151506812112826 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.30594233883116184) - present_state_Q (0.30594233883116184)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6895823182797287 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.23903031348213868) - present_state_Q (0.23903031348213868)) * f3(0.29335743916058415)
w4 ( 0.9150901720827469 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.23903031348213868) - present_state_Q (0.23903031348213868)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6910317617404544 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.18256145549978833) - present_state_Q (0.11770546480396767)) * f3(0.1441505368210292)
w4 ( 0.9152912734442389 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.18256145549978833) - present_state_Q (0.11770546480396767)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6918619279851493 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.17673179814861775) - present_state_Q (0.17673179814861775)) * f3(0.20276947452883665)
w4 ( 0.9154550389709039 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.17673179814861775) - present_state_Q (0.17673179814861775)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.693059370773074 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.08576967964674875) - present_state_Q (0.08576967964674875)) * f3(0.09750584060000293)
w4 ( 0.9157006535475397 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.08576967964674875) - present_state_Q (0.08576967964674875)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.694108537848991 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07214992102930469) - present_state_Q (0.07214992102930469)) * f3(0.07767863797628559)
w4 ( 0.915970783689687 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07214992102930469) - present_state_Q (0.07214992102930469)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6941506381566416 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.11889755328905424) - present_state_Q (0.001388217075697982)) * f3(0.002)
w4 ( 0.915970783689687 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.11889755328905424) - present_state_Q (0.001388217075697982)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.694193377374104 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.15084388588467382) - present_state_Q (0.0013883012763132832)) * f3(0.002)
w4 ( 0.915970783689687 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.15084388588467382) - present_state_Q (0.0013883012763132832)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6942361650881022 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1532695674526947) - present_state_Q (0.001388386754748208)) * f3(0.002)
w4 ( 0.915970783689687 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1532695674526947) - present_state_Q (0.001388386754748208)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6572012726141451 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.4177335522903231) - present_state_Q (0.4260891028157371)) * f3(0.4716274775863684)
w4 ( 0.9093190477337904 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.4177335522903231) - present_state_Q (0.4260891028157371)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6532407665935426 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.31232311217455055) - present_state_Q (0.34267589202149057)) * f3(0.35538215768270687)
w4 ( 0.907981724764142 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.31232311217455055) - present_state_Q (0.34267589202149057)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6543712623690514 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.26381455249437086) - present_state_Q (0.14209227306735356)) * f3(0.13412109908324132)
w4 ( 0.9084874598572344 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.26381455249437086) - present_state_Q (0.14209227306735356)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6522151622059944 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.2932839029011449) - present_state_Q (0.2932839029011449)) * f3(0.33712499126856477)
w4 ( 0.9079758157563462 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.2932839029011449) - present_state_Q (0.2932839029011449)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6515599871117745 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.24608608408156857) - present_state_Q (0.08683288970564625)) * f3(0.10529251291589822)
w4 ( 0.9078513671937513 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.24608608408156857) - present_state_Q (0.08683288970564625)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6515846655139618 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.24695130910496593) - present_state_Q (0.0013031199742235492)) * f3(0.002)
w4 ( 0.9078513671937513 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.24695130910496593) - present_state_Q (0.0013031199742235492)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6526768651281212 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1563443748059617) - present_state_Q (0.1563443748059617)) * f3(0.18421292960222327)
w4 ( 0.9080885274444498 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1563443748059617) - present_state_Q (0.1563443748059617)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6538681878399616 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1288867460229436) - present_state_Q (0.1288867460229436)) * f3(0.14182087625703624)
w4 ( 0.9084245351587672 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1288867460229436) - present_state_Q (0.1288867460229436)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6549252048789708 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.11669775580314418) - present_state_Q (0.06542985496811325)) * f3(0.07227965076732779)
w4 ( 0.9087170149999916 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.11669775580314418) - present_state_Q (0.06542985496811325)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.654961697724643 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.019484190709757772) - present_state_Q (0.019484190709757772)) * f3(0.002)
w4 ( 0.909081943456714 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.019484190709757772) - present_state_Q (0.019484190709757772)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6492836517995485 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.6358169186838747) - present_state_Q (0.3885339872509821)) * f3(0.45441709635734706)
w4 ( 0.907832420502888 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.6358169186838747) - present_state_Q (0.3885339872509821)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6459492045210222 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.32282541682023436) - present_state_Q (0.31985387020933714)) * f3(0.38076929225600137)
w4 ( 0.9071318498746695 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.32282541682023436) - present_state_Q (0.31985387020933714)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6313506555874614 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.5096606090231677) - present_state_Q (0.5096606090231677)) * f3(0.5643160646254151)
w4 ( 0.9029927371047359 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.5096606090231677) - present_state_Q (0.5096606090231677)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6258117858526528 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.35813108577879793) - present_state_Q (0.35813108577879793)) * f3(0.45282548498251196)
w4 ( 0.9020141932871286 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.35813108577879793) - present_state_Q (0.35813108577879793)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.619717991713144 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.36628654953285333) - present_state_Q (0.36628654953285333)) * f3(0.4699902122634916)
w4 ( 0.9009769301304921 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.36628654953285333) - present_state_Q (0.36628654953285333)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6125784423271895 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.3812377818916516) - present_state_Q (0.3812377818916516)) * f3(0.4988714731785881)
w4 ( 0.8998320181008722 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.3812377818916516) - present_state_Q (0.3812377818916516)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6126563343473739 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.21900947347666008) - present_state_Q (0.21900947347666008)) * f3(0.26938517745367824)
w4 ( 0.8998493669440982 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.21900947347666008) - present_state_Q (0.21900947347666008)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6129927237785614 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13792283674772748) - present_state_Q (0.19964270224883165)) * f3(0.23773807935461871)
w4 ( 0.8999342644326539 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13792283674772748) - present_state_Q (0.19964270224883165)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6114534602183415 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.09128973543820929) - present_state_Q (0.07491340129585379)) * f3(0.09284729459164133)
w4 ( 0.8996026955771498 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.09128973543820929) - present_state_Q (0.07491340129585379)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6115018345032818 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.43094331622004295) - present_state_Q (0.001222906920436683)) * f3(0.002)
w4 ( 0.8996026955771498 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.43094331622004295) - present_state_Q (0.001222906920436683)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.609270520522675 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.4072338221823721) - present_state_Q (0.30869396336824)) * f3(0.3282764311934451)
w4 ( 0.8987870486033498 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.4072338221823721) - present_state_Q (0.30869396336824)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6081239277874009 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.30640534406328235) - present_state_Q (0.2729536009002687)) * f3(0.270978406974677)
w4 ( 0.8982792918054225 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.30640534406328235) - present_state_Q (0.2729536009002687)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6085903051119648 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04178893636412829) - present_state_Q (0.054934591300715846)) * f3(0.03124925489717369)
w4 ( 0.8988762690147654 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04178893636412829) - present_state_Q (0.054934591300715846)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6086304455699625 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.019194705990519235) - present_state_Q (0.0012171806102239295)) * f3(0.002)
w4 ( 0.8988762690147654 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.019194705990519235) - present_state_Q (0.0012171806102239295)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.608701884049153 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.19842872831246494) - present_state_Q (0.21640625369276023)) * f3(0.20787429829081777)
w4 ( 0.8989106352061502 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.19842872831246494) - present_state_Q (0.21640625369276023)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6099357247897589 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.14722312451031722) - present_state_Q (0.14722312451031722)) * f3(0.18279341992818007)
w4 ( 0.8991806319579131 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.14722312451031722) - present_state_Q (0.14722312451031722)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6112175530237484 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.0921308249420805) - present_state_Q (0.07721360892921068)) * f3(0.0971085868276836)
w4 ( 0.8994446309050431 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.0921308249420805) - present_state_Q (0.07721360892921068)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6124934962988375 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1316349934032465) - present_state_Q (0.1316349934032465)) * f3(0.15650271772107974)
w4 ( 0.8997707449287914 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1316349934032465) - present_state_Q (0.1316349934032465)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6137660311520498 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1323187213424293) - present_state_Q (0.1323187213424293)) * f3(0.15727169696880985)
w4 ( 0.9000943975319586 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1323187213424293) - present_state_Q (0.1323187213424293)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.615033310086808 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.11132093203225149) - present_state_Q (0.07523899261447758)) * f3(0.09325557583628953)
w4 ( 0.9003661837331361 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.11132093203225149) - present_state_Q (0.07523899261447758)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6150764835253021 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.17097259090928255) - present_state_Q (0.001230066620173616)) * f3(0.002)
w4 ( 0.9003661837331361 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.17097259090928255) - present_state_Q (0.001230066620173616)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5762176213744175 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.5568795846830709) - present_state_Q (0.4078168775645286)) * f3(0.5166516160232009)
w4 ( 0.892844894542174 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.5568795846830709) - present_state_Q (0.4078168775645286)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5556729445767931 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.5395320108409033) - present_state_Q (0.5395320108409033)) * f3(0.7194048051085915)
w4 ( 0.8888467912055786 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.5395320108409033) - present_state_Q (0.5395320108409033)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5429761677149131 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.4648521609395607) - present_state_Q (0.4579988552058455)) * f3(0.6002817083187447)
w4 ( 0.8858856002580122 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.4648521609395607) - present_state_Q (0.4579988552058455)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5430163265977328 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01880366434059007) - present_state_Q (0.0010859523354298261)) * f3(0.002)
w4 ( 0.8858856002580122 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01880366434059007) - present_state_Q (0.0010859523354298261)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5237882828086962 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.44932351397558223) - present_state_Q (0.44932351397558223)) * f3(0.6316886346563358)
w4 ( 0.882232906307076 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.44932351397558223) - present_state_Q (0.44932351397558223)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4707817863771645 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.31505633050720877) - present_state_Q (0.3725606827454854)) * f3(0.5091613209798372)
w4 ( 0.8697402457107388 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.31505633050720877) - present_state_Q (0.3725606827454854)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.47081563372593827 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04967917269998945) - present_state_Q (0.03573117340118388)) * f3(0.002)
w4 ( 0.8704171926862141 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04967917269998945) - present_state_Q (0.03573117340118388)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.47198645385364985 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05376766663130986) - present_state_Q (0.05376766663130986)) * f3(0.07722624350819737)
w4 ( 0.8707204108862777 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05376766663130986) - present_state_Q (0.05376766663130986)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4732628729730016 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05823387621633104) - present_state_Q (0.05823387621633104)) * f3(0.08648440578182885)
w4 ( 0.8710155899090883 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05823387621633104) - present_state_Q (0.05823387621633104)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.47330335176954885 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.033405084820115824) - present_state_Q (0.0009465257459460032)) * f3(0.002)
w4 ( 0.8710155899090883 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.033405084820115824) - present_state_Q (0.0009465257459460032)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4733435297865782 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.018366918501720866) - present_state_Q (0.0009466067035390978)) * f3(0.002)
w4 ( 0.8710155899090883 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.018366918501720866) - present_state_Q (0.0009466067035390978)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4660517679987641 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.40659879827948536) - present_state_Q (0.3891784864813036)) * f3(0.49096621306400995)
w4 ( 0.8683422549893279 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.40659879827948536) - present_state_Q (0.3891784864813036)) * f4(0.18)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.46385612506558854 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.31853859511236415) - present_state_Q (0.283804904912791)) * f3(0.42263691061543307)
w4 ( 0.8678227445353124 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.31853859511236415) - present_state_Q (0.283804904912791)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4639441050235357 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.2191945889093742) - present_state_Q (0.2191945889093742)) * f3(0.3228776365201002)
w4 ( 0.8678445434951649 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.2191945889093742) - present_state_Q (0.2191945889093742)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.46418073200900606 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.21377160229275727) - present_state_Q (0.21377160229275727)) * f3(0.3111237695450868)
w4 ( 0.8679053879586571 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.21377160229275727) - present_state_Q (0.21377160229275727)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.46522917763377064 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.17992854617885976) - present_state_Q (0.17992854617885976)) * f3(0.2754406076873947)
w4 ( 0.8681337738092912 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.17992854617885976) - present_state_Q (0.17992854617885976)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.46527334479503063 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.21766264655324147) - present_state_Q (0.0009304583552675413)) * f3(0.002)
w4 ( 0.8681337738092912 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.21766264655324147) - present_state_Q (0.0009304583552675413)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.46696794126477903 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.12316272998397576) - present_state_Q (0.12316272998397576)) * f3(0.19007617784458275)
w4 ( 0.8684903879813489 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.12316272998397576) - present_state_Q (0.12316272998397576)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.46865737060533225 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13314703168633077) - present_state_Q (0.13314703168633077)) * f3(0.21073698528541615)
w4 ( 0.8688110586672781 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13314703168633077) - present_state_Q (0.13314703168633077)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.47034035310943706 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13322313926663432) - present_state_Q (0.13322313926663432)) * f3(0.21011234026417938)
w4 ( 0.8691314553659183 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13322313926663432) - present_state_Q (0.13322313926663432)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.47184494118789827 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07357512535024052) - present_state_Q (0.140305519072434)) * f3(0.22439125233475454)
w4 ( 0.8693996633397687 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07357512535024052) - present_state_Q (0.140305519072434)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4732907757628166 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.16319657846010005) - present_state_Q (0.16319657846010005)) * f3(0.2721669360345428)
w4 ( 0.8696121556573123 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.16319657846010005) - present_state_Q (0.16319657846010005)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4747316076215647 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1632337334209471) - present_state_Q (0.1632337334209471)) * f3(0.2713960503194452)
w4 ( 0.8698245142169969 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1632337334209471) - present_state_Q (0.1632337334209471)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.47616781068376246 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1632459448465429) - present_state_Q (0.1632459448465429)) * f3(0.27058018091826763)
w4 ( 0.8700368288155493 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1632459448465429) - present_state_Q (0.1632459448465429)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.47663405509140966 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.12045135375044694) - present_state_Q (0.060331493426317745)) * f3(0.09015888072811873)
w4 ( 0.8701402560994468 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.12045135375044694) - present_state_Q (0.060331493426317745)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.47662838334888885 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.11150274469638344) - present_state_Q (0.11150274469638344)) * f3(0.16091408835169457)
w4 ( 0.8701388462185398 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.11150274469638344) - present_state_Q (0.11150274469638344)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.47685934082541526 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.0882067268930691) - present_state_Q (0.0882067268930691)) * f3(0.11203943136814451)
w4 ( 0.8702213020017248 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.0882067268930691) - present_state_Q (0.0882067268930691)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4749962014246721 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.07147158207238213) - present_state_Q (0.07147158207238213)) * f3(0.113381769850121)
w4 ( 0.8698926531539944 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.07147158207238213) - present_state_Q (0.07147158207238213)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4761362266035825 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05294073144504036) - present_state_Q (0.05294073144504036)) * f3(0.07482771078032943)
w4 ( 0.8701973598373933 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05294073144504036) - present_state_Q (0.05294073144504036)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4761775836041579 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07737275330144364) - present_state_Q (0.000952272453207165)) * f3(0.002)
w4 ( 0.8701973598373933 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07737275330144364) - present_state_Q (0.000952272453207165)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4769047037620936 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.038323582293969136) - present_state_Q (0.038323582293969136)) * f3(0.04393242314953568)
w4 ( 0.8705283773892641 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.038323582293969136) - present_state_Q (0.038323582293969136)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.47749725136909793 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.034101293690375054) - present_state_Q (0.034101293690375054)) * f3(0.03499803212449761)
w4 ( 0.8708669950606215 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.034101293690375054) - present_state_Q (0.034101293690375054)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4775339443489052 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.018372334403950627) - present_state_Q (0.018372334403950627)) * f3(0.002)
w4 ( 0.8712339248586943 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.018372334403950627) - present_state_Q (0.018372334403950627)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.45416337991808475 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.5277871421212381) - present_state_Q (0.5277871421212381)) * f3(0.8498126624157147)
w4 ( 0.8673838068679667 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.5277871421212381) - present_state_Q (0.5277871421212381)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.45028664130137674 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.3149832162531182) - present_state_Q (0.3149832162531182)) * f3(0.46436407855472783)
w4 ( 0.8663819881324331 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.3149832162531182) - present_state_Q (0.3149832162531182)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4468663461033375 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.3017669885155143) - present_state_Q (0.3017669885155143)) * f3(0.47775965345213367)
w4 ( 0.8656660852357935 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.3017669885155143) - present_state_Q (0.3017669885155143)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.438192942441608 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.3788432192515672) - present_state_Q (0.3788432192515672)) * f3(0.6153143807336231)
w4 ( 0.8639745784678765 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.3788432192515672) - present_state_Q (0.3788432192515672)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.44042913888568824 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.33921916491090925) - present_state_Q (0.1225127133910974)) * f3(0.20071918493781477)
w4 ( 0.8644202152802765 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.33921916491090925) - present_state_Q (0.1225127133910974)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.43367747906576065 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.2718073388038263) - present_state_Q (0.3430588568657978)) * f3(0.5826518108838709)
w4 ( 0.8632614340504223 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.2718073388038263) - present_state_Q (0.3430588568657978)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4346553111448951 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.20814605933966365) - present_state_Q (0.19016803961656292)) * f3(0.31906741819202356)
w4 ( 0.8634453134483268 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.20814605933966365) - present_state_Q (0.19016803961656292)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4316751255327809 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.28797350610435085) - present_state_Q (0.28797350610435085)) * f3(0.5036125762547365)
w4 ( 0.8629719042043754 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.28797350610435085) - present_state_Q (0.28797350610435085)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.42980651823979044 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.2674041237685254) - present_state_Q (0.2674041237685254)) * f3(0.45952699078351605)
w4 ( 0.862646594513242 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.2674041237685254) - present_state_Q (0.2674041237685254)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.43147903002179216 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.15703569699806424) - present_state_Q (0.15703569699806424)) * f3(0.2850813750320435)
w4 ( 0.8628812660040489 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.15703569699806424) - present_state_Q (0.15703569699806424)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4330098206415417 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1667033537698975) - present_state_Q (0.1667033537698975)) * f3(0.30636043453388523)
w4 ( 0.8630811339304773 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.1667033537698975) - present_state_Q (0.1667033537698975)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4347985076858496 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.14258396834168222) - present_state_Q (0.14258396834168222)) * f3(0.24955721056017108)
w4 ( 0.8633678316444472 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.14258396834168222) - present_state_Q (0.14258396834168222)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4348428056254041 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.22359294787929196) - present_state_Q (0.0008695970153716992)) * f3(0.002)
w4 ( 0.8633678316444472 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.22359294787929196) - present_state_Q (0.0008695970153716992)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4258664190614602 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.4180396663140754) - present_state_Q (0.10307570727970858)) * f3(0.11791304056945005)
w4 ( 0.8588002012005573 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.4180396663140754) - present_state_Q (0.10307570727970858)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3664801648570415 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.36593008074077954) - present_state_Q (0.36593008074077954)) * f3(0.5769369022196672)
w4 ( 0.8443894821832235 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.36593008074077954) - present_state_Q (0.36593008074077954)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3671022384075169 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.3951974965114692) - present_state_Q (0.0397346491674024)) * f3(0.06234132625608853)
w4 ( 0.844589052384191 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.3951974965114692) - present_state_Q (0.0397346491674024)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3687793168850467 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.39548187320425043) - present_state_Q (0.18873973767154667)) * f3(0.3300786560345044)
w4 ( 0.844995519981382 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.39548187320425043) - present_state_Q (0.18873973767154667)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3613961870843216 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.3002877886940226) - present_state_Q (0.3483717699492189)) * f3(0.6238755445808855)
w4 ( 0.8433387181062646 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.3002877886940226) - present_state_Q (0.3483717699492189)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.361439223259543 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.15903668481161096) - present_state_Q (0.0007227923741686432)) * f3(0.002)
w4 ( 0.8433387181062646 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.15903668481161096) - present_state_Q (0.0007227923741686432)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.36146998508326705 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05132320153289496) - present_state_Q (0.05132320153289496)) * f3(0.002)
w4 ( 0.844261572817987 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05132320153289496) - present_state_Q (0.05132320153289496)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3368137885938238 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.4963403445480209) - present_state_Q (0.4963403445480209)) * f3(0.9994149107952205)
w4 ( 0.8403142718564954 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.4963403445480209) - present_state_Q (0.4963403445480209)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2943460358982139 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.41801033938876636) - present_state_Q (0.41801033938876636)) * f3(0.8917875440398904)
w4 ( 0.8336473415801969 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.41801033938876636) - present_state_Q (0.41801033938876636)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.29421775093295865 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.5916386579554448) - present_state_Q (0.0005886920717964278)) * f3(0.002)
w4 ( 0.8336473415801969 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.5916386579554448) - present_state_Q (0.0005886920717964278)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.28150448304763315 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.30951414895843754) - present_state_Q (0.30951414895843754)) * f3(0.7119776672364878)
w4 ( 0.8315045887714458 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.30951414895843754) - present_state_Q (0.30951414895843754)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3106819825704157 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.2919897657724383) - present_state_Q (0.2919897657724383)) * f3(0.5275081885162769)
w4 ( 0.8327080833476447 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.2919897657724383) - present_state_Q (0.2919897657724383)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2700367672572576 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.2234122191088488) - present_state_Q (0.2234122191088488)) * f3(0.4510767235828407)
w4 ( 0.8236973733756651 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.2234122191088488) - present_state_Q (0.2234122191088488)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2376512592083263 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.19813201939500635) - present_state_Q (0.1688929250241714)) * f3(0.38141893120796866)
w4 ( 0.8169047355909878 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.19813201939500635) - present_state_Q (0.1688929250241714)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.20329369860590696 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.19199247570803624) - present_state_Q (0.16220910553183016)) * f3(0.40755823052318024)
w4 ( 0.8101606567272995 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.19199247570803624) - present_state_Q (0.16220910553183016)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.18032801570958096 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.20964480142119646) - present_state_Q (0.10793556280606384)) * f3(0.2918237201116182)
w4 ( 0.8054388302313159 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.20964480142119646) - present_state_Q (0.10793556280606384)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.15010165436665515 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.161789760529635) - present_state_Q (0.1313041010766245)) * f3(0.3708186683860151)
w4 ( 0.7989178292311266 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.161789760529635) - present_state_Q (0.1313041010766245)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.12910023071570748 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.18145886627091415) - present_state_Q (0.08883789968651892)) * f3(0.2725008602019634)
w4 ( 0.7942936771527701 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.18145886627091415) - present_state_Q (0.08883789968651892)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10779568849990526 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.1710165302697757) - present_state_Q (0.08354321768171627)) * f3(0.27796694749193745)
w4 ( 0.7896950277648417 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.1710165302697757) - present_state_Q (0.08354321768171627)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09299231100322017 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.18804917976588648) - present_state_Q (0.05331309061482779)) * f3(0.20154135853265806)
w4 ( 0.7867569950742888 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.18804917976588648) - present_state_Q (0.05331309061482779)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.04631800634217177 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.17642202991811468) - present_state_Q (0.17642202991811468)) * f3(0.5434955875489351)
w4 ( 0.7730165178434679 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.17642202991811468) - present_state_Q (0.17642202991811468)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.050304364344793295 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.09320280287376466) - present_state_Q (0.09320280287376466)) * f3(0.3433038756450131)
w4 ( 0.774177692617604 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.09320280287376466) - present_state_Q (0.09320280287376466)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.05425466066694144 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.0771544712412509) - present_state_Q (0.0771544712412509)) * f3(0.3025633268620743)
w4 ( 0.7752221804246671 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.0771544712412509) - present_state_Q (0.0771544712412509)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.05628306047422698 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05708512017868867) - present_state_Q (0.05375572121942417)) * f3(0.13348881561353307)
w4 ( 0.7761338971694577 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05708512017868867) - present_state_Q (0.05375572121942417)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.05853921143397191 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.055005737338668745) - present_state_Q (0.055005737338668745)) * f3(0.1499155063247682)
w4 ( 0.7770368661878289 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.055005737338668745) - present_state_Q (0.055005737338668745)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.060377048329157385 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03755470117173806) - present_state_Q (0.03755470117173806)) * f3(0.1105793256461311)
w4 ( 0.7777016692636106 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03755470117173806) - present_state_Q (0.03755470117173806)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.062184675417228975 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.037679204829390675) - present_state_Q (0.037679204829390675)) * f3(0.10883503319046656)
w4 ( 0.7783660241262248 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.037679204829390675) - present_state_Q (0.037679204829390675)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.062225610129198784 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04797929199884425) - present_state_Q (0.00012436935083445796)) * f3(0.002)
w4 ( 0.7783660241262248 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04797929199884425) - present_state_Q (0.00012436935083445796)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.062265899074388786 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.015691771702782895) - present_state_Q (0.00012445122025839757)) * f3(0.002)
w4 ( 0.7783660241262248 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.015691771702782895) - present_state_Q (0.00012445122025839757)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.06270590088119643 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04845378890180355) - present_state_Q (0.04845378890180355)) * f3(0.02813462071971643)
w4 ( 0.779304373666155 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04845378890180355) - present_state_Q (0.04845378890180355)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.06506119129749041 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13144010059421007) - present_state_Q (0.14702618806753318)) * f3(0.3562262556959242)
w4 ( 0.7803622588180252 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13144010059421007) - present_state_Q (0.14702618806753318)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.06510325855863917 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.10466428126433132) - present_state_Q (0.00013012238259498083)) * f3(0.002)
w4 ( 0.7803622588180252 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.10466428126433132) - present_state_Q (0.00013012238259498083)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.06981624124221716 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.08778899087123881) - present_state_Q (0.08778899087123881)) * f3(0.38953518959354033)
w4 ( 0.7813301780837523 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.08778899087123881) - present_state_Q (0.08778899087123881)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.07415173618449827 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06880118180338084) - present_state_Q (0.06880118180338084)) * f3(0.31398669891584013)
w4 ( 0.782158651702014 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06880118180338084) - present_state_Q (0.06880118180338084)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.07829650007369558 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06925376054604296) - present_state_Q (0.06925376054604296)) * f3(0.3010616149077989)
w4 ( 0.7829846813950654 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06925376054604296) - present_state_Q (0.06925376054604296)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.08159769046390176 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06527798293733825) - present_state_Q (0.06527798293733825)) * f3(0.23371289950905494)
w4 ( 0.7838321802872038 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06527798293733825) - present_state_Q (0.06527798293733825)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.08499558546667792 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06685872596500633) - present_state_Q (0.06685872596500633)) * f3(0.2430068183920747)
w4 ( 0.7846711431669928 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06685872596500633) - present_state_Q (0.06685872596500633)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.08849734784772151 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06860862494988607) - present_state_Q (0.06860862494988607)) * f3(0.2532879353870275)
w4 ( 0.7855006565922634 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06860862494988607) - present_state_Q (0.06860862494988607)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.08978804730580485 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03832129526009671) - present_state_Q (0.03832129526009671)) * f3(0.07798277761138417)
w4 ( 0.7861626999293271 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03832129526009671) - present_state_Q (0.03832129526009671)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09196380185578316 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04359847920921248) - present_state_Q (0.04359847920921248)) * f3(0.13534063359961016)
w4 ( 0.7868057454041739 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04359847920921248) - present_state_Q (0.04359847920921248)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09334927641282066 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03689662411824255) - present_state_Q (0.02277901190058016)) * f3(0.07658336052201593)
w4 ( 0.7871675667051964 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03689662411824255) - present_state_Q (0.02277901190058016)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09435041189886245 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.020901243630550632) - present_state_Q (0.020901243630550632)) * f3(0.05525369338308353)
w4 ( 0.7875299444666614 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.020901243630550632) - present_state_Q (0.020901243630550632)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09498374211551157 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.019017971862479034) - present_state_Q (0.019017971862479034)) * f3(0.034630192994262926)
w4 ( 0.7878957121173089 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.019017971862479034) - present_state_Q (0.019017971862479034)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09502055633851594 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.00018996748423102315) - present_state_Q (0.015947881726577202)) * f3(0.002)
w4 ( 0.7882638543473526 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.00018996748423102315) - present_state_Q (0.015947881726577202)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.0857238124852342 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.15574046917142423) - present_state_Q (0.10878274432601187)) * f3(0.4811762605907907)
w4 ( 0.7867181847680816 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.15574046917142423) - present_state_Q (0.10878274432601187)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.08944024616731162 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07054046625503411) - present_state_Q (0.07054046625503411)) * f3(0.27223911877425006)
w4 ( 0.7875372662503044 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07054046625503411) - present_state_Q (0.07054046625503411)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09348479369025178 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07445264143512906) - present_state_Q (0.07445264143512906)) * f3(0.3041181864507427)
w4 ( 0.7883352219865547 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07445264143512906) - present_state_Q (0.07445264143512906)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09736618482933537 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05575202872463983) - present_state_Q (0.05575202872463983)) * f3(0.25906480497162465)
w4 ( 0.788934514683146 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05575202872463983) - present_state_Q (0.05575202872463983)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09740782974625664 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.08419316975980848) - present_state_Q (0.00019473236965867076)) * f3(0.002)
w4 ( 0.788934514683146 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.08419316975980848) - present_state_Q (0.00019473236965867076)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10116116070688641 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07882874284317595) - present_state_Q (0.055559144744405695)) * f3(0.24640487545614606)
w4 ( 0.7895438096013057 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07882874284317595) - present_state_Q (0.055559144744405695)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10461707966814597 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07897818363685724) - present_state_Q (0.054350252218064374)) * f3(0.22507155587096989)
w4 ( 0.7901579998658882 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07897818363685724) - present_state_Q (0.054350252218064374)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1077214649746334 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05292081988420738) - present_state_Q (0.05292081988420738)) * f3(0.20373824195038912)
w4 ( 0.790767484914305 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05292081988420738) - present_state_Q (0.05292081988420738)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10775857943196032 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01603079262823537) - present_state_Q (0.01603079262823537)) * f3(0.002)
w4 ( 0.7911386294875742 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01603079262823537) - present_state_Q (0.01603079262823537)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09712758111049387 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.16986897972873177) - present_state_Q (0.16986897972873177)) * f3(0.6953724203234861)
w4 ( 0.7893040445065039 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.16986897972873177) - present_state_Q (0.16986897972873177)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09962627380419949 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.0702167357224543) - present_state_Q (0.046711016674539085)) * f3(0.1558656637094332)
w4 ( 0.7899452871340947 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.0702167357224543) - present_state_Q (0.046711016674539085)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1031669611490814 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.055041928013415384) - present_state_Q (0.055041928013415384)) * f3(0.23532062008188212)
w4 ( 0.7905471361932465 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.055041928013415384) - present_state_Q (0.055041928013415384)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10320858948619745 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.0834801950255066) - present_state_Q (0.00020633392229816281)) * f3(0.002)
w4 ( 0.7905471361932465 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.0834801950255066) - present_state_Q (0.00020633392229816281)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10744526385944772 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.08210774291383774) - present_state_Q (0.08210774291383774)) * f3(0.3359692726629132)
w4 ( 0.7913037543815117 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.08210774291383774) - present_state_Q (0.08210774291383774)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.11169634546832251 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06365889055639229) - present_state_Q (0.06365889055639229)) * f3(0.2978887968761543)
w4 ( 0.7918745823755087 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06365889055639229) - present_state_Q (0.06365889055639229)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.11567514929945133 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06261287019195165) - present_state_Q (0.06261287019195165)) * f3(0.2769820871686926)
w4 ( 0.7924491760428176 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06261287019195165) - present_state_Q (0.06261287019195165)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1177403343013426 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.0468318652917948) - present_state_Q (0.0468318652917948)) * f3(0.13083102413729825)
w4 ( 0.7930805813277672 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.0468318652917948) - present_state_Q (0.0468318652917948)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.11949448884805239 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04464631945715909) - present_state_Q (0.04464631945715909)) * f3(0.10975929600278911)
w4 ( 0.7937198545777214 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04464631945715909) - present_state_Q (0.04464631945715909)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.11953239624791426 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05650385378590085) - present_state_Q (0.016113386069250533)) * f3(0.002)
w4 ( 0.7940989285763401 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05650385378590085) - present_state_Q (0.016113386069250533)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.12180152106776773 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.031700147148444255) - present_state_Q (0.031700147148444255)) * f3(0.13233373607026194)
w4 ( 0.7944418683114729 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.031700147148444255) - present_state_Q (0.031700147148444255)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.12386865992881467 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.030478989079169513) - present_state_Q (0.030478989079169513)) * f3(0.11978628497440856)
w4 ( 0.7947870061311304 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.030478989079169513) - present_state_Q (0.030478989079169513)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.12609822728323708 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03202990768177914) - present_state_Q (0.03202990768177914)) * f3(0.13025221689189648)
w4 ( 0.7951293522973032 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03202990768177914) - present_state_Q (0.03202990768177914)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1261187903978757 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.030677696477130464) - present_state_Q (0.00025219645456647414)) * f3(0.002)
w4 ( 0.7951293522973032 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.030677696477130464) - present_state_Q (0.00025219645456647414)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.12314656506910605 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.193592574297283) - present_state_Q (0.1766958316818646)) * f3(0.5183820916295698)
w4 ( 0.7943266402577733 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.193592574297283) - present_state_Q (0.1766958316818646)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.12652899138864585 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.12916972174675467) - present_state_Q (0.12916972174675467)) * f3(0.403885059181849)
w4 ( 0.7951641127620526 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.12916972174675467) - present_state_Q (0.12916972174675467)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.12735858968259514 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.19525640097213515) - present_state_Q (0.02119589405378393)) * f3(0.041829241982069665)
w4 ( 0.7955607722541395 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.19525640097213515) - present_state_Q (0.02119589405378393)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.13118014231459135 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.16327980324432007) - present_state_Q (0.08471340821052248)) * f3(0.2903593857896478)
w4 ( 0.7963504596868229 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.16327980324432007) - present_state_Q (0.08471340821052248)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.022629571678857888 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.28019780840955943) - present_state_Q (0.28019780840955943)) * f3(1.0868683767391547)
w4 ( 0.7779901478010683 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.28019780840955943) - present_state_Q (0.28019780840955943)) * f4(0.18)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.02951944161487417 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.12641649848682654) - present_state_Q (0.12715769278625283)) * f3(0.8059839732248867)
w4 ( 0.7791869231999423 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.12641649848682654) - present_state_Q (0.12715769278625283)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.033799463186636486 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07093052876828486) - present_state_Q (0.07166411566587012)) * f3(0.31603449454050603)
w4 ( 0.78027035469763 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07093052876828486) - present_state_Q (0.07166411566587012)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.03751420412392213 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07168915663682443) - present_state_Q (0.07168915663682443)) * f3(0.2741915813822214)
w4 ( 0.7813541927698449 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07168915663682443) - present_state_Q (0.07168915663682443)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.041489917894577406 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05690549338073238) - present_state_Q (0.05690549338073238)) * f3(0.26721190142880874)
w4 ( 0.7822469031055889 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05690549338073238) - present_state_Q (0.05690549338073238)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.04525797867469186 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05747893148756596) - present_state_Q (0.05747893148756596)) * f3(0.25413685628451693)
w4 ( 0.783136516875556 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05747893148756596) - present_state_Q (0.05747893148756596)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.04776538066696917 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05804615175982213) - present_state_Q (0.03809178535119152)) * f3(0.14950567555844022)
w4 ( 0.7838073681948551 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05804615175982213) - present_state_Q (0.03809178535119152)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.05171668238929848 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05995167679038873) - present_state_Q (0.05995167679038873)) * f3(0.27055651013861026)
w4 ( 0.784683629140187 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05995167679038873) - present_state_Q (0.05995167679038873)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.05557645313006748 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06082295976027412) - present_state_Q (0.06082295976027412)) * f3(0.265715845970554)
w4 ( 0.7855551851574815 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06082295976027412) - present_state_Q (0.06082295976027412)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.05954201218567371 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06246118301395924) - present_state_Q (0.06246118301395924)) * f3(0.27579795113297373)
w4 ( 0.7864178947692061 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06246118301395924) - present_state_Q (0.06246118301395924)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.060829849160569195 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06439328093769615) - present_state_Q (0.035954500486846036)) * f3(0.07553968250270177)
w4 ( 0.7870998340796338 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.06439328093769615) - present_state_Q (0.035954500486846036)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.06087113268668339 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.0653929026930683) - present_state_Q (0.00012165969832113839)) * f3(0.002)
w4 ( 0.7870998340796338 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.0653929026930683) - present_state_Q (0.00012165969832113839)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.0648256817026141 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.046724305856789994) - present_state_Q (0.046724305856789994)) * f3(0.2503701150436901)
w4 ( 0.7877316265785493 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.046724305856789994) - present_state_Q (0.046724305856789994)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.06801268295355221 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.02754628129802556) - present_state_Q (0.02754628129802556)) * f3(0.18189779816814597)
w4 ( 0.7880820432722129 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.02754628129802556) - present_state_Q (0.02754628129802556)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.07250744534987466 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05140855273545751) - present_state_Q (0.05140855273545751)) * f3(0.2923759237398297)
w4 ( 0.7886969724823653 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05140855273545751) - present_state_Q (0.05140855273545751)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.07254851236831177 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05480107076257028) - present_state_Q (0.0001450148906997493)) * f3(0.002)
w4 ( 0.7886969724823653 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05480107076257028) - present_state_Q (0.0001450148906997493)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.07635966512215718 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04931555452750315) - present_state_Q (0.04931555452750315)) * f3(0.24490751151458795)
w4 ( 0.7893194364860663 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04931555452750315) - present_state_Q (0.04931555452750315)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.0802412286277382 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05078228357106156) - present_state_Q (0.05078228357106156)) * f3(0.25156613875778905)
w4 ( 0.7899366202652105 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05078228357106156) - present_state_Q (0.05078228357106156)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.08357408390648305 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03136806093210323) - present_state_Q (0.03136806093210323)) * f3(0.19403153208221108)
w4 ( 0.7902801577555327 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03136806093210323) - present_state_Q (0.03136806093210323)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.08672648756444247 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.031124037384253168) - present_state_Q (0.031124037384253168)) * f3(0.1832916798260498)
w4 ( 0.7906241344882411 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.031124037384253168) - present_state_Q (0.031124037384253168)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09061207913058425 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.14507201605140455) - present_state_Q (0.052414537187211216)) * f3(0.23971421409444033)
w4 ( 0.7912725051459129 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.14507201605140455) - present_state_Q (0.052414537187211216)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.0936973574815132 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.055211125925779814) - present_state_Q (0.08686202613161634)) * f3(0.26001197573217394)
w4 ( 0.7922217778376005 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.055211125925779814) - present_state_Q (0.08686202613161634)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09763450897539909 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05640880397396966) - present_state_Q (0.05640880397396966)) * f3(0.2638274282745164)
w4 ( 0.7928187061432942 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05640880397396966) - present_state_Q (0.05640880397396966)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10132996119616292 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05580193647877167) - present_state_Q (0.05580193647877167)) * f3(0.24672821613830867)
w4 ( 0.7934178191719706 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05580193647877167) - present_state_Q (0.05580193647877167)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10473075614268629 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.054575969300742475) - present_state_Q (0.054575969300742475)) * f3(0.22539490062223083)
w4 ( 0.794021345682488 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.054575969300742475) - present_state_Q (0.054575969300742475)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10477109990981656 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.019282971636828822) - present_state_Q (0.00020946151228537258)) * f3(0.002)
w4 ( 0.794021345682488 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.019282971636828822) - present_state_Q (0.00020946151228537258)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10481137980075887 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016089969113469393) - present_state_Q (0.00020954219981963312)) * f3(0.002)
w4 ( 0.794021345682488 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016089969113469393) - present_state_Q (0.00020954219981963312)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10485165967720042 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016090049673251276) - present_state_Q (0.00020962275960151775)) * f3(0.002)
w4 ( 0.794021345682488 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016090049673251276) - present_state_Q (0.00020962275960151775)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10489193953914121 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01609013023300416) - present_state_Q (0.00020970331935440086)) * f3(0.002)
w4 ( 0.794021345682488 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01609013023300416) - present_state_Q (0.00020970331935440086)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10493228383162334 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01931246289719687) - present_state_Q (0.00020978387907828242)) * f3(0.002)
w4 ( 0.794021345682488 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01931246289719687) - present_state_Q (0.00020978387907828242)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10497256366453943 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016090291481313006) - present_state_Q (0.00020986456766324669)) * f3(0.002)
w4 ( 0.794021345682488 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016090291481313006) - present_state_Q (0.00020986456766324669)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10501284348295478 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016090372040978837) - present_state_Q (0.00020994512732907885)) * f3(0.002)
w4 ( 0.794021345682488 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016090372040978837) - present_state_Q (0.00020994512732907885)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1050531232868694 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01609045260061567) - present_state_Q (0.00021002568696590955)) * f3(0.002)
w4 ( 0.794021345682488 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01609045260061567) - present_state_Q (0.00021002568696590955)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10507346761876564 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.019317657277547685) - present_state_Q (0.0002101062465737388)) * f3(0.002)
w4 ( 0.794021345682488 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.019317657277547685) - present_state_Q (0.0002101062465737388)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10505374740085557 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.01609057384888729) - present_state_Q (0.00021014693523753128)) * f3(0.002)
w4 ( 0.794021345682488 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.01609057384888729) - present_state_Q (0.00021014693523753128)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.002464427282189652 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.2088016489451514) - present_state_Q (0.2088016489451514)) * f3(0.9489809830690789)
w4 ( 0.7764173907434309 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.2088016489451514) - present_state_Q (0.2088016489451514)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.06606314734278348 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12714479642307502) - present_state_Q (0.14294021197339773)) * f3(1.2924226503247542)
w4 ( 0.7668733275614712 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.12714479642307502) - present_state_Q (0.14294021197339773)) * f4(0.18)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.052235521082494595 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04299339931121773) - present_state_Q (0.04866661021475652)) * f3(0.8884780396443097)
w4 ( 0.7690521857775003 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04299339931121773) - present_state_Q (0.04866661021475652)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.04894140296184455 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.09489225761185022) - present_state_Q (0.03621275918449514)) * f3(0.19010764622165863)
w4 ( 0.7700918445769604 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.09489225761185022) - present_state_Q (0.03621275918449514)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.043956059087688265 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05550586640598076) - present_state_Q (0.01780772191034006)) * f3(0.265541056983393)
w4 ( 0.7708428160358815 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05550586640598076) - present_state_Q (0.01780772191034006)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.03853630379489573 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01787990052256497) - present_state_Q (0.01787990052256497)) * f3(0.2946991242556261)
w4 ( 0.7715784483940002 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01787990052256497) - present_state_Q (0.01787990052256497)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.03277086616388165 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01873161145090282) - present_state_Q (0.01873161145090282)) * f3(0.3148077342711849)
w4 ( 0.772311014592777 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01873161145090282) - present_state_Q (0.01873161145090282)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.029605678866071506 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.02504732371288921) - present_state_Q (0.02504732371288921)) * f3(0.17836320961403385)
w4 ( 0.7730208442274106 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.02504732371288921) - present_state_Q (0.02504732371288921)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.025852308813711415 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.024670920322309758) - present_state_Q (0.024670920322309758)) * f3(0.2111052232600263)
w4 ( 0.7737320289142503 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.024670920322309758) - present_state_Q (0.024670920322309758)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.02182132376147874 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.025076016248699255) - present_state_Q (0.025076016248699255)) * f3(0.22718531447975449)
w4 ( 0.774441755255755 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.025076016248699255) - present_state_Q (0.025076016248699255)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.0155657869558962 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03822344949300216) - present_state_Q (0.03822344949300216)) * f3(0.37775232668948505)
w4 ( 0.7754353486284927 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03822344949300216) - present_state_Q (0.03822344949300216)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.008114074628426279 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03947381641010199) - present_state_Q (0.03947381641010199)) * f3(0.45306443725520823)
w4 ( 0.7764221900198782 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.03947381641010199) - present_state_Q (0.03947381641010199)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.0012363184988798143 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04312314917241912) - present_state_Q (0.04312314917241912)) * f3(0.42668848726685404)
w4 ( 0.7773893250143472 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04312314917241912) - present_state_Q (0.04312314917241912)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.005516371469618235 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04611662530958179) - present_state_Q (0.04611662530958179)) * f3(0.42605056201641794)
w4 ( 0.7783402952376755 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04611662530958179) - present_state_Q (0.04611662530958179)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.007059428484229238 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01609092091967587) - present_state_Q (0.031634396686402035)) * f3(0.09078157257050616)
w4 ( 0.7790201940192977 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01609092091967587) - present_state_Q (0.031634396686402035)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.00766591185074856 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04797295301317075) - present_state_Q (0.01580694592165266)) * f3(0.03209070561063159)
w4 ( 0.7793981747180571 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.04797295301317075) - present_state_Q (0.01580694592165266)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.007703437061597661 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.032293495635642294) - present_state_Q (0.015603295318062638)) * f3(0.002)
w4 ( 0.779773426826548 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.032293495635642294) - present_state_Q (0.015603295318062638)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.007744077314028949 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.032166690305645444) - present_state_Q (1.540687412319532e-05)) * f3(0.002)
w4 ( 0.779773426826548 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.032166690305645444) - present_state_Q (1.540687412319532e-05)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.007784406560101511 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016617185174396983) - present_state_Q (1.5488154628057898e-05)) * f3(0.002)
w4 ( 0.779773426826548 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016617185174396983) - present_state_Q (1.5488154628057898e-05)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.00782473511895654 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01658363088266021) - present_state_Q (1.5568813120203023e-05)) * f3(0.002)
w4 ( 0.779773426826548 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.01658363088266021) - present_state_Q (1.5568813120203023e-05)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.010331045876337819 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016655476659092967) - present_state_Q (0.016655476659092967)) * f3(0.13546888251769482)
w4 ( 0.7801434469685616 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016655476659092967) - present_state_Q (0.016655476659092967)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.010371379596731234 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016892640588287003) - present_state_Q (2.0662091752675637e-05)) * f3(0.002)
w4 ( 0.7801434469685616 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016892640588287003) - present_state_Q (2.0662091752675637e-05)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.010411715180814945 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016986631777457496) - present_state_Q (2.074275919346247e-05)) * f3(0.002)
w4 ( 0.7801434469685616 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.016986631777457496) - present_state_Q (2.074275919346247e-05)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.010452063494342006 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.017623910656630232) - present_state_Q (2.0823430361629892e-05)) * f3(0.002)
w4 ( 0.7801434469685616 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.017623910656630232) - present_state_Q (2.0823430361629892e-05)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.013833979286898718 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.017521551169079976) - present_state_Q (0.017521551169079976)) * f3(0.18356970666580624)
w4 ( 0.7805119081764573 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.017521551169079976) - present_state_Q (0.017521551169079976)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.01701366288487897 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.018003515324380628) - present_state_Q (0.018003515324380628)) * f3(0.1729999092248172)
w4 ( 0.7808795018488734 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.018003515324380628) - present_state_Q (0.018003515324380628)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.019646655153291056 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.018055512947700518) - present_state_Q (0.018055512947700518)) * f3(0.14329206633627217)
w4 ( 0.7812470019255676 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.018055512947700518) - present_state_Q (0.018055512947700518)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.019687011906340212 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.018230585560946522) - present_state_Q (3.929331030658211e-05)) * f3(0.002)
w4 ( 0.7812470019255676 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.018230585560946522) - present_state_Q (3.929331030658211e-05)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.015546131700986284 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.17129888647126754) - present_state_Q (0.17129888647126754)) * f3(0.76443729285841)
w4 ( 0.7801636219690848 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.17129888647126754) - present_state_Q (0.17129888647126754)) * f4(0.2)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.015378738131204637 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.15122011146831835) - present_state_Q (0.03268800003523445)) * f3(0.09529413393410692)
w4 ( 0.7800933580135312 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( 0.15122011146831835) - present_state_Q (0.03268800003523445)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.015419044632202115 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.015632624636533032) - present_state_Q (3.0757476262409275e-05)) * f3(0.002)
w4 ( 0.7800933580135312 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.015632624636533032) - present_state_Q (3.0757476262409275e-05)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.0032140528418566922 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.1012101919068827) - present_state_Q (0.06620735955631515)) * f3(0.24644139801610812)
w4 ( 0.7740446672906062 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.1012101919068827) - present_state_Q (0.06620735955631515)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.028980932897666886 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.0916414887857838) - present_state_Q (0.06082179367486008)) * f3(0.3428007449161735)
w4 ( 0.768031406132236 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.0916414887857838) - present_state_Q (0.06082179367486008)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.07539935097065802 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.10490546642293923) - present_state_Q (0.10597393572586887)) * f3(0.583524668270783)
w4 ( 0.7553036719068987 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.10490546642293923) - present_state_Q (0.10597393572586887)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.1175486973255826 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.058501233908225946) - present_state_Q (0.04780308710905275)) * f3(0.5680865016523006)
w4 ( 0.7464002363422799 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.058501233908225946) - present_state_Q (0.04780308710905275)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.15765932990931253 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.02424797859005781) - present_state_Q (0.02424797859005781)) * f3(0.5556850161435171)
w4 ( 0.7377383581735073 ) += alpha ( 0.1) * (reward ( -0.7) + discount_factor ( 0.1) * next_state_max_Q( 0.02424797859005781) - present_state_Q (0.02424797859005781)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.15769908153577888 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.009265490083907962) - present_state_Q (-0.00031531865981862506)) * f3(0.002)
w4 ( 0.7377383581735073 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.009265490083907962) - present_state_Q (-0.00031531865981862506)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.15771865914360844 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.017965626891064512) - present_state_Q (-0.00031539816307155777)) * f3(0.002)
w4 ( 0.7377383581735073 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.017965626891064512) - present_state_Q (-0.00031539816307155777)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.14938297223829528 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.023640491859216996) - present_state_Q (-0.004526337374938766)) * f3(0.402903539592985)
w4 ( 0.7393934812659941 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.023640491859216996) - present_state_Q (-0.004526337374938766)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.1422991599641003 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.014489103680843293) - present_state_Q (0.02779119999477244)) * f3(0.4079180969832485)
w4 ( 0.7414773737904738 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.014489103680843293) - present_state_Q (0.02779119999477244)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( -0.13585267637344436 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.014544949155881276) - present_state_Q (0.011122038037283587)) * f3(0.3386959689580276)
w4 ( 0.7430000334455003 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.014544949155881276) - present_state_Q (0.011122038037283587)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9607876427357936 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.7151675375175999) - present_state_Q (0.4863805078036324)) * f3(0.3863805078036324)
w4 ( 0.9898513624594812 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.7151675375175999) - present_state_Q (0.4863805078036324)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.00005604 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.022) - present_state_Q (0.022)) * f3(0.002)
w4 ( 1.0005604 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.022) - present_state_Q (0.022)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8974999814511898 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.6370213704343052) - present_state_Q (0.6370213704343052)) * f3(0.5393899587046185)
w4 ( 0.9757715316587907 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.6370213704343052) - present_state_Q (0.6370213704343052)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9182365991872359 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.7720151563825535) - present_state_Q (0.7720151563825535)) * f3(0.6319012886343384)
w4 ( 0.9824330090295798 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.7720151563825535) - present_state_Q (0.7720151563825535)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8407632511152112 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.5733644262015463) - present_state_Q (0.5733644262015463)) * f3(0.5083808934065205)
w4 ( 0.962379195855814 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.5733644262015463) - present_state_Q (0.5733644262015463)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.808288512114216 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.3846578248558117) - present_state_Q (0.3700711595283116)) * f3(0.3485890034692835)
w4 ( 0.9549263528394721 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.3846578248558117) - present_state_Q (0.3700711595283116)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9189581062713799 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12336380718651374) - present_state_Q (0.11159860341027136)) * f3(0.03594276542354985)
w4 ( 0.9840389112480468 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12336380718651374) - present_state_Q (0.11159860341027136)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9211830879155504 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1331944451418366) - present_state_Q (0.1331944451418366)) * f3(0.12352431100200084)
w4 ( 0.9843991612467915 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1331944451418366) - present_state_Q (0.1331944451418366)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9234744499271814 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14274057066084034) - present_state_Q (0.14274057066084034)) * f3(0.13358103188188944)
w4 ( 0.984742228219602 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14274057066084034) - present_state_Q (0.14274057066084034)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.925756913140531 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14227500692400621) - present_state_Q (0.14227500692400621)) * f3(0.13273801172223007)
w4 ( 0.9850861332071388 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14227500692400621) - present_state_Q (0.14227500692400621)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9258191970400863 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1327101160306363) - present_state_Q (0.001851513826281062)) * f3(0.002)
w4 ( 0.9850861332071388 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1327101160306363) - present_state_Q (0.001851513826281062)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8091834769576707 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.26457607229984187) - present_state_Q (0.2836745993566313)) * f3(0.20918698519372517)
w4 ( 0.9554397489339523 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.26457607229984187) - present_state_Q (0.2836745993566313)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8115257509794717 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15905263374496856) - present_state_Q (0.15905263374496856)) * f3(0.14932959857499845)
w4 ( 0.9560671594524704 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15905263374496856) - present_state_Q (0.15905263374496856)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9400182422774115 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.6332661117845605) - present_state_Q (0.6332661117845605)) * f3(0.5131701057318353)
w4 ( 0.9865211259927267 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.6332661117845605) - present_state_Q (0.6332661117845605)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8609440212254036 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.7296144360202583) - present_state_Q (0.7296144360202583)) * f3(0.6292446803460192)
w4 ( 0.9689279840988714 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.7296144360202583) - present_state_Q (0.7296144360202583)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8182464667315142 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.49182520332227697) - present_state_Q (0.5324538343106797)) * f3(0.4834024814138926)
w4 ( 0.9583287283311299 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.49182520332227697) - present_state_Q (0.5324538343106797)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7801102991780098 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.4218398823614912) - present_state_Q (0.40183450961261413)) * f3(0.39739641363195644)
w4 ( 0.9506515241601182 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.4218398823614912) - present_state_Q (0.40183450961261413)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7345761346363815 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.44887200765545876) - present_state_Q (0.44887200765545876)) * f3(0.4535343984206436)
w4 ( 0.9406116760912191 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.44887200765545876) - present_state_Q (0.44887200765545876)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7181174532772931 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.4596199707196134) - present_state_Q (0.21387784004246382)) * f3(0.2143292329459148)
w4 ( 0.9360041810333961 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.4596199707196134) - present_state_Q (0.21387784004246382)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6799363428547035 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2885570789539719) - present_state_Q (0.3671095772781846)) * f3(0.4069379479106906)
w4 ( 0.9284981500783338 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2885570789539719) - present_state_Q (0.3671095772781846)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6823850294567153 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16678646179920462) - present_state_Q (0.16678646179920462)) * f3(0.16336319416042847)
w4 ( 0.9293975031846181 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16678646179920462) - present_state_Q (0.16678646179920462)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6847741338245624 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1606829503836397) - present_state_Q (0.1606829503836397)) * f3(0.15375351988025668)
w4 ( 0.9303298152525464 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1606829503836397) - present_state_Q (0.1606829503836397)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6872705530662324 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.13116665264274183) - present_state_Q (0.13116665264274183)) * f3(0.137203576174667)
w4 ( 0.9310576153030325 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.13116665264274183) - present_state_Q (0.13116665264274183)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.690010211080035 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16883399959725348) - present_state_Q (0.15021284729119283)) * f3(0.16437564824370487)
w4 ( 0.9317242975137067 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16883399959725348) - present_state_Q (0.15021284729119283)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6927007262274153 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1494411683059407) - present_state_Q (0.1494411683059407)) * f3(0.16256599482754824)
w4 ( 0.9323863093078053 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1494411683059407) - present_state_Q (0.1494411683059407)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6948864025366511 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10614335188936161) - present_state_Q (0.08607576653492241)) * f3(0.09734079638690823)
w4 ( 0.9328353864451133 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10614335188936161) - present_state_Q (0.08607576653492241)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6966599388917388 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07644761144711026) - present_state_Q (0.07066040640886574)) * f3(0.07483769791742412)
w4 ( 0.933309355154585 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07644761144711026) - present_state_Q (0.07066040640886574)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6986121875534397 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07780531834883747) - present_state_Q (0.07780531834883747)) * f3(0.08488952492348784)
w4 ( 0.9337693055815571 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07780531834883747) - present_state_Q (0.07780531834883747)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7009565426910639 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09504336340174555) - present_state_Q (0.09504336340174555)) * f3(0.1093138348438456)
w4 ( 0.934198227527434 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09504336340174555) - present_state_Q (0.09504336340174555)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7034456453624798 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10276307526165676) - present_state_Q (0.10276307526165676)) * f3(0.11994910610052568)
w4 ( 0.934613253991963 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10276307526165676) - present_state_Q (0.10276307526165676)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7059059122261072 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10171508505265468) - present_state_Q (0.10171508505265468)) * f3(0.11802307757557366)
w4 ( 0.9350301668388683 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10171508505265468) - present_state_Q (0.10171508505265468)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7078716916456458 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07942480346533401) - present_state_Q (0.07942480346533401)) * f3(0.08602307910562762)
w4 ( 0.9354872021926307 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07942480346533401) - present_state_Q (0.07942480346533401)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.707928069057909 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.020125487427143905) - present_state_Q (0.020125487427143905)) * f3(0.002)
w4 ( 0.9360509763152618 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.020125487427143905) - present_state_Q (0.020125487427143905)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7011900349594576 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4781952091787959) - present_state_Q (0.4781952091787959)) * f3(0.5168167614936542)
w4 ( 0.9344864680561308 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4781952091787959) - present_state_Q (0.4781952091787959)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6942160914951441 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.48073934020788256) - present_state_Q (0.48073934020788256)) * f3(0.5256791250070448)
w4 ( 0.9328944831818856 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.48073934020788256) - present_state_Q (0.48073934020788256)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6911511446795601 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4083672062123498) - present_state_Q (0.4083672062123498)) * f3(0.453861213754889)
w4 ( 0.9322191783259745 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4083672062123498) - present_state_Q (0.4083672062123498)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6934216429985073 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.31815236970600796) - present_state_Q (0.2516250056041113)) * f3(0.28313901584476414)
w4 ( 0.9327003197141734 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.31815236970600796) - present_state_Q (0.2516250056041113)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6956657422319931 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1252510250919823) - present_state_Q (0.08794301230341536)) * f3(0.09992333900844375)
w4 ( 0.933149483894585 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1252510250919823) - present_state_Q (0.08794301230341536)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6977207028732432 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08181592994758799) - present_state_Q (0.08181592994758799)) * f3(0.09078058101161438)
w4 ( 0.9336022152206793 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08181592994758799) - present_state_Q (0.08181592994758799)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6997355562229065 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0804366001107869) - present_state_Q (0.0804366001107869)) * f3(0.08852332394900177)
w4 ( 0.9340574293404799 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0804366001107869) - present_state_Q (0.0804366001107869)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.701565942251012 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07343754892091882) - present_state_Q (0.07343754892091882)) * f3(0.07825299121525006)
w4 ( 0.9345252417524222 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07343754892091882) - present_state_Q (0.07343754892091882)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6389132847734341 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.5366890547110712) - present_state_Q (0.5366890547110712)) * f3(0.578499463020572)
w4 ( 0.9193629596630627 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.5366890547110712) - present_state_Q (0.5366890547110712)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6399131291020486 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.24814154537904054) - present_state_Q (0.2930504046770792)) * f3(0.31477528093987006)
w4 ( 0.9196805971616709 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.24814154537904054) - present_state_Q (0.2930504046770792)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6426128320209572 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.20637819771987403) - present_state_Q (0.20637819771987403)) * f3(0.23627794932468396)
w4 ( 0.9203661548939837 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.20637819771987403) - present_state_Q (0.20637819771987403)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6446977521775262 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07633153779180085) - present_state_Q (0.07633153779180085)) * f3(0.09013859015506265)
w4 ( 0.9208287581259584 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07633153779180085) - present_state_Q (0.07633153779180085)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6404645936102505 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4008389478412894) - present_state_Q (0.4305587407195388)) * f3(0.46788237365971647)
w4 ( 0.9195621102828627 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4008389478412894) - present_state_Q (0.4305587407195388)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6432140735418157 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3149869860393332) - present_state_Q (0.12007058091832418)) * f3(0.1300432488196123)
w4 ( 0.9204078227536051 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3149869860393332) - present_state_Q (0.12007058091832418)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.642929402213091 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3414893070463095) - present_state_Q (0.3414893070463095)) * f3(0.3878157133555508)
w4 ( 0.9203344189901883 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3414893070463095) - present_state_Q (0.3414893070463095)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6459728945530284 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.192224595379076) - present_state_Q (0.15875096713518852)) * f3(0.18965937777281225)
w4 ( 0.9209763049597992 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.192224595379076) - present_state_Q (0.15875096713518852)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6488693103738447 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18223261737471041) - present_state_Q (0.14460385479382518)) * f3(0.16682557968628003)
w4 ( 0.9216707825875738 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18223261737471041) - present_state_Q (0.14460385479382518)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6519103910226758 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17817604994937922) - present_state_Q (0.17817604994937922)) * f3(0.21777762699928163)
w4 ( 0.9222293488077561 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17817604994937922) - present_state_Q (0.17817604994937922)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6548881933491206 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16510559814262338) - present_state_Q (0.16510559814262338)) * f3(0.1966779881958551)
w4 ( 0.9228349686544426 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16510559814262338) - present_state_Q (0.16510559814262338)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6549526744313058 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2371518731258011) - present_state_Q (0.0013097763866982413)) * f3(0.002)
w4 ( 0.9228349686544426 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2371518731258011) - present_state_Q (0.0013097763866982413)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6578912794580352 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16101475183214087) - present_state_Q (0.16101475183214087)) * f3(0.18948140519270362)
w4 ( 0.9234553155478469 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16101475183214087) - present_state_Q (0.16101475183214087)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6609528052759166 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.23153312769001155) - present_state_Q (0.16165392989244814)) * f3(0.1895688864781335)
w4 ( 0.9241013130793531 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.23153312769001155) - present_state_Q (0.16165392989244814)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6626119247591549 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08628390243447126) - present_state_Q (0.08628390243447126)) * f3(0.07461932155762381)
w4 ( 0.924990691030589 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08628390243447126) - present_state_Q (0.08628390243447126)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6626683562523742 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.01982503767013009) - present_state_Q (0.01982503767013009)) * f3(0.002)
w4 ( 0.9255550059627827 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.01982503767013009) - present_state_Q (0.01982503767013009)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6633816714404396 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.368074982648772) - present_state_Q (0.034127995162361965)) * f3(0.02356668293537573)
w4 ( 0.9261603649689878 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.368074982648772) - present_state_Q (0.034127995162361965)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6639441722567315 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.31620871799340144) - present_state_Q (0.31620871799340144)) * f3(0.36497223124986555)
w4 ( 0.9262836621994353 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.31620871799340144) - present_state_Q (0.31620871799340144)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6660163801873389 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2577018224727932) - present_state_Q (0.2577018224727932)) * f3(0.30443041928331016)
w4 ( 0.9266920723580822 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2577018224727932) - present_state_Q (0.2577018224727932)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6553631293152914 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.2651347268645002) - present_state_Q (0.2651347268645002)) * f3(0.3146066804904666)
w4 ( 0.9246603448330138 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.2651347268645002) - present_state_Q (0.2651347268645002)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6536284806467402 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.1990757706439933) - present_state_Q (0.1990757706439933)) * f3(0.21910928999627807)
w4 ( 0.9241853356715363 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.1990757706439933) - present_state_Q (0.1990757706439933)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6548009018831038 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13766212681293735) - present_state_Q (0.13766212681293735)) * f3(0.1540549660358165)
w4 ( 0.9244897520150097 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.13766212681293735) - present_state_Q (0.13766212681293735)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.656650162881499 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0940039807547117) - present_state_Q (0.06882271725675804)) * f3(0.07686752121401837)
w4 ( 0.9249709073766471 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0940039807547117) - present_state_Q (0.06882271725675804)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6582671512412026 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06197617706754126) - present_state_Q (0.06197617706754126)) * f3(0.06620992634681529)
w4 ( 0.9254593502579256 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06197617706754126) - present_state_Q (0.06197617706754126)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6608295630600353 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.24873213736385166) - present_state_Q (0.15457378387496054)) * f3(0.15046508499281386)
w4 ( 0.9264811468370941 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.24873213736385166) - present_state_Q (0.15457378387496054)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6634104871270848 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.24045553580673573) - present_state_Q (0.15880529954380052)) * f3(0.15619221128004807)
w4 ( 0.9274725883613154 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.24045553580673573) - present_state_Q (0.15880529954380052)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6653917748239723 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.25049118008914245) - present_state_Q (0.25049118008914245)) * f3(0.2657379954659444)
w4 ( 0.9280690518646736 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.25049118008914245) - present_state_Q (0.25049118008914245)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6681384990028154 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1448798231099639) - present_state_Q (0.1448798231099639)) * f3(0.1619452856385004)
w4 ( 0.9287474845014777 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1448798231099639) - present_state_Q (0.1448798231099639)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6704489972295522 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08868660366915838) - present_state_Q (0.08868660366915838)) * f3(0.10493580909312845)
w4 ( 0.9291878486148732 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08868660366915838) - present_state_Q (0.08868660366915838)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6727631974340075 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08919827842302347) - present_state_Q (0.08919827842302347)) * f3(0.1053242256197284)
w4 ( 0.9296272917137118 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08919827842302347) - present_state_Q (0.08919827842302347)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6749021539518438 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08228035205860473) - present_state_Q (0.08228035205860473)) * f3(0.09466600799098816)
w4 ( 0.9300791870800064 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08228035205860473) - present_state_Q (0.08228035205860473)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6209180979488299 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.46829323212141566) - present_state_Q (0.46829323212141566)) * f3(0.5284969496441484)
w4 ( 0.9178216201730951 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.46829323212141566) - present_state_Q (0.46829323212141566)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5861452235869056 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.38864804651287854) - present_state_Q (0.31879787928551206)) * f3(0.3951763533423142)
w4 ( 0.9107821555760213 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.38864804651287854) - present_state_Q (0.31879787928551206)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.551004761894889 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.34755683148312994) - present_state_Q (0.32297404857693607)) * f3(0.39562863209948446)
w4 ( 0.901899971921735 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.34755683148312994) - present_state_Q (0.32297404857693607)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5084321709428218 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.4914680144186845) - present_state_Q (0.4914680144186845)) * f3(0.6627928533570612)
w4 ( 0.8929074749400595 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.4914680144186845) - present_state_Q (0.4914680144186845)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5094878764444687 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.49491234758731134) - present_state_Q (0.03492127398663181)) * f3(0.03356027699071294)
w4 ( 0.8935366148616037 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.49491234758731134) - present_state_Q (0.03492127398663181)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5102069144835703 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4110926111008921) - present_state_Q (0.029632147422988697)) * f3(0.02308477918618059)
w4 ( 0.894159569088978 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4110926111008921) - present_state_Q (0.029632147422988697)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5102742685000787 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3779049637160723) - present_state_Q (0.0010204138289671406)) * f3(0.002)
w4 ( 0.894159569088978 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3779049637160723) - present_state_Q (0.0010204138289671406)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5135820489725983 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1675319917641122) - present_state_Q (0.1645343412410464)) * f3(0.21730424977463)
w4 ( 0.8950728822365902 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1675319917641122) - present_state_Q (0.1645343412410464)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5169357713402422 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17326589906856465) - present_state_Q (0.17326589906856465)) * f3(0.23279927009432597)
w4 ( 0.89593724638162 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17326589906856465) - present_state_Q (0.17326589906856465)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5204390632461809 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1509128878902375) - present_state_Q (0.13823668433688646)) * f3(0.19808881520451696)
w4 ( 0.8966446647994285 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1509128878902375) - present_state_Q (0.13823668433688646)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5229124744190025 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18012636170293525) - present_state_Q (0.09309940434603053)) * f3(0.10997179457872562)
w4 ( 0.8975443177267256 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18012636170293525) - present_state_Q (0.09309940434603053)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5263609927997703 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.13901038756572953) - present_state_Q (0.13901038756572953)) * f3(0.1971814020524609)
w4 ( 0.8982438803314889 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.13901038756572953) - present_state_Q (0.13901038756572953)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5298717391236715 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14488511665572823) - present_state_Q (0.14488511665572823)) * f3(0.20699740849511564)
w4 ( 0.8989222939115283 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14488511665572823) - present_state_Q (0.14488511665572823)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5299365870717282 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.25299483761767627) - present_state_Q (0.001059743478247343)) * f3(0.002)
w4 ( 0.8989222939115283 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.25299483761767627) - present_state_Q (0.001059743478247343)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5299967558634744 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.019038319052374023) - present_state_Q (0.0010598731741434564)) * f3(0.002)
w4 ( 0.8989222939115283 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.019038319052374023) - present_state_Q (0.0010598731741434564)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.49946957630916233 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.4590979940813544) - present_state_Q (0.4590979940813544)) * f3(0.5948535034745054)
w4 ( 0.8907112827967568 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.4590979940813544) - present_state_Q (0.4590979940813544)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5029925072560084 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1991861962752941) - present_state_Q (0.1991861962752941)) * f3(0.29179659026374044)
w4 ( 0.8914356773368702 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1991861962752941) - present_state_Q (0.1991861962752941)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5066911592230402 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2034402549271487) - present_state_Q (0.13728620107928818)) * f3(0.20204828604750433)
w4 ( 0.8921679086345239 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2034402549271487) - present_state_Q (0.13728620107928818)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5101672133152937 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19181218940304948) - present_state_Q (0.19181218940304948)) * f3(0.2729120340228942)
w4 ( 0.8929321228117474 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19181218940304948) - present_state_Q (0.19181218940304948)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5136186697954224 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19227751063162982) - present_state_Q (0.19227751063162982)) * f3(0.2718747493818357)
w4 ( 0.8936938242543366 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19227751063162982) - present_state_Q (0.19227751063162982)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5170418902877465 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1983530249645455) - present_state_Q (0.1983530249645455)) * f3(0.2817876452328587)
w4 ( 0.8944227179195281 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1983530249645455) - present_state_Q (0.1983530249645455)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5207260785265239 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15341628674393376) - present_state_Q (0.15341628674393376)) * f3(0.22752388198504273)
w4 ( 0.89507041928725 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15341628674393376) - present_state_Q (0.15341628674393376)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5237512025867147 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.23874277351777087) - present_state_Q (0.23874277351777087)) * f3(0.35534718922495967)
w4 ( 0.895581208310254 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.23874277351777087) - present_state_Q (0.23874277351777087)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5275526935445788 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18224453031381918) - present_state_Q (0.18224453031381918)) * f3(0.2795626649795937)
w4 ( 0.8961251280011242 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18224453031381918) - present_state_Q (0.18224453031381918)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5276179353401279 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.27264083132904454) - present_state_Q (0.0010551053870891576)) * f3(0.002)
w4 ( 0.8961251280011242 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.27264083132904454) - present_state_Q (0.0010551053870891576)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5313103331875434 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16271603925890143) - present_state_Q (0.16271603925890143)) * f3(0.2404600481541047)
w4 ( 0.8967393502597921 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16271603925890143) - present_state_Q (0.16271603925890143)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5348926031061754 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1534016569397949) - present_state_Q (0.1534016569397949)) * f3(0.22121173933185373)
w4 ( 0.8973871042948088 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1534016569397949) - present_state_Q (0.1534016569397949)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.53752934645437 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14506560177770011) - present_state_Q (0.07744067685435775)) * f3(0.11122407455810772)
w4 ( 0.8978612360614556 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14506560177770011) - present_state_Q (0.07744067685435775)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5409459834718938 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14329026665320882) - present_state_Q (0.14329026665320882)) * f3(0.1997580558513107)
w4 ( 0.8985453911015041 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14329026665320882) - present_state_Q (0.14329026665320882)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5421750210925899 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06329803168041678) - present_state_Q (0.06329803168041678)) * f3(0.05057106785557264)
w4 ( 0.8995175181874546 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06329803168041678) - present_state_Q (0.06329803168041678)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5438647354528665 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.20446249304935216) - present_state_Q (0.24044319377685036)) * f3(0.21120622820255516)
w4 ( 0.9006375609648478 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.20446249304935216) - present_state_Q (0.24044319377685036)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5470715588442808 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1325321225912939) - present_state_Q (0.1325321225912939)) * f3(0.17744599688439194)
w4 ( 0.9013604453235191 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1325321225912939) - present_state_Q (0.1325321225912939)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5500700085911623 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12250550767639878) - present_state_Q (0.12250550767639878)) * f3(0.15802519517938526)
w4 ( 0.9021194254958841 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12250550767639878) - present_state_Q (0.12250550767639878)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5528197259352812 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11202336943290506) - present_state_Q (0.11202336943290506)) * f3(0.13805259553699975)
w4 ( 0.9029161413659256 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11202336943290506) - present_state_Q (0.11202336943290506)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5528798880866364 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.019163962279189074) - present_state_Q (0.0011056394518705623)) * f3(0.002)
w4 ( 0.9029161413659256 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.019163962279189074) - present_state_Q (0.0011056394518705623)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5560511521743615 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1947156374967297) - present_state_Q (0.1947156374967297)) * f3(0.2541974704508539)
w4 ( 0.9036646769234432 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1947156374967297) - present_state_Q (0.1947156374967297)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5591935991525445 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18596925601002906) - present_state_Q (0.18596925601002906)) * f3(0.23693750993849158)
w4 ( 0.904460442940989 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18596925601002906) - present_state_Q (0.18596925601002906)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5606661670414371 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17654594463454173) - present_state_Q (0.048706681545323864)) * f3(0.05475290263140481)
w4 ( 0.9049983387668253 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17654594463454173) - present_state_Q (0.048706681545323864)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.562813112225809 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15881669305498242) - present_state_Q (0.06633650707093235)) * f3(0.08603433403184255)
w4 ( 0.9054974290912945 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15881669305498242) - present_state_Q (0.06633650707093235)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5656348749952207 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11826899014538425) - present_state_Q (0.11826899014538425)) * f3(0.14578390446030182)
w4 ( 0.9062716607267711 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11826899014538425) - present_state_Q (0.11826899014538425)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5683412926453499 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11369274733081658) - present_state_Q (0.11369274733081658)) * f3(0.13691143231293876)
w4 ( 0.9070623668363802 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11369274733081658) - present_state_Q (0.11369274733081658)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5712581409920158 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1244739676853679) - present_state_Q (0.1244739676853679)) * f3(0.15517343918726131)
w4 ( 0.9078142605527129 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1244739676853679) - present_state_Q (0.1244739676853679)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5741141392576834 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11787132055191152) - present_state_Q (0.16769908442114675)) * f3(0.1982120177602275)
w4 ( 0.9086787888385172 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11787132055191152) - present_state_Q (0.16769908442114675)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5764591248701861 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09019612543169547) - present_state_Q (0.07593268875561382)) * f3(0.1006056270509636)
w4 ( 0.9091449626860922 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09019612543169547) - present_state_Q (0.07593268875561382)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5786036122973217 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08467011367568483) - present_state_Q (0.07002906589951208)) * f3(0.08993901633088999)
w4 ( 0.9096218385770284 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08467011367568483) - present_state_Q (0.07002906589951208)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.578666549581452 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15843627876059713) - present_state_Q (0.0011572072245946434)) * f3(0.002)
w4 ( 0.9096218385770284 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15843627876059713) - present_state_Q (0.0011572072245946434)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5811628239198023 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08207014270052723) - present_state_Q (0.08207014270052723)) * f3(0.11038776299613177)
w4 ( 0.9100741123201674 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08207014270052723) - present_state_Q (0.08207014270052723)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.583829651612012 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08855306341661033) - present_state_Q (0.08855306341661033)) * f3(0.1210531339491102)
w4 ( 0.9105147168060176 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08855306341661033) - present_state_Q (0.08855306341661033)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5838921330944334 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.13575071410729583) - present_state_Q (0.001167659303224024)) * f3(0.002)
w4 ( 0.9105147168060176 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.13575071410729583) - present_state_Q (0.001167659303224024)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5865222718642527 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08766899626345036) - present_state_Q (0.08766899626345036)) * f3(0.11895810542817568)
w4 ( 0.9109569126127434 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08766899626345036) - present_state_Q (0.08766899626345036)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5890388413473125 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0839940384039399) - present_state_Q (0.0839940384039399)) * f3(0.11214390877710485)
w4 ( 0.9114057233436162 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0839940384039399) - present_state_Q (0.0839940384039399)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5912602179372424 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0743697265892984) - present_state_Q (0.0743697265892984)) * f3(0.09531054351868033)
w4 ( 0.9118718578357555 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0743697265892984) - present_state_Q (0.0743697265892984)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5913224583704124 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12384686285943003) - present_state_Q (0.0011825204358744848)) * f3(0.002)
w4 ( 0.9118718578357555 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12384686285943003) - present_state_Q (0.0011825204358744848)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5913847616977664 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12699281686835587) - present_state_Q (0.0011826449167408248)) * f3(0.002)
w4 ( 0.9118718578357555 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12699281686835587) - present_state_Q (0.0011826449167408248)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5914409013118209 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0011827695233955328) - present_state_Q (0.019420206680110644)) * f3(0.002)
w4 ( 0.9124332539763 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0011827695233955328) - present_state_Q (0.019420206680110644)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5103070259178178 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.5888911394782339) - present_state_Q (0.5888911394782339)) * f3(0.7179976102779088)
w4 ( 0.8920932175167526 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.5888911394782339) - present_state_Q (0.5888911394782339)) * f4(0.18)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4271014739727155 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.5487436223226281) - present_state_Q (0.5487436223226281)) * f3(0.7606535349409922)
w4 ( 0.8724035708351261 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.5487436223226281) - present_state_Q (0.5487436223226281)) * f4(0.18)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.42945518343329053 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1048458024670561) - present_state_Q (0.07816777741422387)) * f3(0.10131464585763325)
w4 ( 0.873332838046456 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1048458024670561) - present_state_Q (0.07816777741422387)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4317261906596329 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06926238653657864) - present_state_Q (0.056395908305519715)) * f3(0.09064799552160412)
w4 ( 0.8738338987071523 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06926238653657864) - present_state_Q (0.056395908305519715)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4337566103796122 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.052110564471314076) - present_state_Q (0.052110564471314076)) * f3(0.08022187962294813)
w4 ( 0.8743400996911039 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.052110564471314076) - present_state_Q (0.052110564471314076)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4358308577767646 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.053168972304880616) - present_state_Q (0.053168972304880616)) * f3(0.08226311589771614)
w4 ( 0.8748443955409552 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.053168972304880616) - present_state_Q (0.053168972304880616)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.43813402133127033 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05800580244361709) - present_state_Q (0.05800580244361709)) * f3(0.09294641214584883)
w4 ( 0.8753399850965566 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05800580244361709) - present_state_Q (0.05800580244361709)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.44065188845980047 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06281797777265302) - present_state_Q (0.06281797777265302)) * f3(0.10341853374692034)
w4 ( 0.8758269127365659 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06281797777265302) - present_state_Q (0.06281797777265302)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.44353371020726895 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07138032004449553) - present_state_Q (0.07138032004449553)) * f3(0.12223658447949229)
w4 ( 0.8762984281604858 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07138032004449553) - present_state_Q (0.07138032004449553)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4469436523517705 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08526946812374335) - present_state_Q (0.08526946812374335)) * f3(0.1527358529949758)
w4 ( 0.876744943117863 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08526946812374335) - present_state_Q (0.08526946812374335)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4501697526454838 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08103486914952802) - present_state_Q (0.08103486914952802)) * f3(0.14207600880567514)
w4 ( 0.8771990803533939 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08103486914952802) - present_state_Q (0.08103486914952802)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4532100651630516 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07683119516893065) - present_state_Q (0.07683119516893065)) * f3(0.13169968264960805)
w4 ( 0.8776607842020898 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07683119516893065) - present_state_Q (0.07683119516893065)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.45605701690927597 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07252112623976548) - present_state_Q (0.07252112623976548)) * f3(0.1212857232902536)
w4 ( 0.8781302461748582 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07252112623976548) - present_state_Q (0.07252112623976548)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.45771065617019113 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07415508526552968) - present_state_Q (0.07415508526552968)) * f3(0.12409080058796798)
w4 ( 0.8783967670213803 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.07415508526552968) - present_state_Q (0.07415508526552968)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.45147639066755496 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07822816703125236) - present_state_Q (0.07822816703125236)) * f3(0.13252964700098524)
w4 ( 0.877455956320724 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07822816703125236) - present_state_Q (0.07822816703125236)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.44336871625249735 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.07256738189227602) - present_state_Q (0.07256738189227602)) * f3(0.12186298974462716)
w4 ( 0.8761253350333179 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.07256738189227602) - present_state_Q (0.07256738189227602)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.436028188718305 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.06682348336684948) - present_state_Q (0.06682348336684948)) * f3(0.11119633582380754)
w4 ( 0.8748050527632576 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.06682348336684948) - present_state_Q (0.06682348336684948)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.591505894905326 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.33168226986685245) - present_state_Q (0.33168226986685245)) * f3(0.43738539045063873)
w4 ( 0.9124451416332587 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.33168226986685245) - present_state_Q (0.33168226986685245)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5910539116537404 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.34428320372140525) - present_state_Q (0.34428320372140525)) * f3(0.45863886518690694)
w4 ( 0.9123663025664647 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.34428320372140525) - present_state_Q (0.34428320372140525)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.582800670822669 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.47468530327045955) - present_state_Q (0.47468530327045955)) * f3(0.6487541414639184)
w4 ( 0.9110941348370305 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.47468530327045955) - present_state_Q (0.47468530327045955)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.580685519789352 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3781955479498169) - present_state_Q (0.3781955479498169)) * f3(0.5238635307881306)
w4 ( 0.9107711268917918 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3781955479498169) - present_state_Q (0.3781955479498169)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5828831165889159 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.26636100205458807) - present_state_Q (0.26636100205458807)) * f3(0.36459447881166673)
w4 ( 0.9111327774806971 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.26636100205458807) - present_state_Q (0.26636100205458807)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5829498096340061 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3463099168402274) - present_state_Q (0.0011657662331778318)) * f3(0.002)
w4 ( 0.9111327774806971 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3463099168402274) - present_state_Q (0.0011657662331778318)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5863510732308772 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18710099070587022) - present_state_Q (0.18710099070587022)) * f3(0.25843679355728516)
w4 ( 0.9116592139141559 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18710099070587022) - present_state_Q (0.18710099070587022)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5736095041714563 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.5490018066954939) - present_state_Q (0.5490018066954939)) * f3(0.6564380381706734)
w4 ( 0.908165384645689 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.5490018066954939) - present_state_Q (0.5490018066954939)) * f4(0.18)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5762654089058925 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.21082158487953845) - present_state_Q (0.21082158487953845)) * f3(0.24087528728705263)
w4 ( 0.9090474692345563 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.21082158487953845) - present_state_Q (0.21082158487953845)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5792772703254506 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2060310072131822) - present_state_Q (0.2060310072131822)) * f3(0.2628791468617332)
w4 ( 0.9097349017956051 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2060310072131822) - present_state_Q (0.2060310072131822)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5821521324315431 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1687222945769639) - present_state_Q (0.20908075805265897)) * f3(0.26670589691551866)
w4 ( 0.9103816506240353 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1687222945769639) - present_state_Q (0.20908075805265897)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5855198299955569 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1688551089855635) - present_state_Q (0.1688551089855635)) * f3(0.2275003999511692)
w4 ( 0.9109737722316873 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1688551089855635) - present_state_Q (0.1688551089855635)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5888741554402467 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17025470403001) - present_state_Q (0.17025470403001)) * f3(0.22854179531674948)
w4 ( 0.9115608552971792 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17025470403001) - present_state_Q (0.17025470403001)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5922120568506507 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1710040131128164) - present_state_Q (0.1710040131128164)) * f3(0.22847254826516364)
w4 ( 0.9121452408499731 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1710040131128164) - present_state_Q (0.1710040131128164)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5934439790476634 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.15212001358857116) - present_state_Q (0.15212001358857116)) * f3(0.19525810495907195)
w4 ( 0.9123976088010542 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.15212001358857116) - present_state_Q (0.15212001358857116)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5934082868182878 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.22725741080135803) - present_state_Q (0.001186887958095327)) * f3(0.002)
w4 ( 0.9123976088010542 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.22725741080135803) - present_state_Q (0.001186887958095327)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.593331118502126 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1534523576495746) - present_state_Q (0.0011868165736365758)) * f3(0.002)
w4 ( 0.9123976088010542 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1534523576495746) - present_state_Q (0.0011868165736365758)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5892753582872794 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07020183931083124) - present_state_Q (0.07020183931083124)) * f3(0.08756305798686)
w4 ( 0.9114712454902948 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.07020183931083124) - present_state_Q (0.07020183931083124)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5862595394303896 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.057563625223425674) - present_state_Q (0.057563625223425674)) * f3(0.06675011904102707)
w4 ( 0.9105676309648926 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.057563625223425674) - present_state_Q (0.057563625223425674)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5837742856747936 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05089392146511623) - present_state_Q (0.05089392146511623)) * f3(0.05574761116479708)
w4 ( 0.9096760219062554 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.05089392146511623) - present_state_Q (0.05089392146511623)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5794816364335941 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.05668615821294755) - present_state_Q (0.05668615821294755)) * f3(0.06593753565271929)
w4 ( 0.9083739868214721 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.05668615821294755) - present_state_Q (0.05668615821294755)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5734522685417446 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.07080818929050978) - present_state_Q (0.07080818929050978)) * f3(0.09084103143985084)
w4 ( 0.9070465320807491 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.07080818929050978) - present_state_Q (0.07080818929050978)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5891676440346473 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3363839877030045) - present_state_Q (0.22512286101600587)) * f3(0.25955460960322685)
w4 ( 0.9125273382161903 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3363839877030045) - present_state_Q (0.22512286101600587)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.591133756643459 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.43171478448457096) - present_state_Q (0.23128033718179591)) * f3(0.1757165568743303)
w4 ( 0.9140938141939235 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.43171478448457096) - present_state_Q (0.23128033718179591)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5931168525266958 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2072310927101635) - present_state_Q (0.24379484527792045)) * f3(0.25778508188027405)
w4 ( 0.9148630968338545 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2072310927101635) - present_state_Q (0.24379484527792045)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5958455709673193 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.23152456793459789) - present_state_Q (0.23152456793459789)) * f3(0.297804355705129)
w4 ( 0.9154128641670076 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.23152456793459789) - present_state_Q (0.23152456793459789)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5987585773537738 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.23385824932283264) - present_state_Q (0.12341371702181193)) * f3(0.14567063461463953)
w4 ( 0.9162127525986495 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.23385824932283264) - present_state_Q (0.12341371702181193)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6011886694465194 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10858164993986286) - present_state_Q (0.10858164993986286)) * f3(0.12013713465922593)
w4 ( 0.917021858658866 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10858164993986286) - present_state_Q (0.10858164993986286)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6033062364639495 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09637534164082356) - present_state_Q (0.09637534164082356)) * f3(0.09929406578707856)
w4 ( 0.917874907428959 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09637534164082356) - present_state_Q (0.09637534164082356)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5815536767214458 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.40889036349062324) - present_state_Q (0.4970117924853831)) * f3(0.6108163369986132)
w4 ( 0.9128891888430506 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.40889036349062324) - present_state_Q (0.4970117924853831)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5831764873393451 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.24468877533203945) - present_state_Q (0.2629465591089004)) * f3(0.26377592058662247)
w4 ( 0.9136274566641422 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.24468877533203945) - present_state_Q (0.2629465591089004)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5861385361005511 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17995300136283265) - present_state_Q (0.17995300136283265)) * f3(0.21457544444889284)
w4 ( 0.914455710456783 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17995300136283265) - present_state_Q (0.17995300136283265)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5890036967110909 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16715525316956611) - present_state_Q (0.16715525316956611)) * f3(0.19157230522528948)
w4 ( 0.9153530720896673 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16715525316956611) - present_state_Q (0.16715525316956611)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5917238848975789 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10953129014336363) - present_state_Q (0.09122422870157029)) * f3(0.12379746963717812)
w4 ( 0.9157925298902928 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10953129014336363) - present_state_Q (0.09122422870157029)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5945646979754852 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09752081215566907) - present_state_Q (0.09752081215566907)) * f3(0.1338545960022769)
w4 ( 0.9162169924284126 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09752081215566907) - present_state_Q (0.09752081215566907)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.596868722825765 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07791741714392908) - present_state_Q (0.07791741714392908)) * f3(0.10022976052610835)
w4 ( 0.9166767410775535 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07791741714392908) - present_state_Q (0.07791741714392908)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5985529622668244 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.059057780232250695) - present_state_Q (0.059057780232250695)) * f3(0.06822981981347287)
w4 ( 0.9171704370731354 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.059057780232250695) - present_state_Q (0.059057780232250695)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5986143760862015 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08266202809654663) - present_state_Q (0.0011971059245336488)) * f3(0.002)
w4 ( 0.9171704370731354 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08266202809654663) - present_state_Q (0.0011971059245336488)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5998402809008545 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.046800244130432544) - present_state_Q (0.046800244130432544)) * f3(0.04753784159849846)
w4 ( 0.9176861966337007 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.046800244130432544) - present_state_Q (0.046800244130432544)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5998967612880455 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.01955340449447572) - present_state_Q (0.01955340449447572)) * f3(0.002)
w4 ( 0.9182510005056106 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.01955340449447572) - present_state_Q (0.01955340449447572)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6020637384133632 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07407869390211796) - present_state_Q (0.07407869390211796)) * f3(0.09287210314718528)
w4 ( 0.9187176588565867 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07407869390211796) - present_state_Q (0.07407869390211796)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6044020525884308 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08015948560505759) - present_state_Q (0.08015948560505759)) * f3(0.10262224493165802)
w4 ( 0.9191733717824976 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08015948560505759) - present_state_Q (0.08015948560505759)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6069219402918178 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08711240795964632) - present_state_Q (0.08711240795964632)) * f3(0.11371394294518972)
w4 ( 0.9196165694481703 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08711240795964632) - present_state_Q (0.08711240795964632)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6096023355035294 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09387803578696671) - present_state_Q (0.09387803578696671)) * f3(0.12437465081870097)
w4 ( 0.9200475889837537 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09387803578696671) - present_state_Q (0.09387803578696671)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6120390347849911 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08481242527678814) - present_state_Q (0.08481242527678814)) * f3(0.10894228848755545)
w4 ( 0.9204949266182555 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08481242527678814) - present_state_Q (0.08481242527678814)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6132318547691729 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.40724264812328625) - present_state_Q (0.12605824729544704)) * f3(0.05556631636341422)
w4 ( 0.9226415867934243 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.40724264812328625) - present_state_Q (0.12605824729544704)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6149256592327392 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.26745707402675695) - present_state_Q (0.26745707402675695)) * f3(0.2856878911050031)
w4 ( 0.9232344731271835 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.26745707402675695) - present_state_Q (0.26745707402675695)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6160206701168414 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.24010381071167614) - present_state_Q (0.042373112257971315)) * f3(0.03888018402949534)
w4 ( 0.9237977476648099 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.24010381071167614) - present_state_Q (0.042373112257971315)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6185919015677176 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16004892755213665) - present_state_Q (0.21941770894075796)) * f3(0.266208346628637)
w4 ( 0.9243772707676967 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16004892755213665) - present_state_Q (0.21941770894075796)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6216487751608687 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15439033916921951) - present_state_Q (0.15439033916921951)) * f3(0.18981051649874878)
w4 ( 0.9250214655466875 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15439033916921951) - present_state_Q (0.15439033916921951)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6241881249759387 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1524906788932358) - present_state_Q (0.1524906788932358)) * f3(0.1560195963312819)
w4 ( 0.925998015880664 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1524906788932358) - present_state_Q (0.1524906788932358)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5734058291311463 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.5710481815832105) - present_state_Q (0.5096371630595276)) * f3(0.5920504317635603)
w4 ( 0.9100544090998361 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.5710481815832105) - present_state_Q (0.5096371630595276)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.517262845617365 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.6071856768870745) - present_state_Q (0.6071856768870745)) * f3(0.8684584678004711)
w4 ( 0.9022968037894558 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.6071856768870745) - present_state_Q (0.6071856768870745)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4957901516104422 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.5211384614536518) - present_state_Q (0.5211384614536518)) * f3(0.7981683751249442)
w4 ( 0.8990685084057564 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.5211384614536518) - present_state_Q (0.5211384614536518)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.45521953904057977 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.42524873386684436) - present_state_Q (0.4812562821538603)) * f3(0.7530768006028011)
w4 ( 0.8926037315005503 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.42524873386684436) - present_state_Q (0.4812562821538603)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.44905130811745286 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.42996762274807926) - present_state_Q (0.42996762274807926)) * f3(0.7092296074295548)
w4 ( 0.8915600811748711 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.42996762274807926) - present_state_Q (0.42996762274807926)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4148488218365848 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.25623317343293756) - present_state_Q (0.25623317343293756)) * f3(0.4117755891061421)
w4 ( 0.884915202326154 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.25623317343293756) - present_state_Q (0.25623317343293756)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3956565784874634 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.3024187988136188) - present_state_Q (0.3024187988136188)) * f3(0.5156752708948819)
w4 ( 0.8811934331368314 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.3024187988136188) - present_state_Q (0.3024187988136188)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.37783618398913593 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.285598259968868) - present_state_Q (0.285598259968868)) * f3(0.4991169802107615)
w4 ( 0.8776230487971116 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.285598259968868) - present_state_Q (0.285598259968868)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3369309037072473 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2562753940648681) - present_state_Q (0.2562753940648681)) * f3(0.49245032118588516)
w4 ( 0.8709778659598446 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2562753940648681) - present_state_Q (0.2562753940648681)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2924050797879486 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.25127049584244593) - present_state_Q (0.25127049584244593)) * f3(0.5389599605367168)
w4 ( 0.864368718389779 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.25127049584244593) - present_state_Q (0.25127049584244593)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.25049671250754674 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.22231180513494458) - present_state_Q (0.22231180513494458)) * f3(0.5238018018525368)
w4 ( 0.8579680733928075 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.22231180513494458) - present_state_Q (0.22231180513494458)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2190457259207483 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.15766950648618563) - present_state_Q (0.15766950648618563)) * f3(0.4239234160784364)
w4 ( 0.8535166580577821 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.15766950648618563) - present_state_Q (0.15766950648618563)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.184608332604452 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.10707913619301476) - present_state_Q (0.15285362447533654)) * f3(0.4640246896606618)
w4 ( 0.8490637837926459 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.10707913619301476) - present_state_Q (0.15285362447533654)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.15637113640196487 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.12418191871152814) - present_state_Q (0.12418191871152814)) * f3(0.39672148407781666)
w4 ( 0.8447932014316036 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.12418191871152814) - present_state_Q (0.12418191871152814)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.13456489605628646 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.10009953340501229) - present_state_Q (0.10009953340501229)) * f3(0.31599144481561237)
w4 ( 0.8406526639512165 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.10009953340501229) - present_state_Q (0.10009953340501229)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10835115863353774 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.10146416069876185) - present_state_Q (0.10146416069876185)) * f3(0.379185079891459)
w4 ( 0.8365047574834432 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.10146416069876185) - present_state_Q (0.10146416069876185)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10269654087537977 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.04024803401594793) - present_state_Q (0.026571673592403734)) * f3(0.0908303941263866)
w4 ( 0.8352596637430616 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.04024803401594793) - present_state_Q (0.026571673592403734)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09640261711342263 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.03361577963147322) - present_state_Q (0.027068461911477756)) * f3(0.10091156477404771)
w4 ( 0.834012249975165 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.03361577963147322) - present_state_Q (0.027068461911477756)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09166669504094191 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.02743062533143706) - present_state_Q (0.02743062533143706)) * f3(0.1115154406989323)
w4 ( 0.8331628748495684 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.02743062533143706) - present_state_Q (0.02743062533143706)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.0840318518567622 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.027859709982531143) - present_state_Q (0.027859709982531143)) * f3(0.12214308021620067)
w4 ( 0.8319127273715998 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.027859709982531143) - present_state_Q (0.027859709982531143)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.0839123549911748 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.02683735766759692) - present_state_Q (0.0001680637037135244)) * f3(0.002)
w4 ( 0.8319127273715998 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.02683735766759692) - present_state_Q (0.0001680637037135244)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.0837928399822081 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.025927798764560164) - present_state_Q (0.00016782470998234962)) * f3(0.002)
w4 ( 0.8319127273715998 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.025927798764560164) - present_state_Q (0.00016782470998234962)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.0836733068820441 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.02502084859919514) - present_state_Q (0.0001675856799644162)) * f3(0.002)
w4 ( 0.8319127273715998 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.02502084859919514) - present_state_Q (0.0001675856799644162)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.0778880850761434 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.024420972876690414) - present_state_Q (0.024420972876690414)) * f3(0.09301315579925466)
w4 ( 0.8306687696204218 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.024420972876690414) - present_state_Q (0.024420972876690414)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.07270493209306995 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.023116320170564912) - present_state_Q (0.023116320170564912)) * f3(0.08349088017505113)
w4 ( 0.8294271602441148 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.023116320170564912) - present_state_Q (0.023116320170564912)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5754132765065881 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2519940951156469) - present_state_Q (0.20485749116344038)) * f3(0.16681198064622965)
w4 ( 0.9114985121200136 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2519940951156469) - present_state_Q (0.20485749116344038)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.578438144883389 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.20244377474158473) - present_state_Q (0.20244377474158473)) * f3(0.2567786842031481)
w4 ( 0.9122053157364091 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.20244377474158473) - present_state_Q (0.20244377474158473)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.581865238802786 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18317478510680604) - present_state_Q (0.18317478510680604)) * f3(0.25359076640238026)
w4 ( 0.9127458865100245 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18317478510680604) - present_state_Q (0.18317478510680604)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5849287961064576 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2320345394360671) - present_state_Q (0.2320345394360671)) * f3(0.33603090704983)
w4 ( 0.9131105621680546 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2320345394360671) - present_state_Q (0.2320345394360671)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5878630731554618 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.23144709733462104) - present_state_Q (0.09276179605773903)) * f3(0.1273652200238385)
w4 ( 0.9135713279954061 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.23144709733462104) - present_state_Q (0.09276179605773903)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5908032533817827 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2380082639960271) - present_state_Q (0.2380082639960271)) * f3(0.34270805579743024)
w4 ( 0.9139144982450204 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2380082639960271) - present_state_Q (0.2380082639960271)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.588896682405442 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3727065993796542) - present_state_Q (0.3727065993796542)) * f3(0.5380331399081536)
w4 ( 0.9137018826083703 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3727065993796542) - present_state_Q (0.3727065993796542)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5876160326565089 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.36072644336787396) - present_state_Q (0.36072644336787396)) * f3(0.5194533091303163)
w4 ( 0.9135539598141837 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.36072644336787396) - present_state_Q (0.36072644336787396)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5884599846049071 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3119000315444631) - present_state_Q (0.3119000315444631)) * f3(0.43750813399928495)
w4 ( 0.9136696996438436 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3119000315444631) - present_state_Q (0.3119000315444631)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5885260294559703 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.31401175285426675) - present_state_Q (0.0011769199692098142)) * f3(0.002)
w4 ( 0.9136696996438436 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.31401175285426675) - present_state_Q (0.0011769199692098142)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5918664191077404 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18096188535903027) - present_state_Q (0.18990932570879793)) * f3(0.26058751872846053)
w4 ( 0.9141824470951521 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18096188535903027) - present_state_Q (0.18990932570879793)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5919317018218992 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.27597303632352327) - present_state_Q (0.0011837328382154808)) * f3(0.002)
w4 ( 0.9141824470951521 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.27597303632352327) - present_state_Q (0.0011837328382154808)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5947417105039899 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17354707026699162) - present_state_Q (0.09213865054991364)) * f3(0.1247694647552973)
w4 ( 0.9146328792081057 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17354707026699162) - present_state_Q (0.09213865054991364)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5971097533873309 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18367689215946667) - present_state_Q (0.07652866250641982)) * f3(0.09791814479079994)
w4 ( 0.9151165572615247 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18367689215946667) - present_state_Q (0.07652866250641982)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5999558510423527 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16369002003590447) - present_state_Q (0.09510957447409717)) * f3(0.12863170111214653)
w4 ( 0.9155590761165837 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16369002003590447) - present_state_Q (0.09510957447409717)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.602703905478254 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15628850623722826) - present_state_Q (0.09205449223482451)) * f3(0.12291456210381566)
w4 ( 0.9160062248333615 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15628850623722826) - present_state_Q (0.09205449223482451)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.605841035898456 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15339179588608295) - present_state_Q (0.15339179588608295)) * f3(0.19371294234455724)
w4 ( 0.9166540143681716 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15339179588608295) - present_state_Q (0.15339179588608295)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6087227304278219 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10229430643827025) - present_state_Q (0.10229430643827025)) * f3(0.13858623166123635)
w4 ( 0.9170698846165828 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10229430643827025) - present_state_Q (0.10229430643827025)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6115967690069591 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10258319779467902) - present_state_Q (0.10258319779467902)) * f3(0.13839108660052932)
w4 ( 0.9174852348605523 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10258319779467902) - present_state_Q (0.10258319779467902)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6116569158262163 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.019572898235224966) - present_state_Q (0.0012231935380139184)) * f3(0.002)
w4 ( 0.9174852348605523 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.019572898235224966) - present_state_Q (0.0012231935380139184)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6103165715415331 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.5719126975364307) - present_state_Q (0.21007481425357055)) * f3(0.2534520515516958)
w4 ( 0.9171679335935528 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.5719126975364307) - present_state_Q (0.21007481425357055)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6103863306820477 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.5001633571642896) - present_state_Q (0.001220633143083066)) * f3(0.002)
w4 ( 0.9171679335935528 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.5001633571642896) - present_state_Q (0.001220633143083066)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6081325956940128 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.38274060887499284) - present_state_Q (0.38274060887499284)) * f3(0.5068383065554903)
w4 ( 0.9168122012096528 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.38274060887499284) - present_state_Q (0.38274060887499284)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6050041039241862 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.39837196116650625) - present_state_Q (0.39837196116650625)) * f3(0.5344672977096498)
w4 ( 0.9163439230892539 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.39837196116650625) - present_state_Q (0.39837196116650625)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6084461833500863 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.30691129027710284) - present_state_Q (0.21177533004177257)) * f3(0.2894551821753379)
w4 ( 0.9168195862851977 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.30691129027710284) - present_state_Q (0.21177533004177257)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.612371202530199 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4627793746461909) - present_state_Q (0.2005422480568954)) * f3(0.2693245008181779)
w4 ( 0.9174025290428286 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4627793746461909) - present_state_Q (0.2005422480568954)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.615857751221475 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.29193550337331153) - present_state_Q (0.18911485783965082)) * f3(0.2488992886147698)
w4 ( 0.9179628438128193 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.29193550337331153) - present_state_Q (0.18911485783965082)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6192698609628882 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.27274112823608765) - present_state_Q (0.19158259073109674)) * f3(0.25146079053390313)
w4 ( 0.9185056099011893 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.27274112823608765) - present_state_Q (0.19158259073109674)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.62242703103723 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1796515778992233) - present_state_Q (0.16250469254575253)) * f3(0.20308507821478144)
w4 ( 0.919127451762166 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1796515778992233) - present_state_Q (0.16250469254575253)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6250729501782091 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09206275761154002) - present_state_Q (0.12730053755054818)) * f3(0.1454555071767862)
w4 ( 0.9198550747150085 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09206275761154002) - present_state_Q (0.12730053755054818)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6277935376179729 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09904702941840474) - present_state_Q (0.09904702941840474)) * f3(0.12902482486421973)
w4 ( 0.9202767900620553 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09904702941840474) - present_state_Q (0.09904702941840474)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6278562672585771 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14903790096421357) - present_state_Q (0.0012555870752359458)) * f3(0.002)
w4 ( 0.9202767900620553 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14903790096421357) - present_state_Q (0.0012555870752359458)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6279192493707114 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1616627320575595) - present_state_Q (0.0012557125345171543)) * f3(0.002)
w4 ( 0.9202767900620553 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1616627320575595) - present_state_Q (0.0012557125345171543)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6291387234022817 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.048249864107805726) - present_state_Q (0.048249864107805726)) * f3(0.04752892722507557)
w4 ( 0.9207899403066613 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.048249864107805726) - present_state_Q (0.048249864107805726)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6291951820685562 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.01967407625293779) - present_state_Q (0.01967407625293779)) * f3(0.002)
w4 ( 0.921354526969406 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.01967407625293779) - present_state_Q (0.01967407625293779)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6194866682896027 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.4402677078573708) - present_state_Q (0.4402677078573708)) * f3(0.4947241856784236)
w4 ( 0.9186071538504031 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.4402677078573708) - present_state_Q (0.4402677078573708)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.62075870602604 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2935450397839075) - present_state_Q (0.2935450397839075)) * f3(0.35522389542853156)
w4 ( 0.918893629563959 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2935450397839075) - present_state_Q (0.2935450397839075)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6243627068834194 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.38604936464862216) - present_state_Q (0.1675288028672894)) * f3(0.21066648991829895)
w4 ( 0.9195779340983493 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.38604936464862216) - present_state_Q (0.1675288028672894)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6280153864161482 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.41345271769241243) - present_state_Q (0.16947956616370827)) * f3(0.21253102937897167)
w4 ( 0.9202653969207715 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.41345271769241243) - present_state_Q (0.16947956616370827)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6308324114293581 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4843378768402458) - present_state_Q (0.08575507710334465)) * f3(0.10724222785252041)
w4 ( 0.9207907543419328 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4843378768402458) - present_state_Q (0.08575507710334465)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6307875358748617 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3346301486064099) - present_state_Q (0.3346301486064099)) * f3(0.38449367657352523)
w4 ( 0.9207790830044751 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3346301486064099) - present_state_Q (0.3346301486064099)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6326977757713168 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.27831391931578353) - present_state_Q (0.26478531074761374)) * f3(0.30299105996471615)
w4 ( 0.9212834516539468 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.27831391931578353) - present_state_Q (0.26478531074761374)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6326389476525905 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.30275874500141053) - present_state_Q (0.3321082323851373)) * f3(0.3210514671178547)
w4 ( 0.9212577986435568 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.30275874500141053) - present_state_Q (0.3321082323851373)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.633795785171283 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1919434901435235) - present_state_Q (0.2656441140350081)) * f3(0.21602846731459918)
w4 ( 0.9220075019332676 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1919434901435235) - present_state_Q (0.2656441140350081)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6365456794753125 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1340591699764636) - present_state_Q (0.1340591699764636)) * f3(0.1533283624990822)
w4 ( 0.9227248889213524 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1340591699764636) - present_state_Q (0.1340591699764636)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6366078456851176 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12104140384682785) - present_state_Q (0.001273091358950625)) * f3(0.002)
w4 ( 0.9227248889213524 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12104140384682785) - present_state_Q (0.001273091358950625)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6381961125831568 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0594778916504413) - present_state_Q (0.0594778916504413)) * f3(0.06444060366215698)
w4 ( 0.9232178287163816 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0594778916504413) - present_state_Q (0.0594778916504413)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6395544408396502 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05382387984047578) - present_state_Q (0.05278267841137291)) * f3(0.053773943714791286)
w4 ( 0.923723028135527 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05382387984047578) - present_state_Q (0.05278267841137291)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6404732377495646 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.04079316763937825) - present_state_Q (0.04079316763937825)) * f3(0.034897274808015105)
w4 ( 0.9242496004337761 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.04079316763937825) - present_state_Q (0.04079316763937825)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6358425032782248 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4496581113728214) - present_state_Q (0.4496581113728214)) * f3(0.44231853354271444)
w4 ( 0.9223651390295364 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4496581113728214) - present_state_Q (0.4496581113728214)) * f4(0.18)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6342366937469508 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.37364769017505006) - present_state_Q (0.37364769017505006)) * f3(0.4425800018419965)
w4 ( 0.9220023098179609 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.37364769017505006) - present_state_Q (0.37364769017505006)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6330556784158873 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.36395870038866174) - present_state_Q (0.36395870038866174)) * f3(0.42848115236185386)
w4 ( 0.921726681514463 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.36395870038866174) - present_state_Q (0.36395870038866174)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6351637076470146 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.22760829704897562) - present_state_Q (0.24470458870880527)) * f3(0.2700654302879998)
w4 ( 0.9223511314424317 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.22760829704897562) - present_state_Q (0.24470458870880527)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6382644360033998 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17583675263940404) - present_state_Q (0.17583675263940404)) * f3(0.21875101758635537)
w4 ( 0.9229181191329299 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17583675263940404) - present_state_Q (0.17583675263940404)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6413343164975916 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1990763687155893) - present_state_Q (0.1990763687155893)) * f3(0.2540634176105158)
w4 ( 0.9234014442055537 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1990763687155893) - present_state_Q (0.1990763687155893)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6413989735844368 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.245681028586216) - present_state_Q (0.0012826686329951832)) * f3(0.002)
w4 ( 0.9234014442055537 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.245681028586216) - present_state_Q (0.0012826686329951832)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6442952758827842 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10203485888450907) - present_state_Q (0.18315719089490567)) * f3(0.22797219694557913)
w4 ( 0.9239096293855279 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10203485888450907) - present_state_Q (0.18315719089490567)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6468040617654874 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08514816543231593) - present_state_Q (0.12507003165612407)) * f3(0.1367597276884789)
w4 ( 0.9246434085250763 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08514816543231593) - present_state_Q (0.12507003165612407)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6468627632987075 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.13294142394303357) - present_state_Q (0.0197864762940325)) * f3(0.002)
w4 ( 0.9252304238572768 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.13294142394303357) - present_state_Q (0.0197864762940325)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6494882360474468 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09904860545050508) - present_state_Q (0.09904860545050508)) * f3(0.12451481449113191)
w4 ( 0.9256521363674659 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09904860545050508) - present_state_Q (0.09904860545050508)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6516766947298678 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08113467040179814) - present_state_Q (0.08113467040179814)) * f3(0.09641687747193338)
w4 ( 0.9261060939607426 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08113467040179814) - present_state_Q (0.08113467040179814)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6534733923980898 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06745237318922265) - present_state_Q (0.06745237318922265)) * f3(0.07508362920710292)
w4 ( 0.926584679689002 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06745237318922265) - present_state_Q (0.06745237318922265)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.654826373915088 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05365713178368437) - present_state_Q (0.05365713178368437)) * f3(0.05375190267656108)
w4 ( 0.9270880968517914 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05365713178368437) - present_state_Q (0.05365713178368437)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6548828006604448 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.019851414684866005) - present_state_Q (0.019851414684866005)) * f3(0.002)
w4 ( 0.9276523643053586 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.019851414684866005) - present_state_Q (0.019851414684866005)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.6190543456451814 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.39962255288036375) - present_state_Q (0.3360540902549262)) * f3(0.3998301693775311)
w4 ( 0.9204836296256235 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.39962255288036375) - present_state_Q (0.3360540902549262)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5695733825286944 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.43719377416595584) - present_state_Q (0.43719377416595584)) * f3(0.49805977162962917)
w4 ( 0.9065749880711325 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.43719377416595584) - present_state_Q (0.43719377416595584)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5694621235965722 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.44844486154402113) - present_state_Q (0.0011391467650573887)) * f3(0.002)
w4 ( 0.9065749880711325 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.44844486154402113) - present_state_Q (0.0011391467650573887)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5277083911405486 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4292901018637651) - present_state_Q (0.4292901018637651)) * f3(0.5309740384911292)
w4 ( 0.8955659327876491 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.4292901018637651) - present_state_Q (0.4292901018637651)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4944352922245016 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.27813720231045364) - present_state_Q (0.27813720231045364)) * f3(0.3912993068788348)
w4 ( 0.8887633449310138 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.27813720231045364) - present_state_Q (0.27813720231045364)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4708972286104722 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2173744259789293) - present_state_Q (0.2173744259789293)) * f3(0.29583923454645267)
w4 ( 0.8823982490639656 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2173744259789293) - present_state_Q (0.2173744259789293)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4549583279222297 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2450889054988969) - present_state_Q (0.15560584810394293)) * f3(0.2180135004468827)
w4 ( 0.8780116673186412 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2450889054988969) - present_state_Q (0.15560584810394293)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4358897995218613 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.22959718217395342) - present_state_Q (0.16897097940046713)) * f3(0.2556064417865261)
w4 ( 0.8735355997515428 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.22959718217395342) - present_state_Q (0.16897097940046713)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.38878392477925894 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.1913236988663826) - present_state_Q (0.34424581938875654)) * f3(0.5091902486981895)
w4 ( 0.8605840114585132 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.1913236988663826) - present_state_Q (0.34424581938875654)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3650726910367916 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.17354305068147013) - present_state_Q (0.17354305068147013)) * f3(0.3135623728866245)
w4 ( 0.8560468789848332 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.17354305068147013) - present_state_Q (0.17354305068147013)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3649975636312807 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2509311782772985) - present_state_Q (0.0007301453820735831)) * f3(0.002)
w4 ( 0.8560468789848332 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.2509311782772985) - present_state_Q (0.0007301453820735831)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.36498190166304545 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.2242015395097399) - present_state_Q (0.0007299951272625615)) * f3(0.002)
w4 ( 0.8560468789848332 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.2242015395097399) - present_state_Q (0.0007299951272625615)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.36504343191387834 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08381217967718992) - present_state_Q (0.0007299638033260909)) * f3(0.002)
w4 ( 0.8560468789848332 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08381217967718992) - present_state_Q (0.0007299638033260909)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3663846522932267 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.035378900557013246) - present_state_Q (0.035378900557013246)) * f3(0.05001586491117593)
w4 ( 0.8565831969638306 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.035378900557013246) - present_state_Q (0.035378900557013246)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.36644536388590315 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.04290732686925498) - present_state_Q (0.0007327693045864534)) * f3(0.002)
w4 ( 0.8565831969638306 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.04290732686925498) - present_state_Q (0.0007327693045864534)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.36821161212023673 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0417994035858247) - present_state_Q (0.0417994035858247)) * f3(0.06731628252835166)
w4 ( 0.857107958037376 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0417994035858247) - present_state_Q (0.0417994035858247)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.37199706014563594 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12146356089620058) - present_state_Q (0.160456540655674)) * f3(0.24955189078251722)
w4 ( 0.8583214765608476 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12146356089620058) - present_state_Q (0.160456540655674)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3758603351326419 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16170373015916298) - present_state_Q (0.16170373015916298)) * f3(0.2501041594196229)
w4 ( 0.8595572097037016 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16170373015916298) - present_state_Q (0.16170373015916298)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.37592387634773367 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18457796129252846) - present_state_Q (0.0007517206702652838)) * f3(0.002)
w4 ( 0.8595572097037016 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18457796129252846) - present_state_Q (0.0007517206702652838)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3788262589480374 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08276440268402778) - present_state_Q (0.08276440268402778)) * f3(0.12870189243081154)
w4 ( 0.8604592578540391 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08276440268402778) - present_state_Q (0.08276440268402778)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3817366351192728 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05986333689031491) - present_state_Q (0.08410925987401982)) * f3(0.13117065775177486)
w4 ( 0.8613467661492992 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05986333689031491) - present_state_Q (0.08410925987401982)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3847213274956786 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06427929300082147) - present_state_Q (0.06427929300082147)) * f3(0.12325869028298547)
w4 ( 0.8618310634218976 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06427929300082147) - present_state_Q (0.06427929300082147)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.38791024749459463 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06875955410947389) - present_state_Q (0.06875955410947389)) * f3(0.1339227361696361)
w4 ( 0.8623072962245005 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06875955410947389) - present_state_Q (0.06875955410947389)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3908117545148144 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06361184617984114) - present_state_Q (0.06361184617984114)) * f3(0.11952687652572834)
w4 ( 0.8627927949013768 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06361184617984114) - present_state_Q (0.06361184617984114)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.39350014417557116 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05995896920241743) - present_state_Q (0.05995896920241743)) * f3(0.1092677300799333)
w4 ( 0.8632848687568124 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05995896920241743) - present_state_Q (0.05995896920241743)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3960685459969561 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05806018751778613) - present_state_Q (0.05806018751778613)) * f3(0.10367083912540646)
w4 ( 0.8637803604192804 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05806018751778613) - present_state_Q (0.05806018751778613)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3988346714646399 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.062167107916607386) - present_state_Q (0.062167107916607386)) * f3(0.11334275635350952)
w4 ( 0.8642684596250305 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.062167107916607386) - present_state_Q (0.062167107916607386)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4016119088222193 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06277374935274023) - present_state_Q (0.06277374935274023)) * f3(0.1140532240920598)
w4 ( 0.8647554668761955 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06277374935274023) - present_state_Q (0.06277374935274023)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.40219614879975607 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.02577173961550719) - present_state_Q (0.02577173961550719)) * f3(0.021106521225533696)
w4 ( 0.8653090777448876 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.02577173961550719) - present_state_Q (0.02577173961550719)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4022563501327736 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.018110573852497265) - present_state_Q (0.0008043922975995121)) * f3(0.002)
w4 ( 0.8653090777448876 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.018110573852497265) - present_state_Q (0.0008043922975995121)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.40601426688128983 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17593590830135608) - present_state_Q (0.17593590830135608)) * f3(0.2652815351368417)
w4 ( 0.8664423392051178 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17593590830135608) - present_state_Q (0.17593590830135608)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.40975911597907855 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09763548765361757) - present_state_Q (0.1433567169522022)) * f3(0.22504178806753575)
w4 ( 0.8674407801959968 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09763548765361757) - present_state_Q (0.1433567169522022)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.41360216322800863 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14490235235319207) - present_state_Q (0.14490235235319207)) * f3(0.2266109573171114)
w4 ( 0.8684583074932896 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14490235235319207) - present_state_Q (0.14490235235319207)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4163166958914229 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1072971073435189) - present_state_Q (0.1072971073435189)) * f3(0.13343646092947745)
w4 ( 0.8696789031136346 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1072971073435189) - present_state_Q (0.1072971073435189)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4184614609975568 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0899445849700552) - present_state_Q (0.07255100690778252)) * f3(0.09070943143987215)
w4 ( 0.8706246769199915 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0899445849700552) - present_state_Q (0.07255100690778252)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.41851504185375704 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.035661909998794775) - present_state_Q (0.035661909998794775)) * f3(0.002)
w4 ( 0.8716962940439958 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.035661909998794775) - present_state_Q (0.035661909998794775)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3939511977280916 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.6010332999680706) - present_state_Q (0.6010332999680706)) * f3(1.019542904047813)
w4 ( 0.8668776946445705 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.6010332999680706) - present_state_Q (0.6010332999680706)) * f4(0.2)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.38590767665028985 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.44285043663320656) - present_state_Q (0.44285043663320656)) * f3(0.816059352622809)
w4 ( 0.8654977791429921 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.44285043663320656) - present_state_Q (0.44285043663320656)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3859453928290748 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4089569030597995) - present_state_Q (0.3403221462664321)) * f3(0.6575986530117716)
w4 ( 0.8655035145833876 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4089569030597995) - present_state_Q (0.3403221462664321)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3826565332095449 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3837271662939178) - present_state_Q (0.3837271662939178)) * f3(0.7251459655792731)
w4 ( 0.8649592611874133 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3837271662939178) - present_state_Q (0.3837271662939178)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3861822356933121 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2507793502405995) - present_state_Q (0.2507793502405995)) * f3(0.4745315801159229)
w4 ( 0.865553649865681 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2507793502405995) - present_state_Q (0.2507793502405995)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3899641478277756 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.23604362148491748) - present_state_Q (0.23604362148491748)) * f3(0.43191870075589706)
w4 ( 0.8662541357909895 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.23604362148491748) - present_state_Q (0.23604362148491748)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.39439383511597964 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15845550296464836) - present_state_Q (0.12531271159973167)) * f3(0.2324894395372275)
w4 ( 0.8670162671457765 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15845550296464836) - present_state_Q (0.12531271159973167)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.39823876819382786 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.22524753933369818) - present_state_Q (0.22524753933369818)) * f3(0.39525526030647645)
w4 ( 0.8677944848625739 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.22524753933369818) - present_state_Q (0.22524753933369818)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.40183325704545536 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10409419134106676) - present_state_Q (0.10409419134106676)) * f3(0.17422314824154564)
w4 ( 0.8686197457737461 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10409419134106676) - present_state_Q (0.10409419134106676)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.401891657162678 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10176647542859037) - present_state_Q (0.018176061429565835)) * f3(0.002)
w4 ( 0.8692037469459727 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10176647542859037) - present_state_Q (0.018176061429565835)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.40195349188608803 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09977400364606591) - present_state_Q (0.000803783314325356)) * f3(0.002)
w4 ( 0.8692037469459727 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09977400364606591) - present_state_Q (0.000803783314325356)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4047041311018695 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06279220652509031) - present_state_Q (0.06279220652509031)) * f3(0.11296862075535677)
w4 ( 0.8696907209742275 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06279220652509031) - present_state_Q (0.06279220652509031)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4070038923120698 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05447900180025329) - present_state_Q (0.05447900180025329)) * f3(0.09163530720528747)
w4 ( 0.8701926587709871 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05447900180025329) - present_state_Q (0.05447900180025329)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.41857685920101345 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2735769224651608) - present_state_Q (0.018270955964587433)) * f3(0.002)
w4 ( 0.8723144675165597 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2735769224651608) - present_state_Q (0.018270955964587433)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.41864237878336097 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.28435065456038355) - present_state_Q (0.0008371537184020269)) * f3(0.002)
w4 ( 0.8723144675165597 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.28435065456038355) - present_state_Q (0.0008371537184020269)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.42160597092265484 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.24710823469467716) - present_state_Q (0.24710823469467716)) * f3(0.38189346336041674)
w4 ( 0.8730904934043077 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.24710823469467716) - present_state_Q (0.24710823469467716)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.42479445937018967 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.22430255566840593) - present_state_Q (0.22430255566840593)) * f3(0.32493255735485566)
w4 ( 0.874071770403292 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.22430255566840593) - present_state_Q (0.22430255566840593)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4280388572254331 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12697563737211148) - present_state_Q (0.12643790386234918)) * f3(0.17418682378262731)
w4 ( 0.8751893283625412 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12697563737211148) - present_state_Q (0.12643790386234918)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.43107760182945837 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09586793884585715) - present_state_Q (0.09586793884585715)) * f3(0.14218420754100478)
w4 ( 0.8760442037826961 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09586793884585715) - present_state_Q (0.09586793884585715)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4337684464611895 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06824139081397537) - present_state_Q (0.06560924303501398)) * f3(0.11155383335918397)
w4 ( 0.8765266335747889 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06824139081397537) - present_state_Q (0.06560924303501398)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.4338307742226318 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1250634410437354) - present_state_Q (0.0008675368929223791)) * f3(0.002)
w4 ( 0.8765266335747889 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1250634410437354) - present_state_Q (0.0008675368929223791)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3802173573599299 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.37161917563600544) - present_state_Q (0.37161917563600544)) * f3(0.5737385674899184)
w4 ( 0.8634442319617752 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.37161917563600544) - present_state_Q (0.37161917563600544)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3322623877074128 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.3216666860224668) - present_state_Q (0.32508198133988003)) * f3(0.5370606704625726)
w4 ( 0.8509434175834484 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.3216666860224668) - present_state_Q (0.32508198133988003)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3048512440975626 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.28472475647669754) - present_state_Q (0.18798969967419668)) * f3(0.36090219869579754)
w4 ( 0.8448672797912362 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.28472475647669754) - present_state_Q (0.18798969967419668)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.29664638272670807 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.3744476532172382) - present_state_Q (0.07314147642529997)) * f3(0.1290688032129475)
w4 ( 0.8423244929468219 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.3744476532172382) - present_state_Q (0.07314147642529997)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.30123193772954315 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18882047377407943) - present_state_Q (0.18882047377407943)) * f3(0.35256800881253697)
w4 ( 0.8436251086828551 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18882047377407943) - present_state_Q (0.18882047377407943)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3023245738348318 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17811354359921167) - present_state_Q (0.08141298507671417)) * f3(0.04622012024032561)
w4 ( 0.8455162956371207 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17811354359921167) - present_state_Q (0.08141298507671417)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.307028797016657 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10218464548002036) - present_state_Q (0.10218464548002036)) * f3(0.22612780955042264)
w4 ( 0.8463484309133926 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10218464548002036) - present_state_Q (0.10218464548002036)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3117433273785399 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10397779655231255) - present_state_Q (0.10397779655231255)) * f3(0.22839505608971422)
w4 ( 0.8471741108458043 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10397779655231255) - present_state_Q (0.10397779655231255)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.31254950448096025 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11393554690184823) - present_state_Q (0.025741613658170955)) * f3(0.028222356883268854)
w4 ( 0.8477454147278684 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11393554690184823) - present_state_Q (0.025741613658170955)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3126117299144159 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11752266287236059) - present_state_Q (0.0006250990089619206)) * f3(0.002)
w4 ( 0.8477454147278684 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11752266287236059) - present_state_Q (0.0006250990089619206)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.31613352833451974 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08272176453195232) - present_state_Q (0.08272176453195232)) * f3(0.15614240692823936)
w4 ( 0.8486476163755533 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08272176453195232) - present_state_Q (0.08272176453195232)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.31964038276577983 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08319037999319173) - present_state_Q (0.08319037999319173)) * f3(0.15577112493446468)
w4 ( 0.8495481310075779 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08319037999319173) - present_state_Q (0.08319037999319173)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.31970251243573305 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11287630531738432) - present_state_Q (0.0006392807655315597)) * f3(0.002)
w4 ( 0.8495481310075779 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11287630531738432) - present_state_Q (0.0006392807655315597)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.32271497168437646 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07219785905295328) - present_state_Q (0.055206896432801716)) * f3(0.11953591956939147)
w4 ( 0.8500521567865229 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07219785905295328) - present_state_Q (0.055206896432801716)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.32594213785786147 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05921543530396664) - present_state_Q (0.05921543530396664)) * f3(0.13081014477854144)
w4 ( 0.8505455690029757 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05921543530396664) - present_state_Q (0.05921543530396664)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.32846875858069663 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.049217323620236064) - present_state_Q (0.049217323620236064)) * f3(0.0988102135300508)
w4 ( 0.8510569778204593 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.049217323620236064) - present_state_Q (0.049217323620236064)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3304969292847872 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.04246991959446904) - present_state_Q (0.04246991959446904)) * f3(0.07747701835639788)
w4 ( 0.8515805319651892 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.04246991959446904) - present_state_Q (0.04246991959446904)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3320812060371423 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.03664030258405904) - present_state_Q (0.03664030258405904)) * f3(0.05933093534995771)
w4 ( 0.8521145794205379 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.03664030258405904) - present_state_Q (0.03664030258405904)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3334676369409718 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0341404259062065) - present_state_Q (0.0341404259062065)) * f3(0.0514878108334844)
w4 ( 0.8526531266539068 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0341404259062065) - present_state_Q (0.0341404259062065)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3346631462969155 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.031740397397977495) - present_state_Q (0.031740397397977495)) * f3(0.044044258686186125)
w4 ( 0.8531959939385905 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.031740397397977495) - present_state_Q (0.031740397397977495)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3384790769377439 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10450995180316022) - present_state_Q (0.11731291922666293)) * f3(0.19757526432768413)
w4 ( 0.8543548223943124 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10450995180316022) - present_state_Q (0.11731291922666293)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3412829094731887 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0751318610175154) - present_state_Q (0.0961654126815763)) * f3(0.13266439906469235)
w4 ( 0.8556229090348334 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0751318610175154) - present_state_Q (0.0961654126815763)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.34244642364710465 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.049785177540424545) - present_state_Q (0.049785177540424545)) * f3(0.04559343801613256)
w4 ( 0.8566436823956879 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.049785177540424545) - present_state_Q (0.049785177540424545)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3438655660491867 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.03524773915128224) - present_state_Q (0.03524773915128224)) * f3(0.052898393011211825)
w4 ( 0.8571802364652156 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.03524773915128224) - present_state_Q (0.03524773915128224)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3439267622685914 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06668828155666565) - present_state_Q (0.0006877311320983735)) * f3(0.002)
w4 ( 0.8571802364652156 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06668828155666565) - present_state_Q (0.0006877311320983735)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.34586284370676584 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0425907094840932) - present_state_Q (0.0425907094840932)) * f3(0.07398989420577813)
w4 ( 0.8577035731881442 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0425907094840932) - present_state_Q (0.0425907094840932)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.34823709873719527 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.049274427912475764) - present_state_Q (0.049274427912475764)) * f3(0.09287021440194253)
w4 ( 0.8582148792179017 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.049274427912475764) - present_state_Q (0.049274427912475764)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.35083859221937597 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.053081908290983484) - present_state_Q (0.053081908290983484)) * f3(0.10314125300512987)
w4 ( 0.858719331782978 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.053081908290983484) - present_state_Q (0.053081908290983484)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.35090035597902 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09520475404536857) - present_state_Q (0.000701677184438752)) * f3(0.002)
w4 ( 0.858719331782978 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09520475404536857) - present_state_Q (0.000701677184438752)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.35326608270263754 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05043574611025331) - present_state_Q (0.04968266482795118)) * f3(0.0926424770975019)
w4 ( 0.8592300536025441 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05043574611025331) - present_state_Q (0.04968266482795118)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3533225186066334 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0007065321654052751) - present_state_Q (0.01789113323745616)) * f3(0.002)
w4 ( 0.8597944126425023 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0007065321654052751) - present_state_Q (0.01789113323745616)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.34630749290436597 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.39112814989081124) - present_state_Q (0.4214387484347283)) * f3(0.852103997933874)
w4 ( 0.8586418495742633 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.39112814989081124) - present_state_Q (0.4214387484347283)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.34760395862317583 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.31119415732064537) - present_state_Q (0.31119415732064537)) * f3(0.6506644441142505)
w4 ( 0.8588411021583775 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.31119415732064537) - present_state_Q (0.31119415732064537)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3527497537491917 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2539927449844229) - present_state_Q (0.12251879036463656)) * f3(0.25363677280176755)
w4 ( 0.8596526240949127 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2539927449844229) - present_state_Q (0.12251879036463656)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3577227239278369 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19308437218077296) - present_state_Q (0.16601181975192347)) * f3(0.32440182052569594)
w4 ( 0.8605724037997097 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19308437218077296) - present_state_Q (0.16601181975192347)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.36207586924624424 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18745205952804928) - present_state_Q (0.18745205952804928)) * f3(0.33155921972683755)
w4 ( 0.8616227489711077 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18745205952804928) - present_state_Q (0.18745205952804928)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3668961311274211 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17159940359989728) - present_state_Q (0.17159940359989728)) * f3(0.3311516973258624)
w4 ( 0.8624961121916682 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.17159940359989728) - present_state_Q (0.17159940359989728)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3437655557460718 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1778071764817718) - present_state_Q (0.2118529913963413)) * f3(0.3893562518144833)
w4 ( 0.8577435340016829 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1778071764817718) - present_state_Q (0.2118529913963413)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3187146758036214 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.16633241466316034) - present_state_Q (0.16633241466316034)) * f3(0.3341457592333899)
w4 ( 0.8532453389625019 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.16633241466316034) - present_state_Q (0.16633241466316034)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3040342618198476 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.18245730509656632) - present_state_Q (0.10250802763194376)) * f3(0.21454366323430765)
w4 ( 0.8505082897740127 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.18245730509656632) - present_state_Q (0.10250802763194376)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.29520014481186324 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.12097603798230055) - present_state_Q (0.12097603798230055)) * f3(0.2860062739996874)
w4 ( 0.8492727760372765 ) += alpha ( 0.1) * (reward ( -0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.12097603798230055) - present_state_Q (0.12097603798230055)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.27552583117239554 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.11638186951017335) - present_state_Q (0.11638186951017335)) * f3(0.2791697765636409)
w4 ( 0.8464538013070398 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.11638186951017335) - present_state_Q (0.11638186951017335)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.27049668006313654 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.105075488402221) - present_state_Q (0.105075488402221)) * f3(0.25847789315034847)
w4 ( 0.8456755295487919 ) += alpha ( 0.1) * (reward ( -0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.105075488402221) - present_state_Q (0.105075488402221)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.27121565413323906 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.10835336893884889) - present_state_Q (0.04773359433758268)) * f3(0.1139388614285881)
w4 ( 0.8458017330339045 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.10835336893884889) - present_state_Q (0.04773359433758268)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.27430873797363103 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0874554745628952) - present_state_Q (0.04924298993520104)) * f3(0.11919280757533937)
w4 ( 0.8463207381489467 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0874554745628952) - present_state_Q (0.04924298993520104)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2771885360161395 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05012291572512832) - present_state_Q (0.06704933048810725)) * f3(0.12101875137984311)
w4 ( 0.8472725899932844 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05012291572512832) - present_state_Q (0.06704933048810725)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2800932883482889 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.048336176074804914) - present_state_Q (0.048336176074804914)) * f3(0.11324683454120728)
w4 ( 0.8477855848763497 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.048336176074804914) - present_state_Q (0.048336176074804914)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.28250364484128576 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.04277264265908369) - present_state_Q (0.04277264265908369)) * f3(0.09217261546608001)
w4 ( 0.8483085941195634 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.04277264265908369) - present_state_Q (0.04277264265908369)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.28466223990342227 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.040070636029142036) - present_state_Q (0.040070636029142036)) * f3(0.08178465860053294)
w4 ( 0.8488364669747109 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.040070636029142036) - present_state_Q (0.040070636029142036)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.28455022956478476 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.4051763129240251) - present_state_Q (0.0005693244798068445)) * f3(0.002)
w4 ( 0.8488364669747109 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.4051763129240251) - present_state_Q (0.0005693244798068445)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.28962634682050664 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16107531654449303) - present_state_Q (0.16107531654449303)) * f3(0.32742338436702645)
w4 ( 0.8500767246955906 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16107531654449303) - present_state_Q (0.16107531654449303)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2949008952923118 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18550658151142863) - present_state_Q (0.133603997057195)) * f3(0.28519295458520494)
w4 ( 0.8511864046621542 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18550658151142863) - present_state_Q (0.133603997057195)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2996945363161022 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12731182224763862) - present_state_Q (0.12731182224763862)) * f3(0.2585296931443294)
w4 ( 0.852298920822017 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12731182224763862) - present_state_Q (0.12731182224763862)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3034065940125818 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1034102890974404) - present_state_Q (0.08303379637372177)) * f3(0.1633057450510869)
w4 ( 0.8532081497521611 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1034102890974404) - present_state_Q (0.08303379637372177)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.307097922355117 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10560890444111132) - present_state_Q (0.08344012534502987)) * f3(0.16252711815781612)
w4 ( 0.8541166328125575 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10560890444111132) - present_state_Q (0.08344012534502987)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.30990852598545726 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06015592625115276) - present_state_Q (0.05091758452106303)) * f3(0.11017740401931475)
w4 ( 0.8546268288287655 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.06015592625115276) - present_state_Q (0.05091758452106303)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3099700497950936 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08238865233662115) - present_state_Q (0.0006198170519709145)) * f3(0.002)
w4 ( 0.8546268288287655 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08238865233662115) - present_state_Q (0.0006198170519709145)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.31292821263518233 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05350090908806264) - present_state_Q (0.05350090908806264)) * f3(0.11745771094838085)
w4 ( 0.855130527192407 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05350090908806264) - present_state_Q (0.05350090908806264)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3144762517397343 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.03515382132925666) - present_state_Q (0.03515382132925666)) * f3(0.057684830119337824)
w4 ( 0.8556672503140144 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.03515382132925666) - present_state_Q (0.03515382132925666)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3157807913748482 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.03225315625670203) - present_state_Q (0.03225315625670203)) * f3(0.04814293978214832)
w4 ( 0.8562091946327522 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.03225315625670203) - present_state_Q (0.03225315625670203)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3169900238670101 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.03116539693781234) - present_state_Q (0.03116539693781234)) * f3(0.04446506383122476)
w4 ( 0.8567530969182642 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.03116539693781234) - present_state_Q (0.03116539693781234)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3183843918852234 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.03351540125162426) - present_state_Q (0.03351540125162426)) * f3(0.05167462090267921)
w4 ( 0.8572927691960113 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.03351540125162426) - present_state_Q (0.03351540125162426)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3205002698580636 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.04291993907961188) - present_state_Q (0.04291993907961188)) * f3(0.08095272366549655)
w4 ( 0.857815513305668 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.04291993907961188) - present_state_Q (0.04291993907961188)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.32262870763876583 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0432888910243757) - present_state_Q (0.0432888910243757)) * f3(0.08153684478903991)
w4 ( 0.8583375933018241 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0432888910243757) - present_state_Q (0.0432888910243757)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.32269017444580905 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0797929263126442) - present_state_Q (0.0006452574152775316)) * f3(0.002)
w4 ( 0.8583375933018241 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0797929263126442) - present_state_Q (0.0006452574152775316)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3254561665694965 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05247785375122854) - present_state_Q (0.05247785375122854)) * f3(0.10942726082638139)
w4 ( 0.8588431331650719 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05247785375122854) - present_state_Q (0.05247785375122854)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3282448091845994 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.31597473532365083) - present_state_Q (0.271660442112271)) * f3(0.4652620506940889)
w4 ( 0.8596822516049532 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.31597473532365083) - present_state_Q (0.271660442112271)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3296480114372382 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3022630329087952) - present_state_Q (0.3022630329087952)) * f3(0.5018019113879432)
w4 ( 0.8601296639310665 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.3022630329087952) - present_state_Q (0.3022630329087952)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3314525893984891 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2956033964340084) - present_state_Q (0.2956033964340084)) * f3(0.5314312157378588)
w4 ( 0.860605061135998 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.2956033964340084) - present_state_Q (0.2956033964340084)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3350869047193415 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.20945402738501526) - present_state_Q (0.24529645185987836)) * f3(0.48041846960754025)
w4 ( 0.8613615506447843 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.20945402738501526) - present_state_Q (0.24529645185987836)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.340596807979975 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.25581772076642906) - present_state_Q (0.127808794365759)) * f3(0.278597375860326)
w4 ( 0.8621526425556278 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.25581772076642906) - present_state_Q (0.127808794365759)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3445169078518499 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19928068669286964) - present_state_Q (0.07084703372516057)) * f3(0.15738251098700726)
w4 ( 0.8626508046255161 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19928068669286964) - present_state_Q (0.07084703372516057)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.34922216311350984 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15000839562348617) - present_state_Q (0.15000839562348617)) * f3(0.2851800451785218)
w4 ( 0.8636407592891493 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.15000839562348617) - present_state_Q (0.15000839562348617)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.35362215537267566 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1402346579329834) - present_state_Q (0.1402346579329834)) * f3(0.25318041554795584)
w4 ( 0.8646834921363112 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1402346579329834) - present_state_Q (0.1402346579329834)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3536813718275573 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1408318856168026) - present_state_Q (0.01800091415347158)) * f3(0.002)
w4 ( 0.8652756566851276 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1408318856168026) - present_state_Q (0.01800091415347158)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3419364360642606 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.47179255429080824) - present_state_Q (0.47179255429080824)) * f3(0.9425106205019947)
w4 ( 0.86328184390334 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.47179255429080824) - present_state_Q (0.47179255429080824)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3316353052664886 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4563274593430409) - present_state_Q (0.4563274593430409)) * f3(0.930589228749832)
w4 ( 0.8615107284888002 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.4563274593430409) - present_state_Q (0.4563274593430409)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.33569757751223794 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.22723384440120958) - present_state_Q (0.22723384440120958)) * f3(0.42541541660940235)
w4 ( 0.8624656238891892 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.22723384440120958) - present_state_Q (0.22723384440120958)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3391199807336182 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.33009819544463326) - present_state_Q (0.07988743922075203)) * f3(0.13520745249801455)
w4 ( 0.8634781134104841 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.33009819544463326) - present_state_Q (0.07988743922075203)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.345414537875883 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.32403184897276927) - present_state_Q (0.1545808683640075)) * f3(0.3539801564269432)
w4 ( 0.8641894026766171 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.32403184897276927) - present_state_Q (0.1545808683640075)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3489122452134568 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.26468643928308083) - present_state_Q (0.26468643928308083)) * f3(0.5661350801025591)
w4 ( 0.864683660313779 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.26468643928308083) - present_state_Q (0.26468643928308083)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.35130114370693083 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.04997803939374108) - present_state_Q (0.04997803939374108)) * f3(0.09367503329517693)
w4 ( 0.8651936998428702 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.04997803939374108) - present_state_Q (0.04997803939374108)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3534697879454769 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07600099494609959) - present_state_Q (0.046479996068615324)) * f3(0.08305160001442462)
w4 ( 0.8657159400497222 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07600099494609959) - present_state_Q (0.046479996068615324)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.355366005089824 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0429617417481834) - present_state_Q (0.0429617417481834)) * f3(0.07255902434056147)
w4 ( 0.8662386089145755 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0429617417481834) - present_state_Q (0.0429617417481834)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3567570636004962 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.03578428353619666) - present_state_Q (0.03578428353619666)) * f3(0.05194506816497326)
w4 ( 0.8667741972042103 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.03578428353619666) - present_state_Q (0.03578428353619666)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3568172818776322 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0180489980712852) - present_state_Q (0.0007135141272009924)) * f3(0.002)
w4 ( 0.8667741972042103 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.0180489980712852) - present_state_Q (0.0007135141272009924)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3585368494310632 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.313624944309983) - present_state_Q (0.29628946036589876)) * f3(0.49028195001301544)
w4 ( 0.8672652196811217 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.313624944309983) - present_state_Q (0.29628946036589876)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3602441751745022 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.27511836289122815) - present_state_Q (0.03852775836859565)) * f3(0.05908027029463263)
w4 ( 0.8678431878369628 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.27511836289122815) - present_state_Q (0.03852775836859565)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.363783490280105 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.24214840935380733) - present_state_Q (0.24214840935380733)) * f3(0.4312744001894069)
w4 ( 0.8686638521527785 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.24214840935380733) - present_state_Q (0.24214840935380733)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3661909034611685 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.23217413124561193) - present_state_Q (0.06922731430576076)) * f3(0.09478374126626864)
w4 ( 0.8696798125480537 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.23217413124561193) - present_state_Q (0.06922731430576076)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3704609955876387 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19719981549395219) - present_state_Q (0.19719981549395219)) * f3(0.3485215751779085)
w4 ( 0.8706599738764973 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19719981549395219) - present_state_Q (0.19719981549395219)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3746783554120607 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19677932940905646) - present_state_Q (0.19677932940905646)) * f3(0.34315766845382456)
w4 ( 0.8716431627047521 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19677932940905646) - present_state_Q (0.19677932940905646)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3788506770503534 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.20284597485010658) - present_state_Q (0.20284597485010658)) * f3(0.3552767858376309)
w4 ( 0.8725826716858313 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.20284597485010658) - present_state_Q (0.20284597485010658)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.35531239083635124 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.21912520493519483) - present_state_Q (0.21912520493519483)) * f3(0.3941357380245152)
w4 ( 0.8678049702102979 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.21912520493519483) - present_state_Q (0.21912520493519483)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3286036768060846 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.17704442552182395) - present_state_Q (0.17704442552182395)) * f3(0.35173591051815367)
w4 ( 0.8632489303124801 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.17704442552182395) - present_state_Q (0.17704442552182395)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.30187392201513186 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.1686325805766033) - present_state_Q (0.1686325805766033)) * f3(0.35555793499779575)
w4 ( 0.8587383143773664 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.1686325805766033) - present_state_Q (0.1686325805766033)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.27461342790675597 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.16188113516947805) - present_state_Q (0.16188113516947805)) * f3(0.3655726058420651)
w4 ( 0.8542641562474512 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.16188113516947805) - present_state_Q (0.16188113516947805)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2568486753242129 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.12014745067988869) - present_state_Q (0.12014745067988869)) * f3(0.25086756255937176)
w4 ( 0.8500153600137799 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.12014745067988869) - present_state_Q (0.12014745067988869)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.24146927168913293 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.10768195825019006) - present_state_Q (0.10768195825019006)) * f3(0.2206787190076662)
w4 ( 0.8458338774392289 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.10768195825019006) - present_state_Q (0.10768195825019006)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2388867040054089 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.0435890085032953) - present_state_Q (0.0435890085032953)) * f3(0.040401220981382484)
w4 ( 0.843276957008617 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.0435890085032953) - present_state_Q (0.0435890085032953)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.23763315762289655 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.02396884747451143) - present_state_Q (0.02396884747451143)) * f3(0.029735051031464087)
w4 ( 0.8424338130831629 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.02396884747451143) - present_state_Q (0.02396884747451143)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3597517771034024 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1759710785396167) - present_state_Q (0.1001624684087136)) * f3(0.13495987728805056)
w4 ( 0.8680788050408819 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1759710785396167) - present_state_Q (0.1001624684087136)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.36302674380074546 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08810548351266398) - present_state_Q (0.08810548351266398)) * f3(0.1483865673738845)
w4 ( 0.8689616253002362 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08810548351266398) - present_state_Q (0.08810548351266398)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3656426440134466 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05533472814990807) - present_state_Q (0.05533472814990807)) * f3(0.10455289119067213)
w4 ( 0.8694620227895664 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05533472814990807) - present_state_Q (0.05533472814990807)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3685169296748298 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08982584806598748) - present_state_Q (0.059517906338794675)) * f3(0.11521814146342858)
w4 ( 0.869960952146502 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08982584806598748) - present_state_Q (0.059517906338794675)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3720556152851869 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09579837396917085) - present_state_Q (0.09579837396917085)) * f3(0.16552817786997082)
w4 ( 0.870816078000213 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09579837396917085) - present_state_Q (0.09579837396917085)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.37555149208699795 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09563028260621166) - present_state_Q (0.09563028260621166)) * f3(0.16341008437569401)
w4 ( 0.8716718089828306 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09563028260621166) - present_state_Q (0.09563028260621166)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3780693466520194 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05520977311084009) - present_state_Q (0.05520977311084009)) * f3(0.10058896776379321)
w4 ( 0.8721724313912311 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05520977311084009) - present_state_Q (0.05520977311084009)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3803967985482355 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05222381203720311) - present_state_Q (0.05222381203720311)) * f3(0.09199466636841852)
w4 ( 0.8726784285295641 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05222381203720311) - present_state_Q (0.05222381203720311)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.38403269901717657 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10107242573484657) - present_state_Q (0.10107242573484657)) * f3(0.17393755374961192)
w4 ( 0.8735145677969187 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10107242573484657) - present_state_Q (0.10107242573484657)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3856172494621356 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05885843808306249) - present_state_Q (0.05885843808306249)) * f3(0.10777245487961158)
w4 ( 0.8738086226083692 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.05885843808306249) - present_state_Q (0.05885843808306249)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.38075668438018007 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.04667097640479974) - present_state_Q (0.04667097640479974)) * f3(0.07570927906714153)
w4 ( 0.8725246148508405 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.04667097640479974) - present_state_Q (0.04667097640479974)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3259797293842906 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2432698517534118) - present_state_Q (0.20948420729197054)) * f3(0.3927564011983434)
w4 ( 0.8604929394272773 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2432698517534118) - present_state_Q (0.20948420729197054)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.29305905179694985 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2192364096278483) - present_state_Q (0.20575068005679303)) * f3(0.41999925934415727)
w4 ( 0.8542223231145253 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2192364096278483) - present_state_Q (0.20575068005679303)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.26327606862849245 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22935240617200497) - present_state_Q (0.22935240617200497)) * f3(0.49113027895919265)
w4 ( 0.8481581514589772 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.22935240617200497) - present_state_Q (0.22935240617200497)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.21862566296886793 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2450431668523072) - present_state_Q (0.2450431668523072)) * f3(0.5441595562541969)
w4 ( 0.8383116852569723 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2450431668523072) - present_state_Q (0.2450431668523072)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1840758655647125 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.18264893490578538) - present_state_Q (0.18264893490578538)) * f3(0.4519952737394773)
w4 ( 0.8306678448428202 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.18264893490578538) - present_state_Q (0.18264893490578538)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.19076728758108805 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18183727936789723) - present_state_Q (0.13294903141666017)) * f3(0.3612402072658341)
w4 ( 0.8321497224149812 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18183727936789723) - present_state_Q (0.13294903141666017)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.19605881883129186 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1440439969231277) - present_state_Q (0.1179573904666049)) * f3(0.26936176178300164)
w4 ( 0.8337212984887868 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1440439969231277) - present_state_Q (0.1179573904666049)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.20021480873253694 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1299507250074413) - present_state_Q (0.15005327500536142)) * f3(0.25505977994153717)
w4 ( 0.8356766000587315 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1299507250074413) - present_state_Q (0.15005327500536142)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.20225224918011517 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11989279131821404) - present_state_Q (0.03124361384966296)) * f3(0.0725724632482045)
w4 ( 0.8362380913892957 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11989279131821404) - present_state_Q (0.03124361384966296)) * f4(0.02)
============================================================================
