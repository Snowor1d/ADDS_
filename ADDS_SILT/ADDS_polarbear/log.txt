GUIDE learning . . .
w1 ( -2.559032517211812 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.8144596229892833) - present_state_Q ( -0.9320463457009742)) * f1( 0.2757337699852224)
w2 ( -2.363228450399798 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.8144596229892833) - present_state_Q (-0.9320463457009742)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.50795518336437 ) += alpha ( 0.1 ) * (reward ( 0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0998376672194934) - present_state_Q ( -1.1845883039540814)) * f1( 0.32438198061607665)
w2 ( -2.3396093823413158 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.0998376672194934) - present_state_Q (-1.1845883039540814)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.531149966178694 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.6433300883412951) - present_state_Q ( -0.6433300883412951)) * f1( 0.16322825576093564)
w2 ( -2.3538194115462443 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.6433300883412951) - present_state_Q (-0.6433300883412951)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.4578527427221077 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.9190570759887366) - present_state_Q ( -1.8950651955894051)) * f1( 0.6092062123784122)
w2 ( -2.335772019226386 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.9190570759887366) - present_state_Q (-1.8950651955894051)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.3560287418627017 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-2.174301675147536) - present_state_Q ( -2.2910902761088554)) * f1( 0.6470520559256915)
w2 ( -2.2885622159685632 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -2.174301675147536) - present_state_Q (-2.2910902761088554)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.1840661530797396 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-2.013054402194328) - present_state_Q ( -2.013054402194328)) * f1( 0.6115858531772347)
w2 ( -2.218268491919191 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -2.013054402194328) - present_state_Q (-2.013054402194328)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.0416118063630395 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.8377832565799546) - present_state_Q ( -1.8377832565799546)) * f1( 0.5367523814931795)
w2 ( -2.138648343991532 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.8377832565799546) - present_state_Q (-1.8377832565799546)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.0425805793066174 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.5959032360922671) - present_state_Q ( -1.6397757019578691)) * f1( 0.4889182143487824)
w2 ( -2.1392427826410727 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -1.5959032360922671) - present_state_Q (-1.6397757019578691)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.06995242355234 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.4889339954390628) - present_state_Q ( -1.4889339954390628)) * f1( 0.4147504236696119)
w2 ( -2.159041564764218 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.4889339954390628) - present_state_Q (-1.4889339954390628)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.1030711550617043 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0428294700358671) - present_state_Q ( -1.150781548274078)) * f1( 0.34733804851773914)
w2 ( -2.178111592738808 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.0428294700358671) - present_state_Q (-1.150781548274078)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.138343067047124 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.7955157709982813) - present_state_Q ( -0.7955157709982813)) * f1( 0.27469570410586064)
w2 ( -2.190951950799824 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.7955157709982813) - present_state_Q (-0.7955157709982813)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.0960854057529783 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0190672135342234) - present_state_Q ( -1.0190672135342234)) * f1( 0.22041796430969068)
w2 ( -2.143022938495304 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.0190672135342234) - present_state_Q (-1.0190672135342234)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.0654231809184536 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.740687442216891) - present_state_Q ( -0.8897341761079244)) * f1( 0.16887596302734548)
w2 ( -2.097631302698148 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.740687442216891) - present_state_Q (-0.8897341761079244)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.0476063465047933 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0010314305450188) - present_state_Q ( -1.0421806234997129)) * f1( 0.4030251528695142)
w2 ( -2.093210527893696 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.0010314305450188) - present_state_Q (-1.0421806234997129)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.082382710004627 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.7448794872889509) - present_state_Q ( -0.7448794872889509)) * f1( 0.26155341597459125)
w2 ( -2.1065066125080953 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.7448794872889509) - present_state_Q (-0.7448794872889509)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.109723190361001 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.46540395605767076) - present_state_Q ( -0.46540395605767076)) * f1( 0.1729166419324841)
w2 ( -2.114412294705836 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.46540395605767076) - present_state_Q (-0.46540395605767076)) * f2(0.05)
============================================================================
GUIDE learning . . .
w1 ( -2.1118751039330625 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.31863521605268474) - present_state_Q ( -0.31863521605268474)) * f1( 0.10092063370690847)
w2 ( -2.115478436233599 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -0.31863521605268474) - present_state_Q (-0.31863521605268474)) * f2(0.05)
============================================================================
GUIDE learning . . .
w1 ( -2.0451845555782717 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.8026275859010128) - present_state_Q ( -1.8444415043468625)) * f1( 0.5728548867419805)
w2 ( -2.080553073860896 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.8026275859010128) - present_state_Q (-1.8444415043468625)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -1.9559961086759143 ) += alpha ( 0.1 ) * (reward ( 0 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.833555556500424) - present_state_Q ( -1.833555556500424)) * f1( 0.540470529974529)
w2 ( -2.022796073831133 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( -1.833555556500424) - present_state_Q (-1.833555556500424)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -1.8608274395945257 ) += alpha ( 0.1 ) * (reward ( 0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.64702595770293) - present_state_Q ( -1.64702595770293)) * f1( 0.4800865030849724)
w2 ( -1.9534147561634905 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.64702595770293) - present_state_Q (-1.64702595770293)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -1.8894915756899084 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.4995400488561028) - present_state_Q ( -1.4807670342973096)) * f1( 0.42834271071033314)
w2 ( -1.976836300134081 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.4995400488561028) - present_state_Q (-1.4807670342973096)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -1.9133108419777125 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.6170189842339266) - present_state_Q ( -1.6170189842339266)) * f1( 0.43730518559131115)
w2 ( -1.9986236167016596 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.6170189842339266) - present_state_Q (-1.6170189842339266)) * f2(0.4)
============================================================================
GUIDE learning . . .
w1 ( -1.9382869541171952 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.6336995705349397) - present_state_Q ( -1.6719535332895874)) * f1( 0.5082474034584152)
w2 ( -2.0158231915333964 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.6336995705349397) - present_state_Q (-1.6719535332895874)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -1.9600841561631783 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.7654414401784653) - present_state_Q ( -1.7852392700252375)) * f1( 0.5570388588207288)
w2 ( -2.0295188621231377 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.7654414401784653) - present_state_Q (-1.7852392700252375)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -1.9769179024017585 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.873840561826412) - present_state_Q ( -1.9130403311970068)) * f1( 0.6136005567272093)
w2 ( -2.039120892497635 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.873840561826412) - present_state_Q (-1.9130403311970068)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -1.9831815972086295 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-2.00215396651434) - present_state_Q ( -2.1041100111392215)) * f1( 0.6517527372152455)
w2 ( -2.0429651079181235 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -2.00215396651434) - present_state_Q (-2.1041100111392215)) * f2(0.4)
============================================================================
GUIDE learning . . .
w1 ( -1.9930109158288363 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-2.0459542438006357) - present_state_Q ( -2.0459542438006357)) * f1( 0.6195943943625253)
w2 ( -2.049310755141301 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -2.0459542438006357) - present_state_Q (-2.0459542438006357)) * f2(0.4)
============================================================================
GUIDE learning . . .
w1 ( -2.0016310607345535 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-2.0245930806267607) - present_state_Q ( -2.0644349131557416)) * f1( 0.6245377791027208)
w2 ( -2.054831730937578 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -2.0245930806267607) - present_state_Q (-2.0644349131557416)) * f2(0.4)
============================================================================
GUIDE learning . . .
w1 ( -2.0041165675964607 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-2.1369666427751652) - present_state_Q ( -2.176981623042726)) * f1( 0.6769723738052017)
w2 ( -2.0563003325869698 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -2.1369666427751652) - present_state_Q (-2.176981623042726)) * f2(0.4)
============================================================================
GUIDE learning . . .
w1 ( -2.0076786713795447 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-2.135209280930333) - present_state_Q ( -2.155488562941456)) * f1( 0.6138133046585429)
w2 ( -2.058911789018791 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -2.135209280930333) - present_state_Q (-2.155488562941456)) * f2(0.45)
============================================================================
GUIDE learning . . .
w1 ( -2.0280101941767317 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.5592330178962623) - present_state_Q ( -1.7651241967981415)) * f1( 0.5202551013424123)
w2 ( -2.072589757693493 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.5592330178962623) - present_state_Q (-1.7651241967981415)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -2.0455013886735203 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.5810746386685697) - present_state_Q ( -1.788333614437919)) * f1( 0.47302410713470183)
w2 ( -2.0873807116706504 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.5810746386685697) - present_state_Q (-1.788333614437919)) * f2(0.4)
============================================================================
GUIDE learning . . .
w1 ( -2.0651343240495024 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.690388439260527) - present_state_Q ( -1.7102136498348566)) * f1( 0.4278957570076212)
w2 ( -2.105733719434298 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.690388439260527) - present_state_Q (-1.7102136498348566)) * f2(0.4)
============================================================================
GUIDE learning . . .
w1 ( -2.091697054921359 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1380072689471479) - present_state_Q ( -1.3485806408905776)) * f1( 0.34712537422486067)
w2 ( -2.1286903220144224 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.1380072689471479) - present_state_Q (-1.3485806408905776)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.1217609827891017 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.8043015642938126) - present_state_Q ( -1.0171705964952549)) * f1( 0.2827524811496215)
w2 ( -2.149955513213105 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.8043015642938126) - present_state_Q (-1.0171705964952549)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.1487896205613803 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.9188970570883216) - present_state_Q ( -0.9188970570883216)) * f1( 0.23042461352221813)
w2 ( -2.1734153661855156 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.9188970570883216) - present_state_Q (-0.9188970570883216)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.169119091805927 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.9737582309940895) - present_state_Q ( -1.0824289993033653)) * f1( 0.20030085092055946)
w2 ( -2.203863770899397 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.9737582309940895) - present_state_Q (-1.0824289993033653)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.1807274708182613 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.7439993909852723) - present_state_Q ( -0.7439993909852723)) * f1( 0.13979252589259072)
w2 ( -2.220471781861662 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -0.7439993909852723) - present_state_Q (-0.7439993909852723)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.138891473629185 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.376417875932729) - present_state_Q ( -1.4073457888914092)) * f1( 0.5435335806819045)
w2 ( -2.2127747418486807 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.376417875932729) - present_state_Q (-1.4073457888914092)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.1809878769608773 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2442119766024855) - present_state_Q ( -1.2442119766024855)) * f1( 0.47825451409273384)
w2 ( -2.2215768340592583 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.2442119766024855) - present_state_Q (-1.2442119766024855)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.19510309341241 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.3200330567494614) - present_state_Q ( -1.3200330567494614)) * f1( 0.45245392790336625)
w2 ( -2.2262563877931405 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -1.3200330567494614) - present_state_Q (-1.3200330567494614)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.230927063158162 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1452043078071394) - present_state_Q ( -1.1452043078071394)) * f1( 0.36957983981381504)
w2 ( -2.240796129637744 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.1452043078071394) - present_state_Q (-1.1452043078071394)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.2639451558514 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0129174213516938) - present_state_Q ( -1.0129174213516938)) * f1( 0.30337074352755317)
w2 ( -2.2571217444494964 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.0129174213516938) - present_state_Q (-1.0129174213516938)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.29361595610639 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.905334343740859) - present_state_Q ( -0.905334343740859)) * f1( 0.2503444399298141)
w2 ( -2.2748997308089947 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.905334343740859) - present_state_Q (-0.905334343740859)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.318812582510389 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.6310440957946821) - present_state_Q ( -0.6310440957946821)) * f1( 0.17594668437816868)
w2 ( -2.2892203339468424 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.6310440957946821) - present_state_Q (-0.6310440957946821)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.2891885718462053 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1749832593839313) - present_state_Q ( -1.3205062109587458)) * f1( 0.4213894508925201)
w2 ( -2.2786752156715373 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.1749832593839313) - present_state_Q (-1.3205062109587458)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.271935543568536 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0702090987557211) - present_state_Q ( -1.0738691349590745)) * f1( 0.3695639685592305)
w2 ( -2.2740067334207024 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.0702090987557211) - present_state_Q (-1.0738691349590745)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.2880605744953373 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.03843685840627) - present_state_Q ( -1.1521371950773052)) * f1( 0.35698027937460886)
w2 ( -2.280782330782152 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -1.03843685840627) - present_state_Q (-1.1521371950773052)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.2251456473584112 ) += alpha ( 0.1 ) * (reward ( 0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1343310725754736) - present_state_Q ( -1.1592946485477489)) * f1( 0.4069894065959884)
w2 ( -2.26532371536925 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.1343310725754736) - present_state_Q (-1.1592946485477489)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.1290463309490786 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2379685554283502) - present_state_Q ( -1.2379685554283502)) * f1( 0.4545483056770485)
w2 ( -2.244181998370395 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.2379685554283502) - present_state_Q (-1.2379685554283502)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.0303955158675095 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.3032246712249578) - present_state_Q ( -1.3032246712249578)) * f1( 0.4540048553281188)
w2 ( -2.211588465308858 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.3032246712249578) - present_state_Q (-1.3032246712249578)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -1.9454350920935255 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1702209318232617) - present_state_Q ( -1.171417320612211)) * f1( 0.41355442535890347)
w2 ( -2.18077253689741 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.1702209318232617) - present_state_Q (-1.171417320612211)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -1.8580062803072237 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.098933758955428) - present_state_Q ( -1.2361073064231223)) * f1( 0.411194802794882)
w2 ( -2.138248258286858 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.098933758955428) - present_state_Q (-1.2361073064231223)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -1.8914362200787396 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2145733526397522) - present_state_Q ( -1.2362013692572864)) * f1( 0.37763021154565474)
w2 ( -2.160379657437025 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.2145733526397522) - present_state_Q (-1.2362013692572864)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -1.8437824927252038 ) += alpha ( 0.1 ) * (reward ( 0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.108135934858673) - present_state_Q ( -1.1324456458995233)) * f1( 0.3131751022065168)
w2 ( -2.122338856126684 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.108135934858673) - present_state_Q (-1.1324456458995233)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -1.8708809420713122 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.9760814262964544) - present_state_Q ( -0.9760814262964544)) * f1( 0.24162107733560093)
w2 ( -2.1503770240350137 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.9760814262964544) - present_state_Q (-0.9760814262964544)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -1.8926288667003388 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.748871218386657) - present_state_Q ( -0.877358931731365)) * f1( 0.18160678645133196)
w2 ( -2.180315228787696 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.748871218386657) - present_state_Q (-0.877358931731365)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -1.903537726503795 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.42225927703327604) - present_state_Q ( -0.5312750384726609)) * f1( 0.10790692129226727)
w2 ( -2.195479492126156 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -0.42225927703327604) - present_state_Q (-0.5312750384726609)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.268459585080396 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.503485452942099) - present_state_Q ( -1.5405402426945363)) * f1( 0.5656421822068388)
w2 ( -2.280318416972839 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.503485452942099) - present_state_Q (-1.5405402426945363)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.157452472119993 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.3602017636457329) - present_state_Q ( -1.3602017636457329)) * f1( 0.49909195182259497)
w2 ( -2.2580766011000275 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.3602017636457329) - present_state_Q (-1.3602017636457329)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.059396697031689 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.3096950690366544) - present_state_Q ( -1.3096950690366544)) * f1( 0.45006024068633393)
w2 ( -2.225395717668033 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.3096950690366544) - present_state_Q (-1.3096950690366544)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.078266721654968 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.111322427376038) - present_state_Q ( -1.111322427376038)) * f1( 0.3775440986413649)
w2 ( -2.232892864898456 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -1.111322427376038) - present_state_Q (-1.111322427376038)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.1205244283766875 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0706883635278122) - present_state_Q ( -1.0706883635278122)) * f1( 0.40774317762407547)
w2 ( -2.243256669626706 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.0706883635278122) - present_state_Q (-1.0706883635278122)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.14225206120826 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.035794677751166) - present_state_Q ( -1.035794677751166)) * f1( 0.3826737385947939)
w2 ( -2.248934517526945 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -1.035794677751166) - present_state_Q (-1.035794677751166)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.173606442176014 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0672961140328856) - present_state_Q ( -1.157118207292549)) * f1( 0.3301811755000555)
w2 ( -2.26792674560916 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.0672961140328856) - present_state_Q (-1.157118207292549)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.1703580501559725 ) += alpha ( 0.1 ) * (reward ( -1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2295226679920979) - present_state_Q ( -1.2295226679920979)) * f1( 0.3048118411567336)
w2 ( -2.2652624855793375 ) += alpha ( 0.1) * (reward ( -1) + discount_factor ( 0.1) * next_state_max_Q( -1.2295226679920979) - present_state_Q (-1.2295226679920979)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.1825924070734644 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1712181992891801) - present_state_Q ( -1.1942812210009923)) * f1( 0.2893373282629699)
w2 ( -2.275833500552536 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -1.1712181992891801) - present_state_Q (-1.1942812210009923)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.1539830497447725 ) += alpha ( 0.1 ) * (reward ( 0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0116587147669132) - present_state_Q ( -1.0116587147669132)) * f1( 0.20283234661407773)
w2 ( -2.2405711794702805 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.0116587147669132) - present_state_Q (-1.0116587147669132)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.127857484026388 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.8749676474890875) - present_state_Q ( -0.8749676474890875)) * f1( 0.1461593918572485)
w2 ( -2.195884407401776 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.8749676474890875) - present_state_Q (-0.8749676474890875)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.097066349911889 ) += alpha ( 0.1 ) * (reward ( 0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.6195242871284032) - present_state_Q ( -0.6195242871284032)) * f1( 0.2911493329694821)
w2 ( -2.195884407401776 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( -0.6195242871284032) - present_state_Q (-0.6195242871284032)) * f2(0.0)
============================================================================
GUIDE learning . . .
w1 ( -2.0617020482487423 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.310736542324638) - present_state_Q ( -1.310736542324638)) * f1( 0.520321210452071)
w2 ( -2.1890877785208542 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.310736542324638) - present_state_Q (-1.310736542324638)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.100800028285152 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.8924382974766889) - present_state_Q ( -0.8924382974766889)) * f1( 0.32668615729257056)
w2 ( -2.201055833843564 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.8924382974766889) - present_state_Q (-0.8924382974766889)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.0421843607575862 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.573421406754611) - present_state_Q ( -1.615427691061003)) * f1( 0.6117999327302048)
w2 ( -2.186684550587781 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.573421406754611) - present_state_Q (-1.615427691061003)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.007656985902012 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.288129057889005) - present_state_Q ( -1.288129057889005)) * f1( 0.5236846503091869)
w2 ( -2.18009138906678 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.288129057889005) - present_state_Q (-1.288129057889005)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -1.9514808199683549 ) += alpha ( 0.1 ) * (reward ( 0 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2948216065349998) - present_state_Q ( -1.2948216065349998)) * f1( 0.48205839193200645)
w2 ( -2.162611297378558 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( -1.2948216065349998) - present_state_Q (-1.2948216065349998)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -1.9883949079262977 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.3088281827457824) - present_state_Q ( -1.3088281827457824)) * f1( 0.44904664924366555)
w2 ( -2.179052390089134 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.3088281827457824) - present_state_Q (-1.3088281827457824)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.024311358928637 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.3946260896045337) - present_state_Q ( -1.3946260896045337)) * f1( 0.48220582730553163)
w2 ( -2.1939491204762525 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.3946260896045337) - present_state_Q (-1.3946260896045337)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.0578382543653504 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.506022896944845) - present_state_Q ( -1.5268312044355203)) * f1( 0.5374871684344614)
w2 ( -2.206424542181432 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.506022896944845) - present_state_Q (-1.5268312044355203)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.087577066220195 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.618334719582223) - present_state_Q ( -1.6594630782965778)) * f1( 0.5919698340120443)
w2 ( -2.216471950054665 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.618334719582223) - present_state_Q (-1.6594630782965778)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.1122721798763213 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.751544480503939) - present_state_Q ( -1.7932753316378076)) * f1( 0.6466735832038885)
w2 ( -2.2241095323829168 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.751544480503939) - present_state_Q (-1.7932753316378076)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.1294070700187846 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.929403189648313) - present_state_Q ( -1.929403189648313)) * f1( 0.6501888438605475)
w2 ( -2.2306979606158297 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.929403189648313) - present_state_Q (-1.929403189648313)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.1423095547072473 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.964263687594603) - present_state_Q ( -2.0068365111892703)) * f1( 0.680547200879975)
w2 ( -2.2354377070550844 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.964263687594603) - present_state_Q (-2.0068365111892703)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.1575834905954863 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.934572625789274) - present_state_Q ( -1.934572625789274)) * f1( 0.58999004644101)
w2 ( -2.243204246158774 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.934572625789274) - present_state_Q (-1.934572625789274)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.1716733318967303 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.9105672036713361) - present_state_Q ( -1.953692192561351)) * f1( 0.5935950679527313)
w2 ( -2.250325181992947 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.9105672036713361) - present_state_Q (-1.953692192561351)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.185708616377 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.924272361886791) - present_state_Q ( -1.924272361886791)) * f1( 0.523402176328475)
w2 ( -2.259710602593513 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.924272361886791) - present_state_Q (-1.924272361886791)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -2.203168145669847 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.6687419684213085) - present_state_Q ( -1.7817274985509841)) * f1( 0.4533215361916075)
w2 ( -2.273190737033703 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.6687419684213085) - present_state_Q (-1.7817274985509841)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -2.2345314675301085 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.171509953471312) - present_state_Q ( -1.2851694903229973)) * f1( 0.37697138302793654)
w2 ( -2.2898303671341855 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.171509953471312) - present_state_Q (-1.2851694903229973)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.270607365607161 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.9132668829991465) - present_state_Q ( -0.9132668829991465)) * f1( 0.3062314656244633)
w2 ( -2.3016109651871934 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.9132668829991465) - present_state_Q (-0.9132668829991465)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.3006005872014046 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.798539289618774) - present_state_Q ( -0.9457301611243009)) * f1( 0.26446162618945396)
w2 ( -2.318622821704757 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.798539289618774) - present_state_Q (-0.9457301611243009)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.318635078942367 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.3257685450388035) - present_state_Q ( -1.3257685450388035)) * f1( 0.22352882995118475)
w2 ( -2.346861112536035 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.3257685450388035) - present_state_Q (-1.3257685450388035)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -2.283196238982247 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2140594941850147) - present_state_Q ( -1.2140594941850147)) * f1( 0.16934881575953356)
w2 ( -2.273618238469207 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.2140594941850147) - present_state_Q (-1.2140594941850147)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -2.2942983989634413 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.40768492094877123) - present_state_Q ( -0.635046744795692)) * f1( 0.07897836113387738)
w2 ( -2.3017326734151906 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.40768492094877123) - present_state_Q (-0.635046744795692)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.265274785666407 ) += alpha ( 0.1 ) * (reward ( 0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.6641338111738248) - present_state_Q ( -0.7792204448445843)) * f1( 0.23930940184202867)
w2 ( -2.2896046027779184 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( -0.6641338111738248) - present_state_Q (-0.7792204448445843)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.247411538677807 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.4981778674375306) - present_state_Q ( -1.4981778674375306)) * f1( 0.5526764089051769)
w2 ( -2.293249072608253 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.4981778674375306) - present_state_Q (-1.4981778674375306)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.327340262474661 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0876876267134896) - present_state_Q ( -1.0876876267134896)) * f1( 0.3235968460060113)
w2 ( -2.3170488904545583 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.0876876267134896) - present_state_Q (-1.0876876267134896)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.3441360900831296 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.9809699947011774) - present_state_Q ( -0.9809699947011774)) * f1( 0.2721616049642376)
w2 ( -2.3263057955260926 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -0.9809699947011774) - present_state_Q (-0.9809699947011774)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.371593635112482 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.8829265628012275) - present_state_Q ( -0.8829265628012275)) * f1( 0.22779423760050427)
w2 ( -2.344386286928276 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.8829265628012275) - present_state_Q (-0.8829265628012275)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.3990964828014234 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.8996107262120452) - present_state_Q ( -0.8996107262120452)) * f1( 0.23104834448032033)
w2 ( -2.3622415421244134 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.8996107262120452) - present_state_Q (-0.8996107262120452)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.2405084978372862 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.5005573530986878) - present_state_Q ( -1.5252210981859036)) * f1( 0.614625571439286)
w2 ( -2.2973568466008105 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.5005573530986878) - present_state_Q (-1.5252210981859036)) * f2(0.05)
============================================================================
GUIDE learning . . .
w1 ( -2.1737710389766165 ) += alpha ( 0.1 ) * (reward ( 0 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.3200685779012102) - present_state_Q ( -1.346274981749876)) * f1( 0.5496105641234952)
w2 ( -2.2912855059810115 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( -1.3200685779012102) - present_state_Q (-1.346274981749876)) * f2(0.05)
============================================================================
GUIDE learning . . .
w1 ( -2.1809822613099468 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.3892383245240871) - present_state_Q ( -1.5038025998231377)) * f1( 0.5336853574386339)
w2 ( -2.2933123244704507 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -1.3892383245240871) - present_state_Q (-1.5038025998231377)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.0741282021368663 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.3824394053133968) - present_state_Q ( -1.3824394053133968)) * f1( 0.4761352602744771)
w2 ( -2.2596493924987198 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.3824394053133968) - present_state_Q (-1.3824394053133968)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -1.9838191607669524 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2285133789263392) - present_state_Q ( -1.2285133789263392)) * f1( 0.4288866855650762)
w2 ( -2.228064461883214 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.2285133789263392) - present_state_Q (-1.2285133789263392)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -1.877333704133183 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2829354205014107) - present_state_Q ( -1.3047945248809942)) * f1( 0.4892506710255183)
w2 ( -2.1954169471407514 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.2829354205014107) - present_state_Q (-1.3047945248809942)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -1.8246076478705608 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.8558222711441597) - present_state_Q ( -0.9655931185011971)) * f1( 0.28045612131389874)
w2 ( -2.1578167293130157 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.8558222711441597) - present_state_Q (-0.9655931185011971)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -1.8540297023750851 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.7210079356933734) - present_state_Q ( -0.7210079356933734)) * f1( 0.21776485852185157)
w2 ( -2.178083122181155 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.7210079356933734) - present_state_Q (-0.7210079356933734)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -1.879270899163213 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.6234927333278508) - present_state_Q ( -0.6605556897253831)) * f1( 0.18006357771428555)
w2 ( -2.199110025935266 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.6234927333278508) - present_state_Q (-0.6605556897253831)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -1.9020290536172644 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.45835012280728005) - present_state_Q ( -0.4958390613664009)) * f1( 0.1468271864879818)
w2 ( -2.2146099854444095 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.45835012280728005) - present_state_Q (-0.4958390613664009)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.3324667859403854 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.059463436806716) - present_state_Q ( -1.105334474443705)) * f1( 0.38145047196022186)
w2 ( -2.31173879210756 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.059463436806716) - present_state_Q (-1.105334474443705)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.368186804772634 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.9710855765531607) - present_state_Q ( -0.9710855765531607)) * f1( 0.3172228225509728)
w2 ( -2.3229990219185814 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.9710855765531607) - present_state_Q (-0.9710855765531607)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.3997673550016128 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0484042665516142) - present_state_Q ( -1.073869035307902)) * f1( 0.30631839538932026)
w2 ( -2.3384635927887905 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.0484042665516142) - present_state_Q (-1.073869035307902)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.423702345922141 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1146789208669097) - present_state_Q ( -1.2561987991703805)) * f1( 0.2798533364384113)
w2 ( -2.359845320111698 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.1146789208669097) - present_state_Q (-1.2561987991703805)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.446817772802166 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.8593440098819136) - present_state_Q ( -0.9773362758874985)) * f1( 0.20851042732843617)
w2 ( -2.382017282613712 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.8593440098819136) - present_state_Q (-0.9773362758874985)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.4650387344615097 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.7185287523122549) - present_state_Q ( -0.8376296164429404)) * f1( 0.14763100216756703)
w2 ( -2.4067017477894774 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.7185287523122549) - present_state_Q (-0.8376296164429404)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.4947960033064036 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.3286275133944199) - present_state_Q ( -1.4735207167313227)) * f1( 0.4513176361124934)
w2 ( -2.416591878308599 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.3286275133944199) - present_state_Q (-1.4735207167313227)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.5216420215011595 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.4612885679440006) - present_state_Q ( -1.4612885679440006)) * f1( 0.3920040720708856)
w2 ( -2.4302886840856073 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.4612885679440006) - present_state_Q (-1.4612885679440006)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.548043903699518 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.4344339306035367) - present_state_Q ( -1.4595637114384918)) * f1( 0.38606033938228557)
w2 ( -2.4439662777180446 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.4344339306035367) - present_state_Q (-1.4595637114384918)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.5677669327253554 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.5996848559832615) - present_state_Q ( -1.6973789422094145)) * f1( 0.42636132415244965)
w2 ( -2.4555310163027673 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.5996848559832615) - present_state_Q (-1.6973789422094145)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.5862428500393646 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.7638230764693965) - present_state_Q ( -1.7638230764693965)) * f1( 0.4478367205909885)
w2 ( -2.465844997082206 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.7638230764693965) - present_state_Q (-1.7638230764693965)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.6077255680238567 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.5845355953957254) - present_state_Q ( -1.5845355953957254)) * f1( 0.37431687674281594)
w2 ( -2.480192946185802 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.5845355953957254) - present_state_Q (-1.5845355953957254)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.633206098059899 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2776684943240562) - present_state_Q ( -1.2776684943240562)) * f1( 0.2997362585508634)
w2 ( -2.4971949132879687 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.2776684943240562) - present_state_Q (-1.2776684943240562)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.6541273320656855 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.150120428128436) - present_state_Q ( -1.30141070174286)) * f1( 0.25714355360172997)
w2 ( -2.517534946814718 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.150120428128436) - present_state_Q (-1.30141070174286)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.6756175662333366 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.7153642331331831) - present_state_Q ( -0.8412409804739192)) * f1( 0.17467539437562962)
w2 ( -2.5359893784573093 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.7153642331331831) - present_state_Q (-0.8412409804739192)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.6743369841970166 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.6582845270340851) - present_state_Q ( -0.6801389194652925)) * f1( 0.1120266649761396)
w2 ( -2.534274721455881 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -0.6582845270340851) - present_state_Q (-0.6801389194652925)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.6597656762994375 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.38406054948205814) - present_state_Q ( -0.4106838466101369)) * f1( 0.10618336889305904)
w2 ( -2.5274133324975714 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.38406054948205814) - present_state_Q (-0.4106838466101369)) * f2(0.05)
============================================================================
GUIDE learning . . .
w1 ( -2.651349918150673 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.3023314726243151) - present_state_Q ( -0.3023314726243151)) * f1( 0.06615650678079762)
w2 ( -2.521052840870762 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.3023314726243151) - present_state_Q (-0.3023314726243151)) * f2(0.05)
============================================================================
GUIDE learning . . .
w1 ( -2.6840886722985027 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1904212128014982) - present_state_Q ( -1.2434041204158777)) * f1( 0.3738845746246261)
w2 ( -2.5298092208794047 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.1904212128014982) - present_state_Q (-1.2434041204158777)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.71544127474085 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0520142418315408) - present_state_Q ( -1.0520142418315408)) * f1( 0.2976925941345123)
w2 ( -2.540341092702921 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.0520142418315408) - present_state_Q (-1.0520142418315408)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.7386791258642744 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0847418875744796) - present_state_Q ( -1.2117589422096258)) * f1( 0.25914415097641863)
w2 ( -2.5582753976338775 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.0847418875744796) - present_state_Q (-1.2117589422096258)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.7577256097682237 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0632143135582344) - present_state_Q ( -1.245592459712468)) * f1( 0.22128317427940716)
w2 ( -2.5797936219249613 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.0632143135582344) - present_state_Q (-1.245592459712468)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.6641889675896664 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-2.0219756505770263) - present_state_Q ( -2.047042597281879)) * f1( 0.6955198549818146)
w2 ( -2.5730693967638403 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -2.0219756505770263) - present_state_Q (-2.047042597281879)) * f2(0.05)
============================================================================
GUIDE learning . . .
w1 ( -2.6797517432355153 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.9797077248117583) - present_state_Q ( -1.9535329779599961)) * f1( 0.6366763239839607)
w2 ( -2.575513774709052 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.9797077248117583) - present_state_Q (-1.9535329779599961)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.6107697536023604 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.8939560165280795) - present_state_Q ( -1.9058922926463184)) * f1( 0.5670544781902995)
w2 ( -2.557266324344149 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.8939560165280795) - present_state_Q (-1.9058922926463184)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.488849225011519 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.5275842596579516) - present_state_Q ( -1.6554475758751592)) * f1( 0.4871580979014398)
w2 ( -2.5197259870955087 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.5275842596579516) - present_state_Q (-1.6554475758751592)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.3938999908975083 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1980711143149332) - present_state_Q ( -1.3240574136697087)) * f1( 0.4307552278323313)
w2 ( -2.4976834840731263 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.1980711143149332) - present_state_Q (-1.3240574136697087)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.425939191300542 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.3172261315325313) - present_state_Q ( -1.3227390613074883)) * f1( 0.39604266773946045)
w2 ( -2.509818237350813 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.3172261315325313) - present_state_Q (-1.3227390613074883)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.4566876650876845 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.4142675906320392) - present_state_Q ( -1.4401303199762243)) * f1( 0.43845187389193263)
w2 ( -2.5203376839371177 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.4142675906320392) - present_state_Q (-1.4401303199762243)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.4792373191683117 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.5625528371387363) - present_state_Q ( -1.688569721335592)) * f1( 0.48215416285158536)
w2 ( -2.5296913951846833 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.5625528371387363) - present_state_Q (-1.688569721335592)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.5033776548839013 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.6991487413647315) - present_state_Q ( -1.7251746730510606)) * f1( 0.5427963484450917)
w2 ( -2.5363624982009645 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.6991487413647315) - present_state_Q (-1.7251746730510606)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.5156016944449826 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.8499272117759085) - present_state_Q ( -1.9767453366859566)) * f1( 0.5869960667656088)
w2 ( -2.540527445890797 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.8499272117759085) - present_state_Q (-1.9767453366859566)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.342951023413354 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-2.0397034891273345) - present_state_Q ( -2.0397034891273345)) * f1( 0.6088396280425831)
w2 ( -2.4838127830865053 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -2.0397034891273345) - present_state_Q (-2.0397034891273345)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.3638939411464035 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.77636366007237) - present_state_Q ( -1.801582800175925)) * f1( 0.5569131537618239)
w2 ( -2.4913338544031314 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.77636366007237) - present_state_Q (-1.801582800175925)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.364839287669548 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.6450141311191269) - present_state_Q ( -1.6450141311191269)) * f1( 0.485109479862015)
w2 ( -2.491723600042987 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -1.6450141311191269) - present_state_Q (-1.6450141311191269)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.3924149138612285 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.4957879917118189) - present_state_Q ( -1.4957879917118189)) * f1( 0.42178057380218875)
w2 ( -2.5047994161921743 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.4957879917118189) - present_state_Q (-1.4957879917118189)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.4201421049651777 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.4218493278208828) - present_state_Q ( -1.4218493278208828)) * f1( 0.3849204580890118)
w2 ( -2.5192061282913984 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.4218493278208828) - present_state_Q (-1.4218493278208828)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.4473910819861207 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2816899583612011) - present_state_Q ( -1.303913370318117)) * f1( 0.33058891170828547)
w2 ( -2.5356912408017585 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.2816899583612011) - present_state_Q (-1.303913370318117)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.4729074157811586 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1609485057601612) - present_state_Q ( -1.1609485057601612)) * f1( 0.26714580371406177)
w2 ( -2.5547941676980757 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.1609485057601612) - present_state_Q (-1.1609485057601612)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.494574662883092 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.878673145535364) - present_state_Q ( -1.0064128539202677)) * f1( 0.20035283861371142)
w2 ( -2.576423256910741 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.878673145535364) - present_state_Q (-1.0064128539202677)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.5142338799820982 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.8933740663779559) - present_state_Q ( -0.9431499642925062)) * f1( 0.17151834309735786)
w2 ( -2.5993470057576467 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.8933740663779559) - present_state_Q (-0.9431499642925062)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.5345150040545836 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0190659720945403) - present_state_Q ( -1.044084087071825)) * f1( 0.36357665214122853)
w2 ( -2.602136118308335 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -1.0190659720945403) - present_state_Q (-1.044084087071825)) * f2(0.05)
============================================================================
GUIDE learning . . .
w1 ( -2.546565617457059 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2890780099337016) - present_state_Q ( -1.2890780099337016)) * f1( 0.3546073275359058)
w2 ( -2.60723356517423 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -1.2890780099337016) - present_state_Q (-1.2890780099337016)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.576084792272482 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2517384573087946) - present_state_Q ( -1.2517384573087946)) * f1( 0.33796632477591076)
w2 ( -2.620335096000561 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.2517384573087946) - present_state_Q (-1.2517384573087946)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.6032846742661078 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0669687964407646) - present_state_Q ( -1.0669687964407646)) * f1( 0.26160572589157133)
w2 ( -2.635931017248611 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.0669687964407646) - present_state_Q (-1.0669687964407646)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.605351868718728 ) += alpha ( 0.1 ) * (reward ( -1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.9557250400326995) - present_state_Q ( -1.0076814787181563)) * f1( 0.23519971987061916)
w2 ( -2.6372493826278873 ) += alpha ( 0.1) * (reward ( -1) + discount_factor ( 0.1) * next_state_max_Q( -0.9557250400326995) - present_state_Q (-1.0076814787181563)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.5961469785470075 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.9693637988958796) - present_state_Q ( -0.9962170219120692)) * f1( 0.23053685059948023)
w2 ( -2.63126017299755 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -0.9693637988958796) - present_state_Q (-0.9962170219120692)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.592300069254717 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.8178142133585453) - present_state_Q ( -0.8178142133585453)) * f1( 0.16298198480492979)
w2 ( -2.6277196811172097 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -0.8178142133585453) - present_state_Q (-0.8178142133585453)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.600532607640733 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2512531933672135) - present_state_Q ( -1.2857289826449525)) * f1( 0.24256414981558405)
w2 ( -2.636204589534504 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -1.2512531933672135) - present_state_Q (-1.2857289826449525)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.6048946361173884 ) += alpha ( 0.1 ) * (reward ( -1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.7980999860252083) - present_state_Q ( -0.7980999860252083)) * f1( 0.15484108771100702)
w2 ( -2.640430239723164 ) += alpha ( 0.1) * (reward ( -1) + discount_factor ( 0.1) * next_state_max_Q( -0.7980999860252083) - present_state_Q (-0.7980999860252083)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.591609064965431 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.5671091960195402) - present_state_Q ( -0.5953216694010207)) * f1( 0.17896681439295767)
w2 ( -2.6275266273682143 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -0.5671091960195402) - present_state_Q (-0.5953216694010207)) * f2(0.05)
============================================================================
GUIDE learning . . .
w1 ( -2.5685206751304954 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.5352126552300536) - present_state_Q ( -0.5352126552300536)) * f1( 0.1558245529084185)
w2 ( -2.620118170419679 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.5352126552300536) - present_state_Q (-0.5352126552300536)) * f2(0.05)
============================================================================
GUIDE learning . . .
w1 ( -2.5548177500674902 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.3913003792564711) - present_state_Q ( -0.3913003792564711)) * f1( 0.10134022795913943)
w2 ( -2.613357318713025 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.3913003792564711) - present_state_Q (-0.3913003792564711)) * f2(0.05)
============================================================================
GUIDE learning . . .
w1 ( -2.4988385101168964 ) += alpha ( 0.1 ) * (reward ( 0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1694775198863598) - present_state_Q ( -1.1776798018074037)) * f1( 0.35867296988675385)
w2 ( -2.5977499982148373 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.1694775198863598) - present_state_Q (-1.1776798018074037)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.474764776240854 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2045243208746346) - present_state_Q ( -1.2364087526425749)) * f1( 0.3908350815256981)
w2 ( -2.591590435009286 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.2045243208746346) - present_state_Q (-1.2364087526425749)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.5010287372859588 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.308323609239179) - present_state_Q ( -1.333481070959229)) * f1( 0.3293900865986938)
w2 ( -2.60753746080858 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.308323609239179) - present_state_Q (-1.333481070959229)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.522400606010137 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.4055520269944564) - present_state_Q ( -1.5359289000348855)) * f1( 0.3534723618538182)
w2 ( -2.6226531183751938 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.4055520269944564) - present_state_Q (-1.5359289000348855)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.54171410868908 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.5472514330811356) - present_state_Q ( -1.6783840889998953)) * f1( 0.4054553455820042)
w2 ( -2.634561644732899 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.5472514330811356) - present_state_Q (-1.6783840889998953)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.5529217897327436 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.8134648864011393) - present_state_Q ( -1.9317697418743345)) * f1( 0.44906751886550916)
w2 ( -2.642048947135873 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.8134648864011393) - present_state_Q (-1.9317697418743345)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.566736278972639 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.8525060096488926) - present_state_Q ( -1.8525060096488926)) * f1( 0.4151679576596379)
w2 ( -2.6520312848753527 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.8525060096488926) - present_state_Q (-1.8525060096488926)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.582595874536519 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.7138800209392595) - present_state_Q ( -1.7406323311315717)) * f1( 0.36818077237261804)
w2 ( -2.6649539550042234 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.7138800209392595) - present_state_Q (-1.7406323311315717)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.5997601157801005 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.4252546326761477) - present_state_Q ( -1.558502330426359)) * f1( 0.2938965989254154)
w2 ( -2.682474648989461 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.4252546326761477) - present_state_Q (-1.558502330426359)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.6136831349597855 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.4312167096173252) - present_state_Q ( -1.5653404420667982)) * f1( 0.2409738925979726)
w2 ( -2.7026969920007837 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.4312167096173252) - present_state_Q (-1.5653404420667982)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -2.630798466816193 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.5477679426119213) - present_state_Q ( -1.5477679426119213)) * f1( 0.2819618167001047)
w2 ( -2.720907257550262 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.5477679426119213) - present_state_Q (-1.5477679426119213)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.6282124277421435 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.7338888227181573) - present_state_Q ( -1.7578469711874662)) * f1( 0.3061919950180489)
w2 ( -2.717951224438214 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -1.7338888227181573) - present_state_Q (-1.7578469711874662)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -2.6417447760765835 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.6019555520013964) - present_state_Q ( -1.6542713382991234)) * f1( 0.26747777399016215)
w2 ( -2.7356585720297497 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.6019555520013964) - present_state_Q (-1.6542713382991234)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -2.6548764053731246 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.4696687025055857) - present_state_Q ( -1.4696687025055857)) * f1( 0.19388254570748317)
w2 ( -2.7593640079008237 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.4696687025055857) - present_state_Q (-1.4696687025055857)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -2.6659098013311984 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.204191377610473) - present_state_Q ( -1.342159578005514)) * f1( 0.14177013079722925)
w2 ( -2.7866030924922676 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.204191377610473) - present_state_Q (-1.342159578005514)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -2.676269687871536 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2630194207095276) - present_state_Q ( -1.316264918699699)) * f1( 0.1278939880700964)
w2 ( -2.8149543883102615 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.2630194207095276) - present_state_Q (-1.316264918699699)) * f2(0.35000000000000003)
============================================================================
GUIDE learning . . .
w1 ( -2.6782372712740923 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.6079455698313709) - present_state_Q ( -0.8894410086623972)) * f1( 0.01679751946264858)
w2 ( -2.8500949947598837 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.6079455698313709) - present_state_Q (-0.8894410086623972)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.5133404717431973 ) += alpha ( 0.1 ) * (reward ( 0 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0508217320924702) - present_state_Q ( -1.2155716129085061)) * f1( 0.3735044822715811)
w2 ( -2.6022524243160325 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( -1.0508217320924702) - present_state_Q (-1.2155716129085061)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.5719221529441407 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.863307434109001) - present_state_Q ( -0.8800539683977859)) * f1( 0.24217705412064675)
w2 ( -2.620420086463156 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -0.863307434109001) - present_state_Q (-0.8800539683977859)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.5849456934496127 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.847261485059863) - present_state_Q ( -0.847261485059863)) * f1( 0.1765988412870342)
w2 ( -2.631482056414848 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -0.847261485059863) - present_state_Q (-0.847261485059863)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.602382482234556 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.7503951568987546) - present_state_Q ( -0.914766706569976)) * f1( 0.15028180138229227)
w2 ( -2.654687512597246 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.7503951568987546) - present_state_Q (-0.914766706569976)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.536297905923427 ) += alpha ( 0.1 ) * (reward ( 0 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.8674136743139689) - present_state_Q ( -0.8674136743139689)) * f1( 0.2372294236748025)
w2 ( -2.6055505956441993 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( -0.8674136743139689) - present_state_Q (-0.8674136743139689)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.521168033303941 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.131342751133424) - present_state_Q ( -1.131342751133424)) * f1( 0.2919649777959288)
w2 ( -2.597777468503898 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.131342751133424) - present_state_Q (-1.131342751133424)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.509057562676586 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1202856080778827) - present_state_Q ( -1.1202856080778827)) * f1( 0.23827452452261105)
w2 ( -2.5876123275584964 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.1202856080778827) - present_state_Q (-1.1202856080778827)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.499282369884069 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0063173419134372) - present_state_Q ( -1.0560599986136154)) * f1( 0.21463737664408972)
w2 ( -2.578503762270051 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.0063173419134372) - present_state_Q (-1.0560599986136154)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.4659366202170916 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0693156993383164) - present_state_Q ( -1.0693156993383164)) * f1( 0.16992468073565578)
w2 ( -2.529444159034939 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.0693156993383164) - present_state_Q (-1.0693156993383164)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.446778772624783 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.8941307287150417) - present_state_Q ( -0.8941307287150417)) * f1( 0.1061542647974715)
w2 ( -2.4843262176388503 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -0.8941307287150417) - present_state_Q (-0.8941307287150417)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.4708113996670007 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.6306436881805879) - present_state_Q ( -0.6306436881805879)) * f1( 0.25774446600420053)
w2 ( -2.4843262176388503 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -0.6306436881805879) - present_state_Q (-0.6306436881805879)) * f2(0.0)
============================================================================
GUIDE learning . . .
w1 ( -2.4156611129156613 ) += alpha ( 0.1 ) * (reward ( 0 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.3321045930116102) - present_state_Q ( -1.3595724159040796)) * f1( 0.44970643825342016)
w2 ( -2.4720625980728212 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( -1.3321045930116102) - present_state_Q (-1.3595724159040796)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.4274903777084953 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1983590278511544) - present_state_Q ( -1.3182186946076282)) * f1( 0.3921946252441007)
w2 ( -2.4765868561954836 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -1.1983590278511544) - present_state_Q (-1.3182186946076282)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.4264442976928073 ) += alpha ( 0.1 ) * (reward ( -1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1189829937203704) - present_state_Q ( -1.14034446954872)) * f1( 0.36774019461689894)
w2 ( -2.476302394493717 ) += alpha ( 0.1) * (reward ( -1) + discount_factor ( 0.1) * next_state_max_Q( -1.1189829937203704) - present_state_Q (-1.14034446954872)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.3736186960733665 ) += alpha ( 0.1 ) * (reward ( 0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2547448890813269) - present_state_Q ( -1.2731806250397075)) * f1( 0.3206008672363311)
w2 ( -2.4433482717710855 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.2547448890813269) - present_state_Q (-1.2731806250397075)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.322303869816598 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1005789394362853) - present_state_Q ( -1.1005789394362853)) * f1( 0.25779594932174166)
w2 ( -2.403537850861232 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.1005789394362853) - present_state_Q (-1.1005789394362853)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.278691068451942 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0160001823813003) - present_state_Q ( -1.106146713012234)) * f1( 0.21756939600536795)
w2 ( -2.3534241834918794 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.0160001823813003) - present_state_Q (-1.106146713012234)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.299062987073966 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.9865444786270197) - present_state_Q ( -1.0178716711253526)) * f1( 0.18849225820864768)
w2 ( -2.3804437529103133 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.9865444786270197) - present_state_Q (-1.0178716711253526)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.3128261829298027 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.8516298144294594) - present_state_Q ( -0.8516298144294594)) * f1( 0.11157540165019769)
w2 ( -2.4112820820856506 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.8516298144294594) - present_state_Q (-0.8516298144294594)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.2848574498536918 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1425654995764345) - present_state_Q ( -1.3552411115612606)) * f1( 0.3774536545752287)
w2 ( -2.3964623908535785 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.1425654995764345) - present_state_Q (-1.3552411115612606)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.3263815704350326 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.39435492817246004) - present_state_Q ( -0.39435492817246004)) * f1( 0.11837933437840514)
w2 ( -2.4170074849088747 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -0.39435492817246004) - present_state_Q (-0.39435492817246004)) * f2(0.05)
============================================================================
GUIDE learning . . .
w1 ( -2.2510668475926447 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.6911157969505823) - present_state_Q ( -1.848348765913236)) * f1( 0.6386732348894343)
w2 ( -2.399318927115602 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.6911157969505823) - present_state_Q (-1.848348765913236)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.1780270141220446 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.8422024487047797) - present_state_Q ( -1.868360742143736)) * f1( 0.616817291856754)
w2 ( -2.375636117170137 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.8422024487047797) - present_state_Q (-1.868360742143736)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.1106856554578752 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.8259409448152761) - present_state_Q ( -1.8501423340192868)) * f1( 0.5767758143409144)
w2 ( -2.3464474111816926 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.8259409448152761) - present_state_Q (-1.8501423340192868)) * f2(0.25)
============================================================================
GUIDE learning . . .
w1 ( -2.054546939373886 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.7795591155517663) - present_state_Q ( -1.7795591155517663)) * f1( 0.5096092302593115)
w2 ( -2.313399315061795 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.7795591155517663) - present_state_Q (-1.7795591155517663)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.0789715133523883 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.6202295501236867) - present_state_Q ( -1.6202295501236867)) * f1( 0.4508097322358604)
w2 ( -2.3296531172084554 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.6202295501236867) - present_state_Q (-1.6202295501236867)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.103020160115089 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2858302334472755) - present_state_Q ( -1.518795545168121)) * f1( 0.39437751058141135)
w2 ( -2.3479467415537534 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.2858302334472755) - present_state_Q (-1.518795545168121)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.134087877250385 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.047097026787628) - present_state_Q ( -1.1644943638653158)) * f1( 0.33043193248158687)
w2 ( -2.3667510483300225 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.047097026787628) - present_state_Q (-1.1644943638653158)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.1550113132227184 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1912664838798857) - present_state_Q ( -1.1912664838798857)) * f1( 0.22550203977585156)
w2 ( -2.3945868532652654 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.1912664838798857) - present_state_Q (-1.1912664838798857)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.137496777629041 ) += alpha ( 0.1 ) * (reward ( 0 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0757258236162444) - present_state_Q ( -1.0990577283477307)) * f1( 0.176649500646407)
w2 ( -2.3648422988856823 ) += alpha ( 0.1) * (reward ( 0) + discount_factor ( 0.1) * next_state_max_Q( -1.0757258236162444) - present_state_Q (-1.0990577283477307)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.139067293585256 ) += alpha ( 0.1 ) * (reward ( -1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.8063831978533273) - present_state_Q ( -0.9246253127976116)) * f1( 0.1006657064393711)
w2 ( -2.369522689095314 ) += alpha ( 0.1) * (reward ( -1) + discount_factor ( 0.1) * next_state_max_Q( -0.8063831978533273) - present_state_Q (-0.9246253127976116)) * f2(0.30000000000000004)
============================================================================
GUIDE learning . . .
w1 ( -2.2604968208610603 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.5567800624937058) - present_state_Q ( -1.7039084675298786)) * f1( 0.6285330564949234)
w2 ( -2.40652518029607 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.5567800624937058) - present_state_Q (-1.7039084675298786)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.287850318550425 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.6792860375315088) - present_state_Q ( -1.709360392301879)) * f1( 0.5964979038297642)
w2 ( -2.413403703467839 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.6792860375315088) - present_state_Q (-1.709360392301879)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.3190407474012775 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.5551297262369979) - present_state_Q ( -1.559714259023493)) * f1( 0.5235061462684231)
w2 ( -2.422340684171842 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.5551297262369979) - present_state_Q (-1.559714259023493)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.352169718436524 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.3938426223536053) - present_state_Q ( -1.3938426223536053)) * f1( 0.4443611096021492)
w2 ( -2.4335238087700684 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.3938426223536053) - present_state_Q (-1.3938426223536053)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.3434565353782926 ) += alpha ( 0.1 ) * (reward ( -1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.3420942240446971) - present_state_Q ( -1.3436380612242094)) * f1( 0.4160454418906371)
w2 ( -2.430382379187772 ) += alpha ( 0.1) * (reward ( -1) + discount_factor ( 0.1) * next_state_max_Q( -1.3420942240446971) - present_state_Q (-1.3436380612242094)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.26797945623882 ) += alpha ( 0.1 ) * (reward ( 1 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2109270817556965) - present_state_Q ( -1.2109270817556965)) * f1( 0.3611629710644091)
w2 ( -2.3990348635840704 ) += alpha ( 0.1) * (reward ( 1) + discount_factor ( 0.1) * next_state_max_Q( -1.2109270817556965) - present_state_Q (-1.2109270817556965)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.2849203443880546 ) += alpha ( 0.1 ) * (reward ( -1.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0075584322337123) - present_state_Q ( -1.0075584322337123)) * f1( 0.2855860095709341)
w2 ( -2.407932824748915 ) += alpha ( 0.1) * (reward ( -1.5) + discount_factor ( 0.1) * next_state_max_Q( -1.0075584322337123) - present_state_Q (-1.0075584322337123)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.3008294279588477 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0975342868589426) - present_state_Q ( -1.2183846611043865)) * f1( 0.4198296294235427)
w2 ( -2.4109211725846897 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.0975342868589426) - present_state_Q (-1.2183846611043865)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.2914941298402955 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.2100621256953945) - present_state_Q ( -1.3519962707384552)) * f1( 0.47726286021082204)
w2 ( -2.4096975843271857 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.2100621256953945) - present_state_Q (-1.3519962707384552)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.234177746455595 ) += alpha ( 0.1 ) * (reward ( 0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0368939084612963) - present_state_Q ( -1.0368939084612963)) * f1( 0.39991768571923225)
w2 ( -2.40253156173911 ) += alpha ( 0.1) * (reward ( 0.5) + discount_factor ( 0.1) * next_state_max_Q( -1.0368939084612963) - present_state_Q (-1.0368939084612963)) * f2(0.05)
============================================================================
GUIDE learning . . .
w1 ( -2.2753451082143616 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.9130424423253446) - present_state_Q ( -0.8784857637531097)) * f1( 0.3394354754760453)
w2 ( -2.4085956541415072 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.9130424423253446) - present_state_Q (-0.8784857637531097)) * f2(0.05)
============================================================================
GUIDE learning . . .
w1 ( -2.312466610606983 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.0242776253316195) - present_state_Q ( -1.0242776253316195)) * f1( 0.34430735675621404)
w2 ( -2.419377155513523 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.0242776253316195) - present_state_Q (-1.0242776253316195)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.29987013842315 ) += alpha ( 0.1 ) * (reward ( -0.5 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.9847251872916176) - present_state_Q ( -0.9885962499306835)) * f1( 0.32288402822964274)
w2 ( -2.4154759182015075 ) += alpha ( 0.1) * (reward ( -0.5) + discount_factor ( 0.1) * next_state_max_Q( -0.9847251872916176) - present_state_Q (-0.9885962499306835)) * f2(0.1)
============================================================================
GUIDE learning . . .
w1 ( -2.3302327370182394 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.9721948605227457) - present_state_Q ( -0.9970312812843249)) * f1( 0.2759764053414216)
w2 ( -2.431978741273027 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.9721948605227457) - present_state_Q (-0.9970312812843249)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.3547194777597267 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.8154828886004978) - present_state_Q ( -0.8154828886004978)) * f1( 0.19340818204547267)
w2 ( -2.4509697222769202 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.8154828886004978) - present_state_Q (-0.8154828886004978)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.3736219573266197 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.7583284777004489) - present_state_Q ( -0.8546883854198417)) * f1( 0.15479314814656248)
w2 ( -2.475392611523924 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.7583284777004489) - present_state_Q (-0.8546883854198417)) * f2(0.2)
============================================================================
GUIDE learning . . .
w1 ( -2.3872053926060715 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-0.5909141144903067) - present_state_Q ( -0.5909141144903067)) * f1( 0.09251903913505105)
w2 ( -2.497415270978305 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -0.5909141144903067) - present_state_Q (-0.5909141144903067)) * f2(0.15000000000000002)
============================================================================
GUIDE learning . . .
w1 ( -2.3641184555929184 ) += alpha ( 0.1 ) * (reward ( -2 ) + discount_factor ( 0.1 ) * next_state_max_Q(-1.1754213399518845) - present_state_Q ( -1.221945008240472)) * f1( 0.4213600521114338)
w2 ( -2.425963456166422 ) += alpha ( 0.1) * (reward ( -2) + discount_factor ( 0.1) * next_state_max_Q( -1.1754213399518845) - present_state_Q (-1.221945008240472)) * f2(0.1)
============================================================================
