NOT GUIDE learning . . .
w3 ( 0.9094405038232352 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.8315911196267426) - present_state_Q (0.8315911196267426)) * f3(0.6715911196267426)
w4 ( 0.9784250878773749 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.8315911196267426) - present_state_Q (0.8315911196267426)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8201937041181052 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.7799527977597518) - present_state_Q (0.7799527977597518)) * f3(0.6854816572151935)
w4 ( 0.9575937675896345 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.7799527977597518) - present_state_Q (0.7799527977597518)) * f4(0.16)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8207648459354152 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.17961381565523216) - present_state_Q (0.17961381565523216)) * f3(0.14893821908960145)
w4 ( 0.9578238529850963 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.17961381565523216) - present_state_Q (0.17961381565523216)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8217874880465055 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.08933926820243794) - present_state_Q (0.08933926820243794)) * f3(0.08550901210047511)
w4 ( 0.958063042302332 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.08933926820243794) - present_state_Q (0.08933926820243794)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8218494744246913 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11575465904998292) - present_state_Q (0.001643574976093011)) * f3(0.002)
w4 ( 0.958063042302332 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11575465904998292) - present_state_Q (0.001643574976093011)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8238212621505464 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09457523303162245) - present_state_Q (0.09457523303162245)) * f3(0.09176129514272294)
w4 ( 0.9584928068828751 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09457523303162245) - present_state_Q (0.09457523303162245)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8259367743157613 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10338057991855432) - present_state_Q (0.10338057991855432)) * f3(0.10221965327899973)
w4 ( 0.9589067218390217 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10338057991855432) - present_state_Q (0.10338057991855432)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8281566207315723 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11066858116207705) - present_state_Q (0.11066858116207705)) * f3(0.11077173165111932)
w4 ( 0.9593075183929299 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11066858116207705) - present_state_Q (0.11066858116207705)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8304899238179034 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11967649112928992) - present_state_Q (0.11967649112928992)) * f3(0.12134219330717991)
w4 ( 0.9596921007088972 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11967649112928992) - present_state_Q (0.11967649112928992)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8305535580390512 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19832085586224346) - present_state_Q (0.001660979847635807)) * f3(0.002)
w4 ( 0.9596921007088972 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19832085586224346) - present_state_Q (0.001660979847635807)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8316691158880786 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.12392470848207413) - present_state_Q (0.12392470848207413)) * f3(0.1260976675786776)
w4 ( 0.9598690362336295 ) += alpha ( 0.1) * (reward ( 0.2) + discount_factor ( 0.1) * next_state_max_Q( 0.12392470848207413) - present_state_Q (0.12392470848207413)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8315514582181913 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.1337498879574207) - present_state_Q (0.0016633382317761572)) * f3(0.002)
w4 ( 0.9598690362336295 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.1337498879574207) - present_state_Q (0.0016633382317761572)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.824134763912925 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.10769162887550521) - present_state_Q (0.10769162887550521)) * f3(0.106420651754317)
w4 ( 0.9584751913016536 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.10769162887550521) - present_state_Q (0.10769162887550521)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9260083502480845 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.9744104000611071) - present_state_Q (0.736945438956066)) * f3(0.596945438956066)
w4 ( 0.9826469384147006 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.9744104000611071) - present_state_Q (0.736945438956066)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0015552873321867 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.31226917600541204) - present_state_Q (0.26078264172726534)) * f3(0.22078264172726536)
w4 ( 1.000281777103493 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.31226917600541204) - present_state_Q (0.26078264172726534)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0022506167553942 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.30125795236517433) - present_state_Q (0.30125795236517433)) * f3(0.24086642923282992)
w4 ( 1.000454984160721 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.30125795236517433) - present_state_Q (0.30125795236517433)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0041686134863712 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19889886345649146) - present_state_Q (0.19889886345649146)) * f3(0.1585238875725616)
w4 ( 1.0009389482522777 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.19889886345649146) - present_state_Q (0.19889886345649146)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0060417239124197 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18007266222388718) - present_state_Q (0.15649237240237052)) * f3(0.11597137463593901)
w4 ( 1.0015850078275577 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.18007266222388718) - present_state_Q (0.15649237240237052)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0075969939476448 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1609427322417953) - present_state_Q (0.1609427322417953)) * f3(0.10024199730002556)
w4 ( 1.002515917073452 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1609427322417953) - present_state_Q (0.1609427322417953)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0090091861839772 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08327698546576884) - present_state_Q (0.08327698546576884)) * f3(0.06274995608768667)
w4 ( 1.0029660184996134 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.08327698546576884) - present_state_Q (0.08327698546576884)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0105911365927853 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09423683057328124) - present_state_Q (0.09423683057328124)) * f3(0.07351519809628755)
w4 ( 1.0033963922045814 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.09423683057328124) - present_state_Q (0.09423683057328124)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0123053648284888 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10400197859763906) - present_state_Q (0.10400197859763906)) * f3(0.08305441015100493)
w4 ( 1.0038091886431058 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.10400197859763906) - present_state_Q (0.10400197859763906)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0141449333095824 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11472618725521914) - present_state_Q (0.11472618725521914)) * f3(0.09349945853383207)
w4 ( 1.0042026815060463 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.11472618725521914) - present_state_Q (0.11472618725521914)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0161784088921433 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1364903942034507) - present_state_Q (0.1364903942034507)) * f3(0.11478274628207905)
w4 ( 1.0045569987964802 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1364903942034507) - present_state_Q (0.1364903942034507)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0181940639777882 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.13462107428987907) - present_state_Q (0.13462107428987907)) * f3(0.11270652211437177)
w4 ( 1.0049146808627585 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.13462107428987907) - present_state_Q (0.13462107428987907)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 1.0201182446641537 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12417747567374932) - present_state_Q (0.12417747567374932)) * f3(0.10221939582901028)
w4 ( 1.0052911614065458 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.12417747567374932) - present_state_Q (0.12417747567374932)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.9872699339979208 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.8463662179444806) - present_state_Q (0.8463662179444806)) * f3(0.7114187814713799)
w4 ( 0.9997504062527455 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.8463662179444806) - present_state_Q (0.8463662179444806)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8620650269172584 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.9628374919619546) - present_state_Q (0.9628374919619546)) * f3(0.8537355531515661)
w4 ( 0.9821517613395564 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.9628374919619546) - present_state_Q (0.9628374919619546)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.8405271127302628 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.8338344430781635) - present_state_Q (0.2740995749847147)) * f3(0.27238490972174656)
w4 ( 0.9789888968168488 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.8338344430781635) - present_state_Q (0.2740995749847147)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.7187498152817647 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.861637628315366) - present_state_Q (0.861637628315366)) * f3(0.88534795538018)
w4 ( 0.9624832104310428 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.861637628315366) - present_state_Q (0.861637628315366)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.5992400717017421 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.7033631978157524) - present_state_Q (0.7870909498718015)) * f3(0.9076083033923612)
w4 ( 0.9440486456097796 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.7033631978157524) - present_state_Q (0.7870909498718015)) * f4(0.14)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.523420038909942 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.5338082990402602) - present_state_Q (0.5338082990402602)) * f3(0.7017595808852917)
w4 ( 0.9310835159801448 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.5338082990402602) - present_state_Q (0.5338082990402602)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.46690553059381085 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.464662323387173) - present_state_Q (0.40251532913606963)) * f3(0.5911255865985113)
w4 ( 0.9215230250121713 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.464662323387173) - present_state_Q (0.40251532913606963)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.42478321919403905 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.3544416684499584) - present_state_Q (0.30095375692545145)) * f3(0.48667642603308636)
w4 ( 0.9145989482915277 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.3544416684499584) - present_state_Q (0.30095375692545145)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3672904231288608 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.3712053739254544) - present_state_Q (0.3712053739254544)) * f3(0.6154986551176361)
w4 ( 0.9033899302531327 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.3712053739254544) - present_state_Q (0.3712053739254544)) * f4(0.12)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.3166679746611759 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.30332144820003515) - present_state_Q (0.30332144820003515)) * f3(0.5798747850825361)
w4 ( 0.8946600372193324 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.30332144820003515) - present_state_Q (0.30332144820003515)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.2816773263620472 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.21173209892267647) - present_state_Q (0.21173209892267647)) * f3(0.4426064747946034)
w4 ( 0.8883355661070891 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.21173209892267647) - present_state_Q (0.21173209892267647)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.245347675299519 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.20196537320651842) - present_state_Q (0.20196537320651842)) * f3(0.46471091446566776)
w4 ( 0.8820814154200022 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.20196537320651842) - present_state_Q (0.20196537320651842)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.20915813902704222 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.17073643993883436) - present_state_Q (0.17073643993883436)) * f3(0.48018207170624533)
w4 ( 0.8775594386443325 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.17073643993883436) - present_state_Q (0.17073643993883436)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.20904207273010336 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2008683158375292) - present_state_Q (0.00041831627805408443)) * f3(0.002)
w4 ( 0.8775594386443325 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.2008683158375292) - present_state_Q (0.00041831627805408443)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1871371622229463 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.1013488394270968) - present_state_Q (0.1013488394270968)) * f3(0.3169049226126603)
w4 ( 0.874794582822395 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.1013488394270968) - present_state_Q (0.1013488394270968)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.14402956056226657 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.17631317226301135) - present_state_Q (0.17631317226301135)) * f3(0.5681907557759358)
w4 ( 0.8687251279821013 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.17631317226301135) - present_state_Q (0.17631317226301135)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10957369605057588 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.13802225459476436) - present_state_Q (0.13802225459476436)) * f3(0.4757651421603276)
w4 ( 0.862931367749019 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.13802225459476436) - present_state_Q (0.13802225459476436)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.08382875188919693 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.09303434560394447) - present_state_Q (0.09303434560394447)) * f3(0.3765362037250225)
w4 ( 0.8588289822827577 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.09303434560394447) - present_state_Q (0.09303434560394447)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.08614256963261262 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.041744247291300926) - present_state_Q (0.041744247291300926)) * f3(0.08816888995031207)
w4 ( 0.859878702992509 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.041744247291300926) - present_state_Q (0.041744247291300926)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.08619960987808975 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.025710865848106224) - present_state_Q (0.017369859199115406)) * f3(0.002)
w4 ( 0.8604491054472804 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.025710865848106224) - present_state_Q (0.017369859199115406)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.08922172167345671 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.026646957337726672) - present_state_Q (0.026646957337726672)) * f3(0.1094897673217894)
w4 ( 0.8610011409240724 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.026646957337726672) - present_state_Q (0.026646957337726672)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09252417462645963 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.02794028948796596) - present_state_Q (0.02794028948796596)) * f3(0.12015310250030482)
w4 ( 0.8615508484029941 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.02794028948796596) - present_state_Q (0.02794028948796596)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.0961047545658118 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.029339836054206588) - present_state_Q (0.029339836054206588)) * f3(0.13087194925037332)
w4 ( 0.8620980366980966 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.029339836054206588) - present_state_Q (0.029339836054206588)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.09970330468451895 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.029906090421654468) - present_state_Q (0.029906090421654468)) * f3(0.13177422641478403)
w4 ( 0.8626442057353376 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.029906090421654468) - present_state_Q (0.029906090421654468)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10305397872955378 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.029468600103403682) - present_state_Q (0.029468600103403682)) * f3(0.1225206729842093)
w4 ( 0.8631911622551515 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.029468600103403682) - present_state_Q (0.029468600103403682)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.10311453743724706 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.029996464238821168) - present_state_Q (0.00020610795745910757)) * f3(0.002)
w4 ( 0.8631911622551515 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.029996464238821168) - present_state_Q (0.00020610795745910757)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1089966169620467 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16717969043082637) - present_state_Q (0.11663256763710265)) * f3(0.2939784453771663)
w4 ( 0.8651920162692113 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16717969043082637) - present_state_Q (0.11663256763710265)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.12027492898167769 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1702975046314346) - present_state_Q (0.1702975046314346)) * f3(0.7686321405157519)
w4 ( 0.8666593387275283 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.1702975046314346) - present_state_Q (0.1702975046314346)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.13055536919684627 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14062538485910459) - present_state_Q (0.14062538485910459)) * f3(0.5927472862757858)
w4 ( 0.8680468359565428 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.14062538485910459) - present_state_Q (0.14062538485910459)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.12887102077218762 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.1439186795373058) - present_state_Q (0.1439186795373058)) * f3(0.5704471069932942)
w4 ( 0.8678106214638741 ) += alpha ( 0.1) * (reward ( 0.1) + discount_factor ( 0.1) * next_state_max_Q( 0.1439186795373058) - present_state_Q (0.1439186795373058)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.13791348786224095 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.13789851068776765) - present_state_Q (0.16521227711011385)) * f3(0.6086024188663299)
w4 ( 0.8692963972034607 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.13789851068776765) - present_state_Q (0.16521227711011385)) * f4(0.1)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.14701641694692238 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.189904933203119) - present_state_Q (0.13947880811089808)) * f3(0.5070939573689702)
w4 ( 0.870732490685136 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.189904933203119) - present_state_Q (0.13947880811089808)) * f4(0.08)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.12821996707748307 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1160793550933529) - present_state_Q (0.10792212234859344)) * f3(0.37872078549966887)
w4 ( 0.8677546055641004 ) += alpha ( 0.1) * (reward ( -0.4) + discount_factor ( 0.1) * next_state_max_Q( 0.1160793550933529) - present_state_Q (0.10792212234859344)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1281039785100996 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.20313603016917053) - present_state_Q (0.0002564399341549661)) * f3(0.002)
w4 ( 0.8677546055641004 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.20313603016917053) - present_state_Q (0.0002564399341549661)) * f4(0.0)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.11115224011001996 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.1289951378258587) - present_state_Q (0.06786585926874869)) * f3(0.2588184647487018)
w4 ( 0.8651347401821557 ) += alpha ( 0.1) * (reward ( -0.6) + discount_factor ( 0.1) * next_state_max_Q( 0.1289951378258587) - present_state_Q (0.06786585926874869)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1158172813461585 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07413610800462442) - present_state_Q (0.07413610800462442)) * f3(0.19997818821909005)
w4 ( 0.8665344051989308 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07413610800462442) - present_state_Q (0.07413610800462442)) * f4(0.06)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.12001945360046325 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07121025085006656) - present_state_Q (0.05387956274608795)) * f3(0.1659353968143214)
w4 ( 0.8675473710482865 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.07121025085006656) - present_state_Q (0.05387956274608795)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1236977787400446 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05214663388222751) - present_state_Q (0.05214663388222751)) * f3(0.1453492622818333)
w4 ( 0.8685596431663105 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05214663388222751) - present_state_Q (0.05214663388222751)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1268594856229838 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05008403886414374) - present_state_Q (0.05008403886414374)) * f3(0.12402529207684773)
w4 ( 0.8695793406263996 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.05008403886414374) - present_state_Q (0.05008403886414374)) * f4(0.04)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1296590134829721 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.030418599386052264) - present_state_Q (0.030418599386052264)) * f3(0.10268851800518493)
w4 ( 0.8701245871475047 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.030418599386052264) - present_state_Q (0.030418599386052264)) * f4(0.02)
============================================================================
NOT GUIDE learning . . .
w3 ( 0.1370221615878133 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16894273716961583) - present_state_Q (0.16894273716961583)) * f3(0.49767297296604524)
w4 ( 0.8719000055860728 ) += alpha ( 0.1) * (reward ( 0.3) + discount_factor ( 0.1) * next_state_max_Q( 0.16894273716961583) - present_state_Q (0.16894273716961583)) * f4(0.12)
============================================================================
